[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "COMP/STAT112 Notebook",
    "section": "",
    "text": "Welcome\nWelcome to my online portfolio for COMP/STAT112 course taken at Macalester College. Please, use the side bar on the left for navigation.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "bw/bw-uni.html",
    "href": "bw/bw-uni.html",
    "title": "\n1  Univariate Viz\n",
    "section": "",
    "text": "Use this file to generate a professional looking univariate visualization. The visualization will not perfect the first time but you are expected to improve on it throughout the semester especially after covering advanced topics such as effective viz.\n\nlibrary(ggplot2)\n# Option 2: Read directly from GitHub\nexped_tidy &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-01-21/exped_tidy.csv')\n\nRows: 882 Columns: 69\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (22): EXPID, PEAKID, SEASON_FACTOR, HOST_FACTOR, ROUTE1, ROUTE2, NATION...\ndbl  (17): YEAR, SEASON, HOST, SMTDAYS, TOTDAYS, TERMREASON, HIGHPOINT, CAMP...\nlgl  (27): ROUTE3, ROUTE4, SUCCESS1, SUCCESS2, SUCCESS3, SUCCESS4, ASCENT3, ...\ndate  (3): BCDATE, SMTDATE, TERMDATE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\npeaks_tidy &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-01-21/peaks_tidy.csv')\n\nRows: 480 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (14): PEAKID, PKNAME, PKNAME2, LOCATION, HIMAL_FACTOR, REGION_FACTOR, RE...\ndbl (12): HEIGHTM, HEIGHTF, HIMAL, REGION, TREKYEAR, PHOST, PSTATUS, PEAKMEM...\nlgl  (3): OPEN, UNLISTED, TREKKING\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n#|fig-cap: \"A bar graph measuring the amount of Himalayan mountain expeditions per season\"\n#|gif-alt: \"A bar graph measuring number of himalayan mountain expeditinos per season. Spring followed by Autumn are the most popular seasons, with Winter and Summer following hundreds of expeditions behind. https://github.com/rfordatascience/tidytuesday/blob/main/data/2025/2025-01-21/readme.md\"\nggplot(exped_tidy, aes(x = SEASON_FACTOR)) +\n  geom_bar() +\n  labs(x = \"Season\", y = \"Number of Expeditions\")",
    "crumbs": [
      "Best Work",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Univariate Viz</span>"
    ]
  },
  {
    "objectID": "bw/bw-bi.html",
    "href": "bw/bw-bi.html",
    "title": "\n2  Bivariate Viz\n",
    "section": "",
    "text": "Use this file to generate a professional looking bivariate visualization. The visualization will not perfect the first time but you are expected to improve it throughout the semester especially after covering advanced topics such as effective viz.\n\nlibrary(ggplot2)\n# Load data\nelections &lt;- read.csv(\"https://mac-stat.github.io/data/election_2020_county.csv\")\n\n#|fig-cap: \"Made by Elina Poll, 2/2025, source: https://mac-stat.github.io/data/election_2020_county.csv\"\n#|fig-alt: \"A scatterplot of the amount of Republican county support and average rent. The lower the median rent is, the more support counties have.\"\nggplot(elections, aes(x = repub_pct_20, y = median_rent)) + \n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  labs(y = \"Median Rent\", x = \"Republican Support (by county)\", title = \"Median Rent's impact on Republican county support\")\n\n`geom_smooth()` using formula = 'y ~ x'",
    "crumbs": [
      "Best Work",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Bivariate Viz</span>"
    ]
  },
  {
    "objectID": "bw/bw-tri.html",
    "href": "bw/bw-tri.html",
    "title": "\n3  Trivariate Viz\n",
    "section": "",
    "text": "Use this file to generate a professional looking trivariate visualization. The visualization will not perfect the first time but you are expected to improve on it throughout the semester especially after covering advanced topics such as effective viz.\n\nlibrary(ggplot2)\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ lubridate 1.9.4     ✔ tibble    3.2.1\n✔ purrr     1.0.2     ✔ tidyr     1.3.1\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(mosaic)\n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\nAttaching package: 'mosaic'\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\nThe following object is masked from 'package:purrr':\n\n    cross\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\nlibrary(fivethirtyeight)\n\nSome larger datasets need to be installed separately, like senators and\nhouse_district_forecast. To install these, we recommend you install the\nfivethirtyeightdata package by running:\ninstall.packages('fivethirtyeightdata', repos =\n'https://fivethirtyeightdata.github.io/drat/', type = 'source')\n\ndata(bechdel)\nnew_bechdel &lt;- bechdel |&gt;\n  mutate(Result = factor(clean_test, c(\"nowomen\", \"notalk\", \"men\", \"dubious\", \"ok\"))) |&gt;\n  mutate(half_decades = cut(year, breaks = seq(1969, 2014, by = 5)))\n\n#|fig-cap: \"Made by Elina Poll, 2/2025, source: https://fivethirtyeight.com/features/the-dollar-and-cents-case-against-hollywoods-exclusion-of-women/\"\n#|fig-alt: \"A bar graph of Bechdel Test results for movies released every half-decade. More movies are passing the test with each half-decade, but only faliures due to women not talking to each other have substantially decreased\"\nggplot(new_bechdel, aes(x = half_decades, fill = Result)) +\n  geom_bar(position = \"fill\") + \n  scale_fill_viridis_d() +\n  labs(y = \"% of surveyed movies\", x = \"Half Decades\")",
    "crumbs": [
      "Best Work",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Trivariate Viz</span>"
    ]
  },
  {
    "objectID": "bw/bw-quad.html",
    "href": "bw/bw-quad.html",
    "title": "\n4  Quadvariate Viz\n",
    "section": "",
    "text": "Use this file to generate a professional looking quadvariate visualization. The visualization will not perfect the first time but you are expected to improve on it throughout the semester especially after covering advanced topics such as effective viz.\n\nlibrary(ggplot2)\n#|fig-cap: \"Made by Elina Poll, 2/2025, source: https://mac-stat.github.io/data/sat.csv\"\n#|fig-alt: \"A scatterplot of Per-pupil funding and SAT average, seperated by the percentile of students taking it. When seperated, there becomes a positive correlation for each group with more spending increasing sat score.\"\neducation &lt;- read.csv(\"https://mac-stat.github.io/data/sat.csv\")\nggplot(education, aes(x = expend, y = sat, color = fracCat)) +\n  geom_point() +\n  geom_smooth(se = FALSE, method = \"lm\") +\n  scale_color_viridis_d() +\n  labs(x = \"Expenditure per pupil\", y = \"Average SAT score\", title = \"SAT Scores vs Per Pupil Spending\", color = \"# of students taking SAT\")  \n\n`geom_smooth()` using formula = 'y ~ x'",
    "crumbs": [
      "Best Work",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Quadvariate Viz</span>"
    ]
  },
  {
    "objectID": "bw/bw-spatial.html",
    "href": "bw/bw-spatial.html",
    "title": "\n5  Spatial Viz\n",
    "section": "",
    "text": "Use this file to generate a professional looking spatial visualization. The visualization will not perfect the first time but you are expected to improve on it throughout the semester especially after covering advanced topics such as effective viz.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(openintro)\n\nLoading required package: airports\nLoading required package: cherryblossom\nLoading required package: usdata\n\nlibrary(ggthemes)\n\n# Import starbucks location data\nstarbucks &lt;- read.csv(\"https://mac-stat.github.io/data/starbucks.csv\")\n\n\nstarbucks_us_by_state &lt;- starbucks |&gt;\n  filter(Country == \"US\") |&gt;\n  count(State.Province) |&gt;\n  mutate(state_name = str_to_lower(abbr2state(State.Province)))\n\n\ncensus_pop_est_2018 &lt;- read_csv(\"https://mac-stat.github.io/data/us_census_2018_state_pop_est.csv\") |&gt;\n  separate(state, into = c(\"dot\", \"state\"), extra = \"merge\") |&gt;\n  select(-dot) |&gt;\n  mutate(state = str_to_lower(state))\n\nRows: 51 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): state\ndbl (1): est_pop_2018\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nstarbucks_with_2018_pop_est &lt;-\n  starbucks_us_by_state |&gt;\n  left_join(census_pop_est_2018,\n    by = c(\"state_name\" = \"state\")\n  ) |&gt;\n  mutate(starbucks_per_10000 = (n / est_pop_2018) * 10000)\n\n\nstates_map &lt;- map_data(\"state\")\nstarbucks_contiguous_us &lt;- starbucks |&gt;\n  filter(Country == \"US\", State.Province != \"AK\", State.Province != \"HI\")\n\n#|fig-cap: \"created by Elina, 2/2025, data: https://mac-stat.github.io/data/us_census_2018_state_pop_est.csv\"\n#|fig-alt: \"A map of the amount of each US State's amount of starbucks per 10,000 people, accompanied by plots of each starbucks location. Although there are more starbucks on the east coast, the west coast tends to have more starbucks per person.\"\nggplot(starbucks_with_2018_pop_est, aes(map_id = state_name, fill = starbucks_per_10000)) +\n  geom_map(map = states_map) +\n  expand_limits(x = states_map$long, y = states_map$lat) +\n  scale_fill_viridis_c() +\n  theme_map() +\n  geom_point(\n    data = starbucks_contiguous_us,\n    aes(x = Longitude, y = Latitude),\n    inherit.aes = FALSE\n  ) +\n  expand_limits(x = states_map$long, y = states_map$lat) +\n  labs(title = \"# of Starbucks per 10,000 people\")",
    "crumbs": [
      "Best Work",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Spatial Viz</span>"
    ]
  },
  {
    "objectID": "bw/bw-exam.html",
    "href": "bw/bw-exam.html",
    "title": "",
    "section": "",
    "text": "Best Work6  bw-exam.html Code\n#all the setup stuff\nlibrary(tidytuesdayR)\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\ntuesdata &lt;- tt_load('2020-02-18')\n\n---- Compiling #TidyTuesday Information for 2020-02-18 ----\n--- There is 1 file available ---\n\n\n── Downloading files ───────────────────────────────────────────────────────────\n\n  1 of 1: \"food_consumption.csv\"\n\nfc &lt;- tuesdata$food_consumption\n\n#| fig-alt: \"a histogram of food consuption with combined countries, faceted by food type. aside from dairy products which are the most evenly spread, other categories like eggs, lamb, and soybeans are less common. source: https://github.com/rfordatascience/tidytuesday/blob/main/data/2020/2020-02-18/readme.md\"\n\n#honest to god, i really did not know how to make an effective graph with this many countries. this one is clearly coherent in telling you the consumption of different food types overall, but how the hell would you be able to tell if i filled by country? it has the effective vis properties, it's just not great. i am aware. \nfc |&gt;\n  ggplot(aes(x = consumption)) +\n  geom_histogram() +\n  facet_wrap(~food_category) +\n  labs(x = \"Consumption\", y = \"Food Category\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n#but at least I tried to color it? to be fair, this one does show the variance of each food category a lot better, but a dotplot was the only way i was able to get a not super hideous result. \nfc |&gt;\n  ggplot(aes(x = consumption, y = food_category, color = country)) +\ngeom_point() +\n  scale_colour_viridis_d() +\n  labs(x = \"Consumption\", y = \"Food Category\")",
    "crumbs": [
      "Best Work",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>bw-exam.html</span>"
    ]
  },
  {
    "objectID": "bw/bw-summary.html",
    "href": "bw/bw-summary.html",
    "title": "",
    "section": "",
    "text": "Best Work7  bw-summary.html Code\n\n\n\n\n\n\n\nmy redone exam summary sheet",
    "crumbs": [
      "Best Work",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>bw-summary.html</span>"
    ]
  },
  {
    "objectID": "bw/bw-exam2.html",
    "href": "bw/bw-exam2.html",
    "title": "",
    "section": "",
    "text": "Best Work8  bw-exam2.html Code\nlibrary(tidytuesdayR)\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(rnaturalearth)\nlibrary(sf)\n\nLinking to GEOS 3.13.0, GDAL 3.10.1, PROJ 9.5.1; sf_use_s2() is TRUE\n\ntuesdata &lt;- tt_load('2020-02-18')\n\n---- Compiling #TidyTuesday Information for 2020-02-18 ----\n--- There is 1 file available ---\n\n\n── Downloading files ───────────────────────────────────────────────────────────\n\n  1 of 1: \"food_consumption.csv\"\n\nfc &lt;- tuesdata$food_consumption\n#to the poor person who has to look at this. yes. i know the graphs are bad. believe me. i struggled.\n\n\nfc |&gt;\n  mutate(food_category = fct_recode(food_category, \"Lamb\" = \"Lamb & Goat\", \"Dairy\" = \"Milk - inc. cheese\", \"Wheat\" = \"Wheat and Wheat Products\", \"Nuts\" = \"Nuts inc. Peanut Butter\")) |&gt;\n  group_by(country) |&gt;\n  summarize(totalcons = sum(consumption)) |&gt;\n  select(country, totalcons) |&gt;\n  arrange(desc(totalcons)) |&gt;\n  head(5) |&gt;\n  \n  ggplot(aes(x = totalcons, fill = country)) +\n  geom_bar() +\n  scale_fill_viridis_d() +\n  theme_minimal() +\n  labs(x = \"Country\", y = \"Count\", color = \"Country\")\n\n\n\nCreated by Elina, 4/2/25, data: https://github.com/rfordatascience/tidytuesday/blob/main/data/2020/2020-02-18/readme.md\n\n\n\n\nfc |&gt;\n  mutate(food_category = fct_recode(food_category, \"Lamb\" = \"Lamb & Goat\", \"Dairy\" = \"Milk - inc. cheese\", \"Wheat\" = \"Wheat and Wheat Products\", \"Nuts\" = \"Nuts inc. Peanut Butter\")) |&gt;\n  group_by(country) |&gt;\n  summarize(totalcons = sum(consumption)) |&gt;\n  select(country, totalcons) |&gt;\n  arrange(desc(totalcons)) |&gt;\n  head(5) |&gt;\n  \n  ggplot(aes(x = totalcons, fill = country)) +\n  geom_boxplot() +\n  scale_fill_viridis_d() +\n  theme_minimal() +\n  labs(x = \"Country\", y = \"Count\", color = \"Country\")\n\n\n\nCreated by Elina, 4/2/25, data: https://github.com/rfordatascience/tidytuesday/blob/main/data/2020/2020-02-18/readme.md\n\n\n\n\nfc |&gt;\n  mutate(food_category = fct_recode(food_category, \"Lamb\" = \"Lamb & Goat\", \"Dairy\" = \"Milk - inc. cheese\", \"Wheat\" = \"Wheat and Wheat Products\", \"Nuts\" = \"Nuts inc. Peanut Butter\")) |&gt;\n  group_by(food_category) |&gt;\n  slice_max(consumption, n = 5) |&gt;\n  select(-co2_emmission) |&gt;\n  ggplot(aes(x = country, y = consumption, color = country)) +\n  geom_point() +\n  facet_wrap(~food_category) \n\n\n\nCreated by Elina, 4/2/25, data: https://github.com/rfordatascience/tidytuesday/blob/main/data/2020/2020-02-18/readme.md\n\n\n\n\nne_countries(returnclass = \"sf\") |&gt;\n  select(name, geometry) |&gt;\n  mutate(name = ifelse(name == \"United States of America\", \"USA\", name)) |&gt;\n  mutate(name = ifelse(name == \"Bosnia and Herz\", \"Bosnia and Herzgovina\", name)) |&gt;\n  mutate(name = ifelse(name == \"Czechia\", \"Czech Republic\", name)) |&gt;\n  mutate(name = ifelse(name == \"Taiwan\", \"Taiwan. ROC\", name)) |&gt;\n  left_join(\n    fc |&gt;\n      select(-co2_emmission) |&gt;\n      group_by(food_category) |&gt;\n      mutate(consumption = (consumption - mean(consumption))/sd(consumption)),\n    join_by(name == country)) |&gt;\n  pivot_wider(names_from = food_category, values_from = consumption) |&gt;\n  select(-\"NA\") |&gt;\n  pivot_longer(cols = c(-name, -geometry),\n               names_to = \"food_category\",\n               values_to = \"consumption\") |&gt;\n  ggplot() +\n  geom_sf(aes(fill = consumption)) +\n  facet_wrap(~food_category) +\n  theme(legend.position = \"bottom\") +\n  scale_fill_viridis_c() +\n  labs(fill = \"Level of consumption\")\n\n\n\nCreated by Elina, 4/2/25, data: https://github.com/rfordatascience/tidytuesday/blob/main/data/2020/2020-02-18/readme.md",
    "crumbs": [
      "Best Work",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>bw-exam2.html</span>"
    ]
  },
  {
    "objectID": "bw/bw-solo.html",
    "href": "bw/bw-solo.html",
    "title": "\n9  solo\n",
    "section": "",
    "text": "library(sf)\n\nLinking to GEOS 3.13.0, GDAL 3.10.1, PROJ 9.5.1; sf_use_s2() is TRUE\n\nlibrary(ggplot2)\nlibrary(maps)\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ lubridate 1.9.4     ✔ tibble    3.2.1\n✔ purrr     1.0.4     ✔ tidyr     1.3.1\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n✖ purrr::map()    masks maps::map()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(stringr)\n\n\nelectric &lt;- read.csv('C:\\\\Users\\\\comma\\\\OneDrive\\\\Documents\\\\GitHub\\\\portfolio-tookmybasspills\\\\data\\\\Electric_Vehicle_Population_Data.csv')\n\n\n # washington &lt;- st_as_sf(\n #  maps::map(\"county\",\n #            region = c(\"washington\"), \n #            fill = TRUE, plot = FALSE))\n # ggplot(electric, aes(map_id = County, fill",
    "crumbs": [
      "Best Work",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>solo</span>"
    ]
  },
  {
    "objectID": "ica/ica-uni.html",
    "href": "ica/ica-uni.html",
    "title": "10  Univariate Viz",
    "section": "",
    "text": "Use this file for practice with the univariate viz in-class activity. Refer to the class website for details.",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Univariate Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-bi.html",
    "href": "ica/ica-bi.html",
    "title": "\n11  Bivariate Viz\n",
    "section": "",
    "text": "11.1 Review\nLet’s review some univariate concepts and code using our class survey data. If the answers aren’t at the top of your mind, don’t fret! We’ve barely started speaking this new language, and learned a ton of vocab last week, so you naturally won’t remember it all.\n# Import data\nsurvey &lt;- read.csv(\"https://hash-mac.github.io/stat112site-s25/data/survey.csv\")\n\n# How many students have now filled out the survey?\n\n\n# What type of variables do we have?",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Bivariate Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-bi.html#review",
    "href": "ica/ica-bi.html#review",
    "title": "\n11  Bivariate Viz\n",
    "section": "",
    "text": "EXAMPLE 1: Hangout Preferences\nStudents were asked, in that moment, where they’d most like to spend time outside. How did they answer? Was there a lot of agreement or a lot of variability in answers? Build and interpret a plot that helps address these questions while reviewing:\n\n“code as communication”\nconnecting with the components of a plot:\n\nset up a frame\n\nadd a layer / geometric element\nchange the theme, e.g. axis labels, color, fill\n\n\n\n\n# Attach a package needed to use the ggplot function\n\n\n# Make a ggplot\n\nEXAMPLE 2: Temperature Preferences\nStudents were asked about their ideal outdoor temperature, in degrees Celsius. How did they answer? What was the typical response? What was the range in responses? Were there any outliers? Build and interpret 2 plots that help address these questions.\n\n\n\n\n\n\nBar Charts vs. Histograms\n\n\n\nBar charts & histograms can appear pretty similar, but they do different things.\n\n\nBar charts count up the number of observations of each outcome of a variable. They’re good for categorical variables, or quantitative variables with only a handful of possible outcomes.\n\nHistograms count up the number of observations that fall into different numerical ranges of variable. They’re good for quantitative variables, especially those with many different observed outcomes.",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Bivariate Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-bi.html#new-stuff",
    "href": "ica/ica-bi.html#new-stuff",
    "title": "\n11  Bivariate Viz\n",
    "section": "\n11.2 New stuff",
    "text": "11.2 New stuff\nThus far, we’ve been studying one variable at a time, using univariate plots. But once we get a sense of how individual variables behave on their own, our questions often turn to relationships among variables. For example, in our hikes data:\n\nHow much time does it take to complete a hike? ——&gt; How is time related to a hike’s elevation? What about its length?\nHow does difficult rating vary from hike to hike? ——-&gt; How is difficulty rating related to a hike’s ascent?\n\n\n11.2.1 Exploring relationships\nExploring univariate patterns often sparks follow-up questions about relationships between 2+ variables. Often, but not always, variables take on specific roles:\n\n\nresponse variable: the variable whose variability we would like to explain (time to complete a hike)\n\npredictors: variables that might explain some of the variability in the response (a hike’s elevation or length)\n\nVisualizations can help explore:\n\nrelationship trends (direction and form)\nrelationship strength (degree of variability from the trend)\n\noutliers in the relationship\n\nEXAMPLE 3\nFor each pair of variables below, sketch on paper a visualization of their relationship. Focus on general viz process, don’t worry about the exact details. The data here are totally made up.\n\n3pm temperature (response) vs 9am temperature (predictor)\n\n\ndata.frame(temp_3pm = c(24, 26, 20, 15, 15, 15), temp_9am = c(14, 18, 15, 13, 11, 11))\n\n  temp_3pm temp_9am\n1       24       14\n2       26       18\n3       20       15\n4       15       13\n5       15       11\n6       15       11\n\n\n\n3pm temperature (response) vs location (predictor)\n\n\nweather &lt;- data.frame(temp_3pm = c(24, 26, 20, 15, 15, 0, 40, 60, 57, 44, 51, 75),\n                      location = rep(c(\"A\", \"B\"), each = 6))\nweather\n\n   temp_3pm location\n1        24        A\n2        26        A\n3        20        A\n4        15        A\n5        15        A\n6         0        A\n7        40        B\n8        60        B\n9        57        B\n10       44        B\n11       51        B\n12       75        B\n\n\nThink: How might we modify the below density plot of temp_3pm to distinguish between locations?\n\nggplot(weather, aes(x = temp_3pm)) +\n      geom_density()\n\n\n\n\n\n\n\n\n\nrain_today (the response) and location (the predictor)\n\n\nweather &lt;- data.frame(rain_today = c(\"no\", \"no\", \"no\", \"no\", \"yes\", \"no\", \"yes\", \"no\", \"yes\", \"yes\", \"no\", \"yes\"),\n                        location = c(rep(\"A\", 7), rep(\"B\", 5)))\n    weather\n\n   rain_today location\n1          no        A\n2          no        A\n3          no        A\n4          no        A\n5         yes        A\n6          no        A\n7         yes        A\n8          no        B\n9         yes        B\n10        yes        B\n11         no        B\n12        yes        B\n\n\nThink: How might we modify the below bar plot of location to distinguish between days on which it did or didn’t rain?\n\nggplot(weather, aes(x = location)) +\n      geom_bar()\n\n\n\n\n\n\n\n\n11.2.2 General guidance for building bivariate plots\nAs with univariate plots, an appropriate visualization for the relationship between 2 variables depends upon whether the variables are quantitative or categorical. In general:\n\nEach quantitative variable requires a new axis (or a quantitative scale if we run out of axes).\nEach categorical variable requires a new way to “group” the graphic (eg: using colors, shapes, separate facets, etc)\nFor visualizations in which overlap in glyphs or plots obscures the patterns, try faceting or transparency.",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Bivariate Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-bi.html#exercises-required",
    "href": "ica/ica-bi.html#exercises-required",
    "title": "\n11  Bivariate Viz\n",
    "section": "\n11.3 Exercises (required)",
    "text": "11.3 Exercises (required)\nGithub user Tony McGovern has compiled and made available 2020/2016/2012 presidential election results for most of 3000+ U.S. counties, except Alaska. (Image: Wikimedia Commons)\n\nA wrangled version of this data, is imported below, after being combined with:\n\n2013 county-level demographics from the df_county_demographics data set from the choroplethr R package\nhistorical voting trends in the state in which the county falls (from https://www.270towin.com/content/blue-and-red-states):\n\nred = consistently Republican\nblue = consistently Democratic\npurple = something in between\n\n\n\n\n# Load data\nelections &lt;- read.csv(\"https://mac-stat.github.io/data/election_2020_county.csv\")\n\n# Check it out\nhead(elections)\n\n  state_name state_abbr historical    county_name county_fips total_votes_20\n1    Alabama         AL        red Autauga County        1001          27770\n2    Alabama         AL        red Baldwin County        1003         109679\n3    Alabama         AL        red Barbour County        1005          10518\n4    Alabama         AL        red    Bibb County        1007           9595\n5    Alabama         AL        red  Blount County        1009          27588\n6    Alabama         AL        red Bullock County        1011           4613\n  repub_pct_20 dem_pct_20 winner_20 total_votes_16 repub_pct_16 dem_pct_16\n1        71.44      27.02     repub          24661        73.44      23.96\n2        76.17      22.41     repub          94090        77.35      19.57\n3        53.45      45.79     repub          10390        52.27      46.66\n4        78.43      20.70     repub           8748        76.97      21.42\n5        89.57       9.57     repub          25384        89.85       8.47\n6        24.84      74.70       dem           4701        24.23      75.09\n  winner_16 total_votes_12 repub_pct_12 dem_pct_12 winner_12 total_population\n1     repub          23909        72.63      26.58     repub            54907\n2     repub          84988        77.39      21.57     repub           187114\n3     repub          11459        48.34      51.25       dem            27321\n4     repub           8391        73.07      26.22     repub            22754\n5     repub          23980        86.49      12.35     repub            57623\n6       dem           5318        23.51      76.31       dem            10746\n  percent_white percent_black percent_asian percent_hispanic per_capita_income\n1            76            18             1                2             24571\n2            83             9             1                4             26766\n3            46            46             0                5             16829\n4            75            22             0                2             17427\n5            88             1             0                8             20730\n6            22            71             0                6             18628\n  median_rent median_age\n1         668       37.5\n2         693       41.5\n3         382       38.3\n4         351       39.4\n5         403       39.6\n6         276       39.6\n\n\nWe’ll use this data to explore voting outcomes within the U.S.’s 2-party system. Here’s a list of candidates by year:\n\n\nyear\nRepublican candidate\nDemocratic candidate\n\n\n\n2020\nDonald Trump\nJoe Biden\n\n\n2016\nDonald Trump\nHillary Clinton\n\n\n2012\nMitt Romney\nBarack Obama\n\n\n\nExercise 0: Review\nPart a\nHow many, or roughly what percent, of the 3000+ counties did the Republican candidate win in 2020?\n\nTake a guess.\nThen make a plot of the winner variable.\nThen discuss what follow-up questions you might have (and that our data might help us answer).\nPart b\nThe repub_pct_20 variable provides more detail about the Republican support in each county. Construct a plot of repub_pct_20.\nNotice that the distribution of Republican support from county to county is slightly left skewed or negatively skewed.\nWhat follow-up questions do you have?\nExercise 1: Quantitative vs Quantitative Intuition Check\n\n\n\n\n\n\nBe Quick\n\n\n\nDon’t spend more than 3 minutes on this!\n\n\nBelow is a scatterplot of the Republican support in 2020 vs 2016. Notice that:\n\nboth variables are quantitative, and get their own axes\nthe response variable is on the y-axis, demonstrating how repub_pct_20 might be predicted by repub_pct_16, not vice versa\n\nTry to replicate this using ggplot(). THINK:\n\nWhat info do you need to set up the canvas?\nWhat geometric layer (geom_???) might add these dots / points for each county? We haven’t learned this yet, just take some guesses.\n\n\nExercise 2: 2 Quantitiative Variables\nRun each chunk below to build up a a scatterplot of repub_pct_20 vs repub_pct_16 with different glyphs representing each county. Address or think about any prompts in the comments (#).\n\n# Set up the plotting frame\n# How does this differ than the frame for our histogram of repub_pct_20 alone?\nggplot(elections, aes(y = repub_pct_20, x = repub_pct_16))\n\n\n# Add a layer of points for each county\n# Take note of the geom!\nggplot(elections, aes(y = repub_pct_20, x = repub_pct_16)) +\n  geom_point()\n\n\n# Change the shape of the points\n# What happens if you change the shape to another number?\nggplot(elections, aes(y = repub_pct_20, x = repub_pct_16)) +\n  geom_point(shape = 3)\n\n\n# YOU TRY: Modify the code to make the points \"orange\"\n# NOTE: Try to anticipate if \"color\" or \"fill\" will be useful here. Then try both.\nggplot(elections, aes(y = repub_pct_20, x = repub_pct_16)) +\n  geom_point()\n\n\n\n\n\n\n\n\n# Add a layer that represents each county by the state it's in\n# Take note of the geom and the info it needs to run!\nggplot(elections, aes(y = repub_pct_20, x = repub_pct_16)) +\n  geom_text(aes(label = state_abbr))\n\nExercise 3: Reflect\nSummarize the relationship between the Republican support in 2020 and 2016. Be sure to comment on:\n\nthe strength of the relationship (weak/moderate/strong)\n\nthe direction of the relationship (positive/negative)\n\noutliers (in what state do counties deviate from the national trend? Any ideas why this might be the case?)\nExercise 4: Visualizing trend\nThe trend of the relationship between repub_pct_20 and repub_pct_16 is clearly positive and (mostly) linear. We can highlight this trend by adding a model “smooth” to the plot:\n\nggplot(elections, aes(y = repub_pct_20, x = repub_pct_16)) +\n  geom_point() +\n  geom_smooth()\n\nPart a\nConstruct a new plot that contains the model smooth but does not include the individual point glyphs.\nPart b\nBy default, geom_smooth() adds a smooth, localized model line. To examine the “best” linear model, we can specify method = \"lm\". It’s pretty similar in this example!\n\nggplot(elections, aes(y = repub_pct_20, x = repub_pct_16)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\n\nExercise 5: Your Turn\nTo examine how the 2020 results are related to some county demographics, construct scatterplots of repub_pct_20 vs median_rent, and repub_pct_20 vs median_age. Summarize the relationship between these two variables and comment on which is the better predictor of repub_pct_20, median_rent or median_age.\n\n# Scatterplot of repub_pct_20 vs median_rent\n\n\n\n# Scatterplot of repub_pct_20 vs median_age\n\nExercise 6: A Sad Scatterplot\nNext, let’s explore the relationship between a county’s 2020 Republican support repub_pct_20 and the historical political trends in its state. In this case repub_pct_20 is quantitative, but historical is categorical. Explain why a scatterplot might not be an effective visualization for exploring this relationship. (What questions does / doesn’t it help answer?)\n\nggplot(elections, aes(y = repub_pct_20, x = historical)) +\n  geom_point()\n\n\n\n\n\n\n\nExercise 7: Quantitative vs Categorical – Violins & Boxes\nThough the above scatterplot did group the counties by historical category, it’s nearly impossible to pick out meaningful patterns in 2020 Republican support in each category. Let’s try adding 2 different geom layers to the frame:\n\n# Side-by-side violin plots\nggplot(elections, aes(y = repub_pct_20, x = historical)) +\n  geom_violin()\n\n\n# Side-by-side boxplots (defined below)\nggplot(elections, aes(y = repub_pct_20, x = historical)) +\n  geom_boxplot()\n\nBox plots are constructed from five numbers - the minimum, 25th percentile, median, 75th percentile, and maximum value of a quantitative variable:\n\nREFLECT:\nSummarize what you’ve learned about the 2020 Republican county-level support within and between red/purple/blue states.\nExercise 8: Quantitative vs Categorical – Intuition Check\n\n\n\n\n\n\nBe Quick\n\n\n\nDon’t spend more than 3 minutes on this!\n\n\nWe can also visualize the relationship between repub_pct_20 and historical using our familiar density plots. In the plot below, notice that we simply created a separate density plot for each historical category. (The plot itself is “bad” but we’ll fix it below.) Try to adjust the code chunk below, which starts with a density plot of repub_pct_20 alone, to re-create this image.\n\n\nggplot(elections, aes(x = repub_pct_20)) +\n  geom_density()\n\n\n\n\n\n\n\nExercise 9: Quantitative vs Categorical – Density Plots\nWork through the chunks below and address the comments therein.\n\n# Name two \"bad\" things about this plot\nggplot(elections, aes(x = repub_pct_20, fill = historical)) +\n  geom_density()\n\n\n# What does scale_fill_manual do?\nggplot(elections, aes(x = repub_pct_20, fill = historical)) +\n  geom_density() +\n  scale_fill_manual(values = c(\"blue\", \"purple\", \"red\"))\n\n\n# What does alpha = 0.5 do?\n# Play around with different values of alpha, between 0 and 1\nggplot(elections, aes(x = repub_pct_20, fill = historical)) +\n  geom_density(alpha = 0.5) +\n  scale_fill_manual(values = c(\"blue\", \"purple\", \"red\"))\n\n\n# What does facet_wrap do?!\nggplot(elections, aes(x = repub_pct_20, fill = historical)) +\n  geom_density() +\n  scale_fill_manual(values = c(\"blue\", \"purple\", \"red\")) +\n  facet_wrap(~ historical)\n\n\n# Let's try a similar grouping strategy with a histogram instead of density plot.\n# Why is this terrible?\nggplot(elections, aes(x = repub_pct_20, fill = historical)) +\n  geom_histogram(color = \"white\") +\n  scale_fill_manual(values = c(\"blue\", \"purple\", \"red\"))\n\nExercise 10\nWe’ve now learned 3 (of many) ways to visualize the relationship between a quantitative and categorical variable: side-by-side violins, boxplots, and density plots.\n\nWhich do you like best?\nWhat is one pro of density plots relative to boxplots?\nWhat is one con of density plots relative to boxplots?\nExercise 11: Categorical vs Categorical – Intuition Check\nFinally, let’s simply explore who won each county in 2020 (winner_20) and how this breaks down by historical voting trends in the state. That is, let’s explore the relationship between 2 categorical variables! Following the same themes as above, we can utilize grouping features such as fill/color or facets to distinguish between different categories of winner_20 and historical.\n\n\n\n\n\n\nBe Quick\n\n\n\nSpend at most 5 minutes on the following intuition check. Adjust the code below to recreate the following two plots.\n\n\n\n\n# Plot 1: adjust this to recreate the top plot\nggplot(elections, aes(x = historical)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n# Plot 2: adjust this to recreate the bottom plot\nggplot(elections, aes(x = winner_20)) +\n  geom_bar()\n\n\n\n\n\n\n\nExercise 12: Categorical vs Categorical\nConstruct the following 4 bar plot visualizations.\n\n# A stacked bar plot\n# How are the \"historical\" and \"winner_20\" variables mapped to the plot, i.e. what roles do they play?\nggplot(elections, aes(x = historical, fill = winner_20)) +\n  geom_bar()\n\n\n# A faceted bar plot\nggplot(elections, aes(x = winner_20)) +\n  geom_bar() +\n  facet_wrap(~ historical)\n\n\n# A side-by-side bar plot\n# Note the new argument to geom_bar\nggplot(elections, aes(x = historical, fill = winner_20)) +\n  geom_bar(position = \"dodge\")\n\n\n# A proportional bar plot\n# Note the new argument to geom_bar\nggplot(elections, aes(x = historical, fill = winner_20)) +\n  geom_bar(position = \"fill\")\n\nPart a\nName one pro and one con of using the “proportional bar plot” instead of one of the other three options.\nPart b\nWhat’s your favorite bar plot from part and why?\nExercise 13: Practice (now or later)\n\n\n\n\n\n\nDecide\n\n\n\nDecide what’s best for you:\n\nTry this extra practice now.\nReflect on the above exercises and come back to this extra practice later (but before the next class).\n\n\n\nImport some daily weather data from a few locations in Australia:\n\nweather &lt;- read.csv(\"https://mac-stat.github.io/data/weather_3_locations.csv\")\n\nConstruct plots that address the research questions in each chunk. You might make multiple plots–there are many ways to do things!. However, don’t just throw spaghetti at the wall.\nReflect before doing anything. What types of variables are these? How might you plot just 1 of the variables, and then tweak the plot to incorporate the other?\n\n# How do 3pm temperatures (temp3pm) differ by location?\n\n\n# How might we predict the 3pm temperature (temp3pm) by the 9am temperature (temp9am)?\n\n\n# How do the number of rainy days (raintoday) differ by location?",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Bivariate Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-bi.html#exercises-optional",
    "href": "ica/ica-bi.html#exercises-optional",
    "title": "\n11  Bivariate Viz\n",
    "section": "\n11.4 Exercises (optional)",
    "text": "11.4 Exercises (optional)\nThe above visualizations are foundational and important. But they’re not the only way to visualize the variables in our dataset.\nOptional Exercise 1: Many Categories\nSuppose we wanted to better understand how the 2020 Republican support varied from county to county within each state. Since repub_pct_20 is quantitative and state_abbr is categorical, we could make a density plot of repub_pct_20 for each state. Reflect on why this is bad.\n\nggplot(elections, aes(x = repub_pct_20, fill = state_abbr)) + \n  geom_density(alpha = 0.5)\n\n\n\n\n\n\n\nA facet wrap would also be bad!\n\nggplot(elections, aes(x = repub_pct_20)) + \n  geom_density(alpha = 0.5) + \n  facet_wrap(~ state_abbr)\n\n\n\n\n\n\n\nWhen we want to compare the distribution of some quantitative outcome among many groups / categories, a ridgeline plot can be a good option. These are also called joy plots, named after the album cover for “Unknown Pleasures” by Joy Division. (Look it up!) To make a ridgeline plot, we can use the geom_density_ridges() function from the ggridges package.\n\n# Install ggridges package\nlibrary(ggridges)\n\n# Make our first joy plot\n# THINK: What DON'T you like about this?\nggplot(elections, aes(x = repub_pct_20, y = state_abbr)) + \n  geom_density_ridges()\n\n\n# Let's put the states in order by Republican support, not alphabet\n# How do you think fct_reorder works? We'll learn about this later in the semester.\nggplot(elections, aes(x = repub_pct_20, y = fct_reorder(state_abbr, repub_pct_20))) + \n  geom_density_ridges(alpha = 0.5)\n\n\n# YOUR TURN: color/fill the ridges according to a state's historical voting patterns \n# and add meaningful axis labels\n\nFollow-up questions\n\nWhich states tend to have the most variability in outcomes from county to county? The least?\nWhat other interesting patterns do you notice?\nDoes this plot prompt any other questions?\nOptional Exercise 2: Total Outcomes by State\nLet’s import some new data and counts up the total votes (Republican and Democratic) by state, not county. This was wrangled from the elections data!\n\nelections_by_state &lt;- read.csv(\"https://mac-stat.github.io/data/election_2020_by_state.csv\")\n\nFor example, we might make a scatterplot of the 2020 vs 2016 outcomes:\n\nggplot(elections_by_state, aes(y = repub_pct_20, x = repub_pct_16)) + \n  geom_point()\n\n\n\n\n\n\n\nBUT this isn’t the easiest way to communicate or identify the changes from 1 year to the next.\n\n# YOU TRY\n# Start by creating a \"scatterplot\" of state_abbr (y-axis) by 2020 Republican support on the x-axis\n# Color the points red\n# Scroll to solutions below when you're ready\n\n\n# Check it out\nggplot(elections_by_state, aes(x = repub_pct_20, y = state_abbr)) + \n  geom_point(color = \"red\")\n\n\n\n\n\n\n\n\n# YOU TRY\n# Reorder the states in terms of their 2020 Republican support (not alphabet)\n# Scroll to solutions below when you're ready\n\n\n# Check it out\nggplot(elections_by_state, aes(x = repub_pct_20, y = fct_reorder(state_abbr, repub_pct_20))) + \n  geom_point(color = \"red\")\n\n\n\n\n\n\n\n\n# Finally, add ANOTHER layer of points for the 2016 outcomes\n# What info does this new geom_point() layer need to run?\nggplot(elections_by_state, aes(x = repub_pct_20, y = fct_reorder(state_abbr, repub_pct_20))) + \n  geom_point(color = \"red\") + \n  geom_point(aes(x = repub_pct_16, y = state_abbr))\n\n\n\n\n\n\n\nReflect on the following\n\nWhat do you think this plot needs? Try it! You might need to do some digging online.\nSummarize the main takeaways from the plots. Which states changed the most from 2016 to 2020? The least? Where did the Republican support increase? Where did it decrease?\nWhat other questions are you left with?",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Bivariate Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-bi.html#solutions",
    "href": "ica/ica-bi.html#solutions",
    "title": "\n11  Bivariate Viz\n",
    "section": "\n11.5 Solutions",
    "text": "11.5 Solutions\n\nClick for Solutions\n\n# Import data\nsurvey &lt;- read.csv(\"https://ajohns24.github.io/data/112/about_us_2024.csv\")\n\n# How many students have now filled out the survey?\nnrow(survey)\n\n[1] 28\n\n# What type of variables do we have?\nstr(survey)\n\n'data.frame':   28 obs. of  4 variables:\n $ cafe_mac         : chr  \"Cheesecake\" \"Cheese pizza\" \"udon noodles\" \"egg rolls\" ...\n $ minutes_to_campus: int  15 10 4 7 5 35 5 15 7 20 ...\n $ fave_temp        : num  18 24 18 10 18 7 75 24 13 16 ...\n $ hangout          : chr  \"the mountains\" \"a beach\" \"the mountains\" \"a beach\" ...\n\n\nEXAMPLE 1: Hangout preferences\n\n# Attach a package needed to use the ggplot function\nlibrary(tidyverse)\n\n# Make a ggplot\nggplot(survey, aes(x = hangout)) + \n  geom_bar()\n\n\n\n\n\n\n\nEXAMPLE 2: Temperature preferences\n\nggplot(survey, aes(x = fave_temp)) + \n  geom_histogram(color = \"white\", binwidth = 5)\n\n\n\n\n\n\nggplot(survey, aes(x = fave_temp)) + \n  geom_density()\n\n\n\n\n\n\n\n\n11.5.1 Exercise 0:\n\nggplot(elections, aes(x = winner_20)) + \n  geom_bar()\n\n\n\n\n\n\nggplot(elections, aes(x = repub_pct_20)) + \n  geom_histogram(color = \"white\")\n\n\n\n\n\n\nggplot(elections, aes(x = repub_pct_20)) + \n  geom_density()\n\n\n\n\n\n\n\nExercise 1: quantitative vs quantitative intuition check\nSee next exercise.\nExercise 2: 2 quantitiative variables\n\n# Set up the plotting frame\n# How does this differ than the frame for our histogram of repub_pct_20 alone?\n# ANSWER: we added a y-axis variable\nggplot(elections, aes(y = repub_pct_20, x = repub_pct_16))\n\n\n\n\n\n\n# Add a layer of points for each county\n# Take note of the geom: geom_point\nggplot(elections, aes(y = repub_pct_20, x = repub_pct_16)) +\n  geom_point()\n\n\n\n\n\n\n# Change the shape of the points\n# What happens if you change the shape to another number?\nggplot(elections, aes(y = repub_pct_20, x = repub_pct_16)) +\n  geom_point(shape = 3)\n\n\n\n\n\n\n# YOU TRY: Modify the code to make the points \"orange\"\n# NOTE: Try to anticipate if \"color\" or \"fill\" will be useful here. Then try both.\nggplot(elections, aes(y = repub_pct_20, x = repub_pct_16)) +\n  geom_point(color = \"orange\")\n\n\n\n\n\n\n# Add a layer that represents each county by the state it's in\n# Take note of the geom and the info it needs to run!\nggplot(elections, aes(y = repub_pct_20, x = repub_pct_16)) +\n  geom_text(aes(label = state_abbr))\n\n\n\n\n\n\n\nExercise 3: Reflect\nThere’s a strong, positive association – the higher the Republican support in 2016, the higher it was in 2020. There are some counties in Texas and Utah where the R support in 2020 was disproportionately higher than in 2016.\nExercise 4: Visualizing trend\n\nggplot(elections, aes(y = repub_pct_20, x = repub_pct_16)) +\n  geom_point() +\n  geom_smooth()\n\n\n\n\n\n\n\nPart a\n\nggplot(elections, aes(y = repub_pct_20, x = repub_pct_16)) +\n  geom_smooth()\n\n\n\n\n\n\n\nPart b\n\nggplot(elections, aes(y = repub_pct_20, x = repub_pct_16)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\n\n\n\n\n\n\n\nExercise 5: Your turn\nThere’s a moderate, positive association between R support and median age – the older the average age in a county, the higher the R support tends to be. However, there’s a stronger, negative association between R support and median rent – the higher the rent (a proxy for cost of living), the lower the R support tends to be.\n\n# Scatterplot of repub_pct_20 vs median_rent\nggplot(elections, aes(y = repub_pct_20, x = median_rent)) +\n  geom_point() \n\n\n\n\n\n\n# Scatterplot of repub_pct_20 vs median_age\nggplot(elections, aes(y = repub_pct_20, x = median_age)) +\n  geom_point() \n\n\n\n\n\n\n\nExercise 6: A sad scatterplot\nSee next exercise.\nExercise 7: quantitative vs categorical – violins & boxes\n\n# Side-by-side violin plots\nggplot(elections, aes(y = repub_pct_20, x = historical)) +\n  geom_violin()\n\n\n\n\n\n\n# Side-by-side boxplots (defined below)\nggplot(elections, aes(y = repub_pct_20, x = historical)) +\n  geom_boxplot()\n\n\n\n\n\n\n\nREFLECT:\nThere’s quite a bit of range in county-level R support within blue, purple, and red states. However, R support tends to be higher in red states and lower in blue states.\nExercise 8: quantitative vs categorical – intuition check\nSee next exercise.\nExercise 9: quantitative vs categorical – density plots\n\n# The colors used don't match up with the blue, purple, red labels\n# The density plots are on top of each other\nggplot(elections, aes(x = repub_pct_20, fill = historical)) +\n  geom_density()\n\n\n\n\n\n\n# scale_fill_manual \"hard codes\" or defines what colors to use for the fill categories\nggplot(elections, aes(x = repub_pct_20, fill = historical)) +\n  geom_density() +\n  scale_fill_manual(values = c(\"blue\", \"purple\", \"red\"))\n\n\n\n\n\n\n# alpha = 0.5 adds transparency\n# the closer alpha is to 0, the more transparent.\n# the closer alpha is to 1, the more opaque.\nggplot(elections, aes(x = repub_pct_20, fill = historical)) +\n  geom_density(alpha = 0.5) +\n  scale_fill_manual(values = c(\"blue\", \"purple\", \"red\"))\n\n\n\n\n\n\n# facet_wrap separates the density plots into \"facets\" for each historical group\nggplot(elections, aes(x = repub_pct_20, fill = historical)) +\n  geom_density() +\n  scale_fill_manual(values = c(\"blue\", \"purple\", \"red\")) +\n  facet_wrap(~ historical)\n\n\n\n\n\n\n# Let's try a similar grouping strategy with a histogram instead of density plot.\n# Why is this terrible?\nggplot(elections, aes(x = repub_pct_20, fill = historical)) +\n  geom_histogram(color = \"white\") +\n  scale_fill_manual(values = c(\"blue\", \"purple\", \"red\"))\n\n\n\n\n\n\n\nExercise 10\n\nOne pro of density plots relative to boxplots: doesn’t oversimplify the data / boil the data down to just 5 numbers.\nName one con of density plots relative to boxplots: boxplots can be easier to interpret\nExercise 11: categorical vs categorical intuition check\nsee exercise below\nExercise 12: categorical vs categorical\n\n# A stacked bar plot\n# historical = x axis / bar categories\n# winner_20 = fills the bars\nggplot(elections, aes(x = historical, fill = winner_20)) +\n  geom_bar()\n\n\n\n\n\n\n# A faceted bar plot\nggplot(elections, aes(x = winner_20)) +\n  geom_bar() +\n  facet_wrap(~ historical)\n\n\n\n\n\n\n# A side-by-side bar plot\n# Note the new argument to geom_bar\nggplot(elections, aes(x = historical, fill = winner_20)) +\n  geom_bar(position = \"dodge\")\n\n\n\n\n\n\n# A proportional bar plot\n# Note the new argument to geom_bar\nggplot(elections, aes(x = historical, fill = winner_20)) +\n  geom_bar(position = \"fill\")\n\n\n\n\n\n\n\nPart a\npro = easier to compare the relative outcomes in blue vs purple vs red states con = lose track of how many counties fall into blue vs purple vs red states\nExercise 13: Practice (now or later)\n\nweather &lt;- read.csv(\"https://mac-stat.github.io/data/weather_3_locations.csv\")\n\n# How do 3pm temperatures (temp3pm) differ by location?\nggplot(weather, aes(x = temp3pm, fill = location)) + \n  geom_density(alpha = 0.5)\n\n\n\n\n\n\nggplot(weather, aes(y = temp3pm, x = location)) + \n  geom_boxplot()\n\n\n\n\n\n\n# How might we predict the 3pm temperature (temp3pm) by the 9am temperature (temp9am)?\nggplot(weather, aes(y = temp3pm, x = temp9am)) + \n  geom_point()\n\n\n\n\n\n\n# How do the number of rainy days (raintoday) differ by location?\nggplot(weather, aes(x = location, fill = raintoday)) + \n  geom_bar()\n\n\n\n\n\n\n\nOptional exercise 1: Dealing with lots of categories\n\n# Install ggridges package\nlibrary(ggridges)\n\n# Make our first joy plot\n# THINK: What DON'T you like about this?\nggplot(elections, aes(x = repub_pct_20, y = state_abbr)) + \n  geom_density_ridges()\n\n\n\n\n\n\n# Let's put the states in order by Republican support, not alphabet\n# How do you think fct_reorder works? We'll learn about this later in the semester.\nggplot(elections, aes(x = repub_pct_20, y = fct_reorder(state_abbr, repub_pct_20))) + \n  geom_density_ridges(alpha = 0.5)\n\n\n\n\n\n\n# YOUR TURN: color/fill the ridges according to a state's historical voting patterns \n# and add meaningful axis labels\nggplot(elections, aes(x = repub_pct_20, y = fct_reorder(state_abbr, repub_pct_20), fill = historical)) + \n  geom_density_ridges(alpha = 0.5) + \n  labs(y = \"state\", x = \"2020 Republican support (%)\") + \n  scale_fill_manual(values = c(\"blue\", \"purple\", \"red\"))\n\n\n\n\n\n\n\nOptional exercise 2: total outcomes by state\n\nelections_by_state &lt;- read.csv(\"https://mac-stat.github.io/data/election_2020_by_state.csv\")\n\nggplot(elections_by_state, aes(y = repub_pct_20, x = repub_pct_16)) + \n  geom_point()\n\n\n\n\n\n\n# YOU TRY\n# Start by creating a \"scatterplot\" of state_abbr (y-axis) by 2020 Republican support on the x-axis\n# Color the points red\nggplot(elections_by_state, aes(x = repub_pct_20, y = state_abbr)) + \n  geom_point(color = \"red\")\n\n\n\n\n\n\n# YOU TRY\n# Reorder the states in terms of their 2020 Republican support (not alphabet)\nggplot(elections_by_state, aes(x = repub_pct_20, y = fct_reorder(state_abbr, repub_pct_20))) + \n  geom_point(color = \"red\")\n\n\n\n\n\n\n# Finally, add ANOTHER layer of points for the 2016 outcomes\n# What info does this new geom_point() layer need to run?\nggplot(elections_by_state, aes(x = repub_pct_20, y = fct_reorder(state_abbr, repub_pct_20))) + \n  geom_point(color = \"red\") + \n  geom_point(aes(x = repub_pct_16, y = state_abbr))",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Bivariate Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-multi.html",
    "href": "ica/ica-multi.html",
    "title": "\n12  Multivariate Viz\n",
    "section": "",
    "text": "12.1 Review\nLet’s review some univariate and bivariate plotting concepts using some daily weather data from Australia. This is a subset of the data from the weatherAUS data in the rattle package.\nlibrary(tidyverse)\nlibrary(ggplot2)\n# Import data\nweather &lt;- read.csv(\"https://mac-stat.github.io/data/weather_3_locations.csv\") |&gt; \n  mutate(date = as.Date(date))  \n\n# Check out the first 6 rows\nhead(weather)\n\n        date   location mintemp maxtemp rainfall evaporation sunshine\n1 2020-01-01 Wollongong    17.1    23.1        0          NA       NA\n2 2020-01-02 Wollongong    17.7    24.2        0          NA       NA\n3 2020-01-03 Wollongong    19.7    26.8        0          NA       NA\n4 2020-01-04 Wollongong    20.4    35.5        0          NA       NA\n5 2020-01-05 Wollongong    19.8    21.4        0          NA       NA\n6 2020-01-06 Wollongong    18.3    22.9        0          NA       NA\n  windgustdir windgustspeed winddir9am winddir3pm windspeed9am windspeed3pm\n1         SSW            39        SSW        SSE           20           15\n2         SSW            37          S        ENE           13           15\n3          NE            41        NNW        NNE            7           17\n4         SSW            78         NE        NNE           15           17\n5         SSW            57        SSW          S           31           35\n6          NE            35        ESE         NE           17           20\n  humidity9am humidity3pm pressure9am pressure3pm cloud9am cloud3pm temp9am\n1          69          64      1014.9      1014.0        8        1    19.1\n2          72          54      1020.1      1017.7        7        1    19.8\n3          72          71      1017.5      1013.0        6       NA    23.4\n4          77          69      1008.8      1003.9       NA       NA    24.5\n5          70          75      1018.9      1019.9       NA        7    20.7\n6          71          71      1021.2      1018.2       NA       NA    20.9\n  temp3pm raintoday risk_mm raintomorrow\n1    22.9        No     0.0           No\n2    23.6        No     0.0           No\n3    25.7        No     0.0           No\n4    26.7        No     0.0           No\n5    20.0        No     0.0           No\n6    22.6        No     0.8           No\n\n# What are the units of observation?\n\"Units of observation are almost all numerical, except for wind and if there's rain or not\"\n\n[1] \"Units of observation are almost all numerical, except for wind and if there's rain or not\"\n\n# How many data points do we have? \n\"there are 2367 days kept on the sheet\"\n\n[1] \"there are 2367 days kept on the sheet\"\n\n# What type of variables do we have?\n\"temperature, rainfall and exaporation, sunshine, wind, and measures for each at 9 and 3 pm\"\n\n[1] \"temperature, rainfall and exaporation, sunshine, wind, and measures for each at 9 and 3 pm\"",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Multivariate Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-multi.html#review",
    "href": "ica/ica-multi.html#review",
    "title": "\n12  Multivariate Viz\n",
    "section": "",
    "text": "Example 1\nConstruct a plot that allows us to examine how temp3pm varies.\n\nggplot(weather, aes(x = temp3pm)) +\n  geom_histogram(color = \"white\") +\n  labs(x = \"3pm Temperature\", y = \"Count\")\n\n\n\n\n\n\n\nExample 2\nConstruct 3 plots that address the following research question:\nHow do afternoon temperatures (temp3pm) differ by location?\n\n# Plot 1 (no facets & starting from a density plot of temp3pm)\nggplot(weather, aes(x = temp3pm)) + \n  geom_density()\n\n\n\n\n\n\n\n\n# Plot 2 (no facets or densities)\n#unsure what this is saying, is it saying to make a graph without these?\nggplot(weather, aes(x = temp3pm)) + \n  geom_bar()\n\n\n\n\n\n\n\n\n# Plot 3 (facets)\n#again, unsure what to do here\n\nReflection\n\nTemperatures tend to be highest, and most variable, in Uluru. There, they range from ~10 to ~45 with a typical temp around ~30 degrees.\nTemperatures tend to be lowest in Hobart. There, they range from ~5 to ~45 with a typical temp around ~15 degrees.\nWollongong temps are in between and are the least variable from day to day.\n\nSUBTLETIES: Defining fill or color by a variable\nHow we define the fill or color depends upon whether we’re defining it by a named color or by some variable in our dataset. For example:\n\ngeom___(fill = \"blue\")named colors are defined outside the aesthetics and put in quotes\ngeom___(aes(fill = variable)) or ggplot(___, aes(fill = variable))\ncolors/fills defined by a variable are defined inside the aesthetics\nExample 3\nLet’s consider Wollongong alone:\n\n# Don't worry about the syntax (we'll learn it soon)\nwoll &lt;- weather |&gt;\n  filter(location == \"Wollongong\") |&gt; \n  mutate(date = as.Date(date))  \n\n\n# How often does it raintoday?\n# Fill your geometric layer with the color blue.\nggplot(woll, aes(x = raintoday)) +\n  geom_bar(fill = \"blue\")\n\n\n\n\n\n\n\n\n# If it does raintoday, what does this tell us about raintomorrow?\n# Use your intuition first\nggplot(woll, aes(x = raintoday, fill = raintomorrow)) +\n  geom_density() +\n  facet_wrap(~ raintomorrow)\n\n\n\n\n\n\n\nholy shit this is ugly\n\n# Now compare different approaches\n\n# Default: stacked bars\nggplot(woll, aes(x = raintoday, fill = raintomorrow)) + \n  geom_bar()\n\n\n\n\n\n\n\n\n# Side-by-side bars\nggplot(woll, aes(x = raintoday, fill = raintomorrow)) + \n  geom_bar(position = \"dodge\")\n\n\n\n\n\n\n\n\n# Proportional bars\n# position = \"fill\" refers to filling the frame, nothing to do with the color-related fill\nggplot(woll, aes(x = raintoday, fill = raintomorrow)) + \n  geom_bar(position = \"fill\")\n\n\n\n\n\n\n\nReflection\nThere’s often not one “best plot”, but a combination of plots that provide a complete picture:\n\nThe stacked and side-by-side bars reflect that on most days, it does not rain.\nThe proportional / filled bars lose that information, but make it easier to compare proportions: it’s more likely to rain tomorrow if it also rains today.\nExample 4\nConstruct a plot that illustrates how 3pm temperatures (temp3pm) vary by date in Wollongong. Represent each day on the plot and use a curve/line to help highlight the trends.\n\n# THINK: What variable goes on the y-axis?\n# For the curve, try adding span = 0.5 to tweak the curvature\nggplot(woll, aes(x = date, y = temp3pm)) + \n  geom_point() + \n  geom_smooth(span = 0.5)\n\n\n\n\n\n\n\n\n# Instead of a curve that captures the general TREND,\n# draw a line that illustrates the movement of RAW temperatures from day to day\n# NOTE: We haven't learned this geom yet! Guess.\nggplot(woll, aes(y = temp3pm, x = date)) +\n  geom_point() +\n  geom_smooth(span = .01)\n\n\n\n\n\n\n\nNOTE: A line plot isn’t always appropriate! It can be useful in situations like this, when our data are chronological.\nReflection\nThere’s a seasonal / cyclic behavior in temperatures – they’re highest in January (around 23 degrees) and lowest in July (around 16 degrees). There are also some outliers – some abnormally hot and cold days.",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Multivariate Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-multi.html#new-stuff",
    "href": "ica/ica-multi.html#new-stuff",
    "title": "\n12  Multivariate Viz\n",
    "section": "\n12.2 New Stuff",
    "text": "12.2 New Stuff\nNext, let’s consider the entire weather data for all 3 locations. The addition of location adds a 3rd variable into our research questions:\n\nHow does the relationship between raintoday and raintomorrow vary by location?\nHow does the behavior of temp3pm over date vary by location?\nAnd so on.\n\nThus far, we’ve focused on the following components of a plot:\n\nsetting up a frame\n\nadding layers / geometric elements\nsplitting the plot into facets for different groups / categories\nchange the theme, e.g. axis labels, color, fill\n\nWe’ll have to think about all of this, along with scales. Scales change the color, fill, size, shape, or other properties according to the levels of a new variable. This is different than just assigning scale by, for example, color = \"blue\".\nWork on the examples below in your groups. Check in with your intuition! We’ll then discuss as a group as relevant.\nExample 5\n\n# Plot temp3pm vs temp9am\n# Change the code in order to indicate the location to which each data point corresponds\nggplot(weather, aes(y = temp3pm, x = temp9am, color = location)) + \n  geom_point() \n\n\n\n\n\n\n\n\n# Change the code in order to indicate the location to which each data point corresponds\n# AND identify the days on which it rained / didn't raintoday\nggplot(weather, aes(y = temp3pm, x = temp9am, color = location)) + \n  geom_point()\n\n\n\n\n\n\n\n\n# How many ways can you think to make that plot of temp3pm vs temp9am with info about location and rain?\n# Play around!\n\nExample 6\n\n# Change the code in order to construct a line plot of temp3pm vs date for each separate location (no points!)\nggplot(weather, aes(y = temp3pm, x = date, color = location)) + \n  geom_line()\n\n\n\n\n\n\n\nExample 7\n\n# Plot the relationship of raintomorrow & raintoday\n# Change the code in order to indicate this relationship by location\nggplot(weather, aes(x = raintoday, fill = raintomorrow)) + \n  geom_bar(position = \"fill\") +\n  facet_wrap(~ location)\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow to Not Get Overwhelmed?\n\n\n\nThere’s no end to the number and type of visualizations you could make. And it’s important to not just throw spaghetti at the wall until something sticks. FlowingData shows that one dataset can be visualized many ways, and makes good recommendations for data viz workflow, which we modify and build upon here:\n\nIdentify simple research questions.\nWhat do you want to understand about the variables or the relationships among them?\n\nStart with the basics and work incrementally.\n\nIdentify what variables you want to include in your plot and what structure these have (eg: categorical, quantitative, dates)\nStart simply. Build a plot of just 1 of these variables, or the relationship between 2 of these variables.\nSet up a plotting frame and add just one geometric layer at a time.\nStart tweaking: add whatever new variables you want to examine,\n\n\n\nAsk your plot questions.\n\nWhat questions does your plot answer? What questions are left unanswered by your plot?\nWhat new questions does your plot spark / inspire?\nDo you have the viz tools to answer these questions, or might you learn more?\n\n\nFocus.\nReporting a large number of visualizations can overwhelm the audience and obscure your conclusions. Instead, pick out a focused yet comprehensive set of visualizations.",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Multivariate Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-multi.html#exercises-required",
    "href": "ica/ica-multi.html#exercises-required",
    "title": "\n12  Multivariate Viz\n",
    "section": "\n12.3 Exercises (required)",
    "text": "12.3 Exercises (required)\nThe story\nThough far from a perfect assessment of academic preparedness, SAT scores have historically been used as one measurement of a state’s education system. The education dataset contains various education variables for each state:\n\n# Import and check out data\neducation &lt;- read.csv(\"https://mac-stat.github.io/data/sat.csv\")\nhead(education)\n\n       State expend ratio salary frac verbal math  sat  fracCat\n1    Alabama  4.405  17.2 31.144    8    491  538 1029   (0,15]\n2     Alaska  8.963  17.6 47.951   47    445  489  934 (45,100]\n3    Arizona  4.778  19.3 32.175   27    448  496  944  (15,45]\n4   Arkansas  4.459  17.1 28.934    6    482  523 1005   (0,15]\n5 California  4.992  24.0 41.078   45    417  485  902  (15,45]\n6   Colorado  5.443  18.4 34.571   29    462  518  980  (15,45]\n\n\nA codebook is provided by Danny Kaplan who also made these data accessible:\n\nExercise 1: SAT scores\nPart a\nConstruct a plot of how the average sat scores vary from state to state. (Just use 1 variable – sat not State!)\n\nggplot(education, aes(x = sat)) +\n  geom_density()\n\n\n\n\n\n\n\nPart b\nSummarize your observations from the plot. Comment on the basics: range, typical outcomes, shape. (Any theories about what might explain this non-normal shape?) The most typical outcomes are around the 900 and 1025 range, but I don’t know why its like this\nExercise 2: SAT Scores vs Per Pupil Spending & SAT Scores vs Salaries\nThe first question we’d like to answer is: Can the variability in sat scores from state to state be partially explained by how much a state spends on education, specifically its per pupil spending (expend) and typical teacher salary?\nPart a\n\n# Construct a plot of sat vs expend\n# Include a \"best fit linear regression model\" (HINT: method = \"lm\")\nggplot(education, aes(x = expend, y = sat)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\n\n\n\n\n\n\n\n\n# Construct a plot of sat vs salary\n# Include a \"best fit linear regression model\" (HINT: method = \"lm\")\nggplot(education, aes(x = salary, y = sat)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\n\n\n\n\n\n\n\nPart b\nWhat are the relationship trends between SAT scores and spending? Is there anything that surprises you?\nBoth spending and teacher salaries have a negative relationship, where the more money is spent the worse kids end up doing. I would have thought the relationship was positive\nExercise 3: SAT Scores vs Per Pupil Spending and Teacher Salaries\nConstruct one visualization of the relationship of sat with salary and expend. HINT: Start with just 2 variables and tweak that code to add the third variable. Try out a few things!\n\nggplot(education, aes(x = salary, y = sat, color = expend)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\n\n\n\n\n\n\n\nExercise 4: Another way to Incorporate Scale\nIt can be tough to distinguish color scales and size scales for quantitative variables. Another option is to discretize a quantitative variable, or basically cut it up into categories.\nConstruct the plot below. Check out the code and think about what’s happening here. What happens if you change “2” to “3”?\n\nggplot(education, aes(y = sat, x = salary, color = cut(expend, 2))) + \n  geom_point() + \n  geom_smooth(se = FALSE, method = \"lm\")\n\nDescribe the trivariate relationship between sat, salary, and expend.\nThe less money is spend on both salary and school budget, the higher sat scores chart\nExercise 5: Finally an Explanation\nIt’s strange that SAT scores seem to decrease with spending. But we’re leaving out an important variable from our analysis: the fraction of a state’s students that actually take the SAT. The fracCat variable indicates this fraction: low (under 15% take the SAT), medium (15-45% take the SAT), and high (at least 45% take the SAT).\nPart a\nBuild a univariate viz of fracCat to better understand how many states fall into each category.\n\nggplot(education, aes(x = sat, fill = fracCat)) +\n  geom_histogram()\n\n\n\n\n\n\n\nPart b\nBuild 2 bivariate visualizations that demonstrate the relationship between sat and fracCat. What story does your graphic tell and why does this make contextual sense?\n\nggplot(education, aes(x = sat, y = fracCat, fill = fracCat)) +\n  geom_boxplot()\n\n\n\n\n\n\nggplot(education, aes(x = sat, y = fracCat, fill = fracCat)) +\n  geom_violin()\n\n\n\n\n\n\n\nThese graphics show that schools with less students taking the SAT tend to have higher averages (likely because the average is built on less data)\nPart c\nMake a trivariate visualization that demonstrates the relationship of sat with expend AND fracCat. Highlight the differences in fracCat groups through color AND unique trend lines. What story does your graphic tell?\nDoes it still seem that SAT scores decrease as spending increases?\n\neducation &lt;- read.csv(\"https://mac-stat.github.io/data/sat.csv\")\nggplot(education, aes(x = expend, y = sat, color = fracCat)) +\n  geom_point() +\n  geom_smooth(se = FALSE, method = \"lm\")\n\n\n\n\n\n\n\nthese graphics show that while having less students increases the average sat score per school, spending more on schools will still result in higher averages within these groups. #### Part d {-}\nPutting all of this together, explain this example of Simpson’s Paradox. That is, why did it appear that SAT scores decrease as spending increases even though the opposite is true?\nBecause we only relied on two variables, and didn’t use all given to us.",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Multivariate Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-multi.html#exercises-optional",
    "href": "ica/ica-multi.html#exercises-optional",
    "title": "\n12  Multivariate Viz\n",
    "section": "\n12.4 Exercises (optional)",
    "text": "12.4 Exercises (optional)\nExercise 6: Heat Maps\nAs usual, we’ve only just scratched the surface! There are lots of other data viz techniques for exploring multivariate relationships. Let’s start with a heat map.\nPart a\nRun the chunks below. Check out the code, but don’t worry about every little detail! NOTES:\n\nThis is not part of the ggplot() grammar, making it a bit complicated.\nIf you’re curious about what a line in the plot does, comment it out (#) and check out what happens!\nIn the plot, for each state (row), each variable (column) is scaled to indicate whether the state has a relative high value (yellow), a relatively low value (purple), or something in between (blues/greens).\nYou can also play with the color scheme. Type ?cm.colors in the console to learn about various options.\nWe’ll improve the plot later, so don’t spend too much time trying to learn something from this plot.\n\n\n# Remove the \"State\" column and use it to label the rows\n# Then scale the variables\nplot_data &lt;- education |&gt; \n  column_to_rownames(\"State\") |&gt; \n  data.matrix() |&gt; \n  scale()\n\n# Load the gplots package needed for heatmaps\nlibrary(gplots)\n\n# Construct heatmap 1\nheatmap.2(plot_data,\n  dendrogram = \"none\",\n  Rowv = NA, \n  scale = \"column\",\n  keysize = 0.7, \n  density.info = \"none\",\n  col = hcl.colors(256), \n  margins = c(10, 20),\n  colsep = c(1:7), rowsep = (1:50), sepwidth = c(0.05, 0.05),\n  sepcolor = \"white\", trace = \"none\"\n)\n\n\n# Construct heatmap 2\nheatmap.2(plot_data,\n  dendrogram = \"none\",\n  Rowv = TRUE,             ### WE CHANGED THIS FROM NA TO TRUE\n  scale = \"column\",\n  keysize = 0.7, \n  density.info = \"none\",\n  col = hcl.colors(256), \n  margins = c(10, 20),\n  colsep = c(1:7), rowsep = (1:50), sepwidth = c(0.05, 0.05),\n  sepcolor = \"white\", trace = \"none\"\n)\n\n\n# Construct heatmap 3\nheatmap.2(plot_data,\n  dendrogram = \"row\",       ### WE CHANGED THIS FROM \"none\" TO \"row\"\n  Rowv = TRUE,            \n  scale = \"column\",\n  keysize = 0.7, \n  density.info = \"none\",\n  col = hcl.colors(256), \n  margins = c(10, 20),\n  colsep = c(1:7), rowsep = (1:50), sepwidth = c(0.05, 0.05),\n  sepcolor = \"white\", trace = \"none\"\n)\n\nPart b\nIn the final two plots, the states (rows) are rearranged by similarity with respect to these education metrics. The final plot includes a dendrogram which further indicates clusters of similar states. In short, states that have a shorter path to connection are more similar than others.\nPutting this all together, what insight do you gain about the education trends across U.S. states? Which states are similar? In what ways are they similar? Are there any outliers with respect to 1 or more of the education metrics?\nExercise 7: Star plots\nLike heat maps, star plots indicate the relative scale of each variable for each state. Thus, we can use star maps to identify similar groups of states, and unusual states!\nPart a\nConstruct and check out the star plot below. Note that each state has a “pie”, with each segment corresponding to a different variable. The larger a segment, the larger that variable’s value is in that state. For example:\n\nCheck out Minnesota. How does Minnesota’s education metrics compare to those in other states? What metrics are relatively high? Relatively low?\nWhat states appear to be similar? Do these observations agree with those that you gained from the heat map?\n\n\nstars(plot_data,\n  flip.labels = FALSE,\n  key.loc = c(10, 1.5),\n  cex = 1, \n  draw.segments = TRUE\n)\n\nPart b\nFinally, let’s plot the state stars by geographic location! What new insight do you gain here?!\n\nstars(plot_data,\n  flip.labels = FALSE,\n  locations = data.matrix(as.data.frame(state.center)),  # added external data to arrange by geo location\n  key.loc = c(-110, 28),\n  cex = 1, \n  draw.segments = TRUE\n)",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Multivariate Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-multi.html#solutions",
    "href": "ica/ica-multi.html#solutions",
    "title": "\n12  Multivariate Viz\n",
    "section": "\n12.5 Solutions",
    "text": "12.5 Solutions\n\nClick for Solutions\n\nlibrary(tidyverse)\n\n# Import data\nweather &lt;- read.csv(\"https://mac-stat.github.io/data/weather_3_locations.csv\") |&gt; \n  mutate(date = as.Date(date))  \n\n# Check out the first 6 rows\n# What are the units of observation?\nhead(weather)\n\n        date   location mintemp maxtemp rainfall evaporation sunshine\n1 2020-01-01 Wollongong    17.1    23.1        0          NA       NA\n2 2020-01-02 Wollongong    17.7    24.2        0          NA       NA\n3 2020-01-03 Wollongong    19.7    26.8        0          NA       NA\n4 2020-01-04 Wollongong    20.4    35.5        0          NA       NA\n5 2020-01-05 Wollongong    19.8    21.4        0          NA       NA\n6 2020-01-06 Wollongong    18.3    22.9        0          NA       NA\n  windgustdir windgustspeed winddir9am winddir3pm windspeed9am windspeed3pm\n1         SSW            39        SSW        SSE           20           15\n2         SSW            37          S        ENE           13           15\n3          NE            41        NNW        NNE            7           17\n4         SSW            78         NE        NNE           15           17\n5         SSW            57        SSW          S           31           35\n6          NE            35        ESE         NE           17           20\n  humidity9am humidity3pm pressure9am pressure3pm cloud9am cloud3pm temp9am\n1          69          64      1014.9      1014.0        8        1    19.1\n2          72          54      1020.1      1017.7        7        1    19.8\n3          72          71      1017.5      1013.0        6       NA    23.4\n4          77          69      1008.8      1003.9       NA       NA    24.5\n5          70          75      1018.9      1019.9       NA        7    20.7\n6          71          71      1021.2      1018.2       NA       NA    20.9\n  temp3pm raintoday risk_mm raintomorrow\n1    22.9        No     0.0           No\n2    23.6        No     0.0           No\n3    25.7        No     0.0           No\n4    26.7        No     0.0           No\n5    20.0        No     0.0           No\n6    22.6        No     0.8           No\n\n# How many data points do we have? \nnrow(weather)\n\n[1] 2367\n\n# What type of variables do we have?\nstr(weather)\n\n'data.frame':   2367 obs. of  24 variables:\n $ date         : Date, format: \"2020-01-01\" \"2020-01-02\" ...\n $ location     : chr  \"Wollongong\" \"Wollongong\" \"Wollongong\" \"Wollongong\" ...\n $ mintemp      : num  17.1 17.7 19.7 20.4 19.8 18.3 19.9 20.1 19.8 20.5 ...\n $ maxtemp      : num  23.1 24.2 26.8 35.5 21.4 22.9 25.6 23.2 23.1 25.4 ...\n $ rainfall     : num  0 0 0 0 0 0 0.8 1.6 0 0 ...\n $ evaporation  : num  NA NA NA NA NA NA NA NA NA NA ...\n $ sunshine     : num  NA NA NA NA NA NA NA NA NA NA ...\n $ windgustdir  : chr  \"SSW\" \"SSW\" \"NE\" \"SSW\" ...\n $ windgustspeed: int  39 37 41 78 57 35 44 41 39 56 ...\n $ winddir9am   : chr  \"SSW\" \"S\" \"NNW\" \"NE\" ...\n $ winddir3pm   : chr  \"SSE\" \"ENE\" \"NNE\" \"NNE\" ...\n $ windspeed9am : int  20 13 7 15 31 17 30 31 24 19 ...\n $ windspeed3pm : int  15 15 17 17 35 20 7 33 26 39 ...\n $ humidity9am  : int  69 72 72 77 70 71 76 77 76 79 ...\n $ humidity3pm  : int  64 54 71 69 75 71 72 76 79 76 ...\n $ pressure9am  : num  1015 1020 1018 1009 1019 ...\n $ pressure3pm  : num  1014 1018 1013 1004 1020 ...\n $ cloud9am     : int  8 7 6 NA NA NA NA 8 NA NA ...\n $ cloud3pm     : int  1 1 NA NA 7 NA NA NA NA NA ...\n $ temp9am      : num  19.1 19.8 23.4 24.5 20.7 20.9 22.9 21.3 21.2 23 ...\n $ temp3pm      : num  22.9 23.6 25.7 26.7 20 22.6 24.9 22.2 22.2 25.1 ...\n $ raintoday    : chr  \"No\" \"No\" \"No\" \"No\" ...\n $ risk_mm      : num  0 0 0 0 0 0.8 1.6 0 0 1 ...\n $ raintomorrow : chr  \"No\" \"No\" \"No\" \"No\" ...\n\n\nExample 1\n\nggplot(weather, aes(x = temp3pm)) + \n  geom_density()\n\n\n\n\n\n\n\nExample 2\n\n# Plot 1 (no facets & starting from a density plot of temp3pm)\nggplot(weather, aes(x = temp3pm, fill = location)) + \n  geom_density(alpha = 0.5)\n\n\n\n\n\n\n\n\n# Plot 2 (no facets or densities)\nggplot(weather, aes(y = temp3pm, x = location)) + \n  geom_boxplot()\n\n\n\n\n\n\n\n\n# Plot 3 (facets)\nggplot(weather, aes(x = temp3pm, fill = location)) + \n  geom_density(alpha = 0.5) + \n  facet_wrap(~ location)\n\n\n\n\n\n\n\nExample 3\n\n# How often does it raintoday?\n# Fill your geometric layer with the color blue.\nggplot(woll, aes(x = raintoday)) + \n  geom_bar(fill = \"blue\")\n\n\n\n\n\n\n\n\n# If it does raintoday, what does this tell us about raintomorrow?\n# Use your intuition first\nggplot(woll, aes(x = raintoday)) + \n  geom_bar(aes(fill = raintomorrow))\n\n\n\n\n\n\nggplot(woll, aes(x = raintoday, fill = raintomorrow)) + \n  geom_bar()\n\n\n\n\n\n\n\n\n# Now compare different approaches\n\n# Default: stacked bars\nggplot(woll, aes(x = raintoday, fill = raintomorrow)) + \n  geom_bar()\n\n\n\n\n\n\n\n\n# Side-by-side bars\nggplot(woll, aes(x = raintoday, fill = raintomorrow)) + \n  geom_bar(position = \"dodge\")\n\n\n\n\n\n\n\n\n# Proportional bars\n# position = \"fill\" refers to filling the frame, nothing to do with the color-related fill\nggplot(woll, aes(x = raintoday, fill = raintomorrow)) + \n  geom_bar(position = \"fill\")\n\n\n\n\n\n\n\nExample 4\n\n# THINK: What variable goes on the y-axis?\n# For the curve, try adding span = 0.5 to tweak the curvature\nggplot(woll, aes(y = temp3pm, x = date)) + \n  geom_point() + \n  geom_smooth(span = 0.5)\n\n\n\n\n\n\n\n\n# Instead of a curve that captures the general TREND,\n# draw a line that illustrates the movement of RAW temperatures from day to day\n# NOTE: We haven't learned this geom yet! Guess.\nggplot(woll, aes(y = temp3pm, x = date)) + \n  geom_line()\n\n\n\n\n\n\n\nExample 5\n\n# Plot temp3pm vs temp9am\n# Change the code in order to indicate the location to which each data point corresponds\nggplot(weather, aes(y = temp3pm, x = temp9am, color = location)) + \n  geom_point()\n\n\n\n\n\n\n\n\n# Change the code in order to indicate the location to which each data point corresponds\n# AND identify the days on which it rained / didn't raintoday\nggplot(weather, aes(y = temp3pm, x = temp9am, color = location)) + \n  geom_point() +\n  facet_wrap(~ raintoday)\n\n\n\n\n\n\n\n\n# How many ways can you think to make that plot of temp3pm vs temp9am with info about location and rain?\n# Play around!\n\nggplot(weather, aes(y = temp3pm, x = temp9am, color = location, shape = raintoday)) + \n  geom_point()\n\n\n\n\n\n\n\nExample 6\n\n# Change the code in order to construct a line plot of temp3pm vs date for each separate location (no points!)\nggplot(weather, aes(y = temp3pm, x = date, color = location)) + \n  geom_line()\n\n\n\n\n\n\n\nExample 7\n\n# Plot the relationship of raintomorrow & raintoday\n# Change the code in order to indicate this relationship by location\nggplot(weather, aes(x = raintoday, fill = raintomorrow)) + \n  geom_bar(position = \"fill\") + \n  facet_wrap(~ location)\n\n\n\n\n\n\n\nExercise 1: SAT scores\nPart a\n\n# A histogram would work too!\nggplot(education, aes(x = sat)) + \n  geom_density()\n\n\n\n\n\n\n\nPart b\naverage SAT scores range from roughly 800 to 1100. They appear bi-modal.\nExercise 2: SAT Scores vs Per Pupil Spending & SAT Scores vs Salaries\nPart a\n\n# Construct a plot of sat vs expend\n# Include a \"best fit linear regression model\"\nggplot(education, aes(y = sat, x = expend)) + \n  geom_point() + \n  geom_smooth(method = \"lm\")\n\n\n\n\n\n\n\n\n# Construct a plot of sat vs salary\n# Include a \"best fit linear regression model\"\nggplot(education, aes(y = sat, x = salary)) + \n  geom_point() + \n  geom_smooth(method = \"lm\")\n\n\n\n\n\n\n\nPart b\nThe higher the student expenditures and teacher salaries, the worse the SAT performance.\nExercise 3: SAT Scores vs Per Pupil Spending and Teacher Salaries\n\nggplot(education, aes(y = sat, x = salary, color = expend)) + \n  geom_point() + \n  geom_smooth(method = \"lm\")\n\n\n\n\n\n\n\nExercise 4: Another Way to Incorporate Scale\n\nggplot(education, aes(y = sat, x = salary, color = cut(expend, 2))) + \n  geom_point() + \n  geom_smooth(se = FALSE, method = \"lm\")\n\n\n\n\n\n\nggplot(education, aes(y = sat, x = salary, color = cut(expend, 3))) + \n  geom_point() + \n  geom_smooth(se = FALSE, method = \"lm\")\n\n\n\n\n\n\n\nStates with lower salaries and expenditures tend to have higher SAT scores.\nExercise 5: Finally an Explanation\nPart a\n\nggplot(education, aes(x = fracCat)) + \n  geom_bar()\n\n\n\n\n\n\n\nPart b\nThe more students in a state that take the SAT, the lower the average scores tend to be. This is probably related to self-selection.\n\nggplot(education, aes(x = sat, fill = fracCat)) + \n  geom_density(alpha = 0.5)\n\n\n\n\n\n\n\nPart c\nWhen we control for the fraction of students that take the SAT, SAT scores increase with expenditure.\n\nggplot(education, aes(y = sat, x = expend, color = fracCat)) + \n  geom_point() + \n  geom_smooth(method = \"lm\")\n\n\n\n\n\n\n\nPart d\nStudent participation tends to be lower among states with lower expenditures (which are likely also the states with higher ed institutions that haven’t historically required the SAT). Those same states tend to have higher SAT scores because of the self-selection of who participates.\nExercise 6: Heat Maps\nPart a\n\n# Remove the \"State\" column and use it to label the rows\n# Then scale the variables\nplot_data &lt;- education |&gt; \n  column_to_rownames(\"State\") |&gt; \n  data.matrix() |&gt; \n  scale()\n\n# Load the gplots package needed for heatmaps\nlibrary(gplots)\n\n# Construct heatmap 1\nheatmap.2(plot_data,\n  dendrogram = \"none\",\n  Rowv = NA, \n  scale = \"column\",\n  keysize = 0.7, \n  density.info = \"none\",\n  col = hcl.colors(256), \n  margins = c(10, 20),\n  colsep = c(1:7), rowsep = (1:50), sepwidth = c(0.05, 0.05),\n  sepcolor = \"white\", trace = \"none\"\n)\n\n\n\n\n\n\n\n\n# Construct heatmap 2\nheatmap.2(plot_data,\n  dendrogram = \"none\",\n  Rowv = TRUE,             ### WE CHANGED THIS FROM NA TO TRUE\n  scale = \"column\",\n  keysize = 0.7, \n  density.info = \"none\",\n  col = hcl.colors(256), \n  margins = c(10, 20),\n  colsep = c(1:7), rowsep = (1:50), sepwidth = c(0.05, 0.05),\n  sepcolor = \"white\", trace = \"none\"\n)\n\n\n\n\n\n\n\n\n# Construct heatmap 3\nheatmap.2(plot_data,\n  dendrogram = \"row\",       ### WE CHANGED THIS FROM \"none\" TO \"row\"\n  Rowv = TRUE,            \n  scale = \"column\",\n  keysize = 0.7, \n  density.info = \"none\",\n  col = hcl.colors(256), \n  margins = c(10, 20),\n  colsep = c(1:7), rowsep = (1:50), sepwidth = c(0.05, 0.05),\n  sepcolor = \"white\", trace = \"none\"\n)\n\n\n\n\n\n\n\nPart b\n\nSimilar values in verbal, math, and sat.\nHigh contrast (an inverse relationship) verbal/math/sat scores and the fraction of students that take the SAT.\nOutliers of Utah and California in ratio (more students per teacher).\nWhile grouped, fraction and salary are not as similar to each other as the sat scores; it is also interesting to notice states that have high ratios have generally low expenditures per student.\nExercise 7: Star Plots\nPart a\nMN is high on the SAT performance related metrics and low on everything else. MN is similar to Iowa, Kansas, Mississippi, Missouri, the Dakotas…\n\nstars(plot_data,\n  flip.labels = FALSE,\n  key.loc = c(10, 1.5),\n  cex = 1, \n  draw.segments = TRUE\n)\n\n\n\n\n\n\n\nPart b\nWhen the states are in geographical ordering, we’d notice more easily that states in similar regions of the U.S. have similar patterns of these variables.\n\nstars(plot_data,\n  flip.labels = FALSE,\n  locations = data.matrix(as.data.frame(state.center)),  # added external data to arrange by geo location\n  key.loc = c(-110, 28),\n  cex = 1, \n  draw.segments = TRUE\n)",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Multivariate Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-spatial.html",
    "href": "ica/ica-spatial.html",
    "title": "\n13  Spatial Viz\n",
    "section": "",
    "text": "13.1 Review\nIn the previous activity, we explored a Simpson’s Paradox–it seemed that - states with higher spending… - tend to have lower average SAT scores.\nBUT this was explained by a confounding (aka omitted and lurking) variable which is the % of students in a state that take the SAT. Hence,\nThus, when controlling for the % of students that take the SAT, more spending is correlated with higher scores.\nLet’s explore a Simpson’s paradox related to Mac!\nBack in the 2000s, Macalester invested in insulating a few campus-owned houses, with the hopes of leading to energy savings.  Former Mac Prof Danny Kaplan accessed monthly data on energy use and other info for these addresses, before and after renovations:\n# Load tidyverse package for plotting and wrangling\nlibrary(tidyverse)\n\n# Import the data and only keep 2 addresses\nenergy &lt;- read.csv(\"https://mac-stat.github.io/data/MacNaturalGas.csv\") |&gt; \n  mutate(date = as.Date(paste0(month, \"/1/\", year), \"%m/%d/%Y\")) |&gt; \n  filter(address != \"c\")\n\n# Check it out\nhead(energy)\n\n  month year  price therms hdd address renovated       date\n1     6 2005  35.21     21   0       a        no 2005-06-01\n2     7 2005  37.37     21   0       a        no 2005-07-01\n3     8 2005  36.93     21   3       a        no 2005-08-01\n4     9 2005  62.36     39  61       a        no 2005-09-01\n5    10 2005 184.15    120 416       a        no 2005-10-01\n6    11 2005 433.35    286 845       a        no 2005-11-01\nThe part of dataset codebook is below:",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Spatial Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-spatial.html#review",
    "href": "ica/ica-spatial.html#review",
    "title": "\n13  Spatial Viz\n",
    "section": "",
    "text": "States with higher spending…\ntend to have a higher % of students of students that take the SAT…\nwhich then “leads to” lower average SAT scores.\n\n\n\n\n\n\n\n\n\n\n\n\nvariable\nmeaning\n\n\n\ntherms\na measure of energy use–the more energy used, the larger the therms\n\n\naddress\na or b\n\n\nrenovated\nwhether the location had been renovated, yes or no\n\n\nmonth\nfrom 1 (January) to 12 (December)\n\n\nhdd\nmonthly heating degree days. A proxy measure of outside temperatures–the higher the hdd, the COLDER it was outside",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Spatial Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-spatial.html#examples",
    "href": "ica/ica-spatial.html#examples",
    "title": "\n13  Spatial Viz\n",
    "section": "\n13.2 Examples",
    "text": "13.2 Examples\n\n\n\n\n\n\nInstructions\n\n\n\n\nConstruct a plot that addresses each research question\nInclude a 1-sentence summary of the plot.\n\n\n\nExample 1\nWhat was range in, and typical, energy used each month, as measured by therms? How does this differ by address?\n\nggplot(energy, aes(x = therms, fill = address)) +\n  geom_density(alpha = .05)\n\n\n\n\n\n\n\nExample 2\nHow did energy use (therms) change over time (date) at the two addresses?\n\nggplot(energy, aes(x = date, y = therms, color = address)) +\n  geom_point()\n\n\n\n\n\n\n\nExample 3\nHow did the typical energy use (therms) at the two addresses change before and after they were renovated?\n\nggplot(energy, aes(x = therms, fill = address)) +\n  geom_boxplot() +\n  facet_wrap(~ renovated)\n\n\n\n\n\n\n\nExample 4\nThat seems unfortunate that energy usage went up after renovations. But also fishy.\nTake 5 minutes in your groups to try and explain what’s going on here. Think: What confounding, lurking, or omitted variable related to energy usage are we ignoring here? Try to make some plots to prove your point.\n\nggplot(energy, aes(y = hdd, x = renovated, fill = address)) + \n  geom_boxplot() + \n  facet_wrap(~ address)\n\n\n\n\n\n\n\nExample 5\nLet’s summarize the punchlines by filling in the ???. It seemed that:\n\nAfter renovation…\nenergy use increased.\n\nBUT this was explained by a confounding or omitted or lurking variable: ???\n\nAfter renovation…\nThere were more colder days than before rennovation\nwhich then leads to higher energy use.\n\nThus, when controlling for outside temperature, renovations led to decreased energy use.",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Spatial Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-spatial.html#new-stuff",
    "href": "ica/ica-spatial.html#new-stuff",
    "title": "\n13  Spatial Viz\n",
    "section": "\n13.3 New stuff",
    "text": "13.3 New stuff\nTypes of spatial viz:\n\nPoint Maps: plotting locations of individual observations\nexample: bigfoot sightings\nContour Maps: plotting the density or distribution of observations (not the individual observations themselves)\n\nChoropleth Maps: plotting outcomes in different regions\n\nNYT article on effects of redlining\nMinnesota Reformer article on how Mpls / St Paul voted on 2021 ballot measures related to mayoral, policing, and rent policies\n\n\n\nThese spatial maps can be static or dynamic/interactive.",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Spatial Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-spatial.html#exercises",
    "href": "ica/ica-spatial.html#exercises",
    "title": "\n13  Spatial Viz\n",
    "section": "\n13.4 Exercises",
    "text": "13.4 Exercises\n\n13.4.1 Preview\nYou’ll explore some R spatial viz tools below. In general, there are two important pieces to every map:\nPiece 1: A dataset\nThis dataset must include either:\n\nlocation coordinates for your points of interest (for point maps); or\nvariable outcomes for your regions of interest (for choropleth maps)\n\n\nPiece 2: A background map\nWe need latitude and longitude coordinates to specify the boundaries for your regions of interest (eg: countries, states). This is where it gets really sticky!\n\nCounty-level, state-level, country-level, continent-level info live in multiple places.\nWhere we grab this info can depend upon whether we want to make a point map or a choropleth map. (The background maps can be used somewhat interchangeably, but it requires extra code :/)\nWhere we grab this info can also depend upon the structure of our data and how much data wrangling / cleaning we’re up for. For choropleth maps, the labels of regions in our data must match those in the background map. For example, if our data labels states with their abbreviations (eg: MN) and the background map refers to them as full names in lower case (eg: minnesota), we have to wrangle our data so that it matches the background map.\n\nIn short, the code for spatial viz gets very specialized. The goal of these exercises is to:\n\nplay around and experience the wide variety of spatial viz tools out there\nunderstand the difference between point maps and choropleth maps\nhave fun\n\nYou can skip around as you wish and it’s totally fine if you don’t finish everything. Just come back at some point to play around.\nPart 1: Interactive points on a map with leaflet\n\nLeaflet is an open-source JavaScript library for creating maps. We can use it inside R through the leaflet package.\nThis uses a different plotting framework than ggplot2, but still has a tidyverse feel (which will become more clear as we learn other tidyverse tools!).\nThe general steps are as follows:\n\nCreate a map widget by calling leaflet() and telling it the data to use.\nAdd a base map using addTiles() (the default) or addProviderTiles().\nAdd layers to the map using layer functions (e.g. addMarkers(), addPolygons()).\nPrint the map widget to display it.\nExercise 1: A leaflet with markers / points\nEarlier this semester, I asked for the latitude and longitude of one of your favorite places. I rounded these to the nearest whole number, so that they’re near to but not exactly at those places. Let’s load the data and map it!\n\nfave_places &lt;- read.csv(\"https://ajohns24.github.io/data/112/our_fave_places.csv\")\n\n# Check it out\nhead(fave_places)\n\n  latitude longitude\n1       46      -123\n2       33        52\n3       48       -90\n4       36      -112\n5       59        25\n6       39      -106\n\n\nPart a\nYou can use a “two-finger scroll” to zoom in and out.\n\n# Load the leaflet package\nlibrary(leaflet)\n\n# Just a plotting frame\nleaflet(data = fave_places)\n\n\n\n\n\n\n# Now what do we have?\nleaflet(data = fave_places) |&gt; \n  addTiles()\n\n\n\n\n\n\n# Now what do we have?\n# longitude and latitude refer to the variables in our data\nleaflet(data = fave_places) |&gt; \n  addTiles() |&gt; \n  addMarkers(lng = ~longitude, lat = ~latitude)\n\n\n\n\n\n\n# Since we named them \"longitude\" and \"latitude\", the function\n# automatically recognizes these variables. No need to write them!\nleaflet(data = fave_places) |&gt; \n  addTiles() |&gt; \n  addMarkers()\n\n\n\n\n\nPart b\nPLAY AROUND! This map is interactive. Zoom in on one location. Keep zooming – what level of detail can you get into? How does that detail depend upon where you try to zoom in (thus what are the limitations of this tool)?\nExercise 2: Details\nWe can change all sorts of details in leaflet maps.\n\n# Load package needed to change color\nlibrary(gplots)\n\n# We can add colored circles instead of markers at each location\nleaflet(data = fave_places) |&gt; \n  addTiles() |&gt; \n  addCircles(color = col2hex(\"red\"))\n\n\n\n\n\n\n# We can change the background\n# Mark locations with yellow dots\n# And connect the dots, in their order in the dataset, with green lines\n# (These green lines don't mean anything here, but would if this were somebody's travel path!)\nleaflet(data = fave_places) |&gt;\n  addProviderTiles(\"USGS\") |&gt;\n  addCircles(weight = 10, opacity = 1, color = col2hex(\"yellow\")) |&gt;\n  addPolylines(\n    lng = ~longitude,\n    lat = ~latitude,\n    color = col2hex(\"green\")\n  )\n\n\n\n\n\nIn general:\n\naddProviderTiles() changes the base map.\nTo explore all available provider base maps, type providers in the console. (Though some don’t work :/)\n\nUse addMarkers() or addCircles() to mark locations. Type ?addControl into the console to pull up a help file which summarizes the aesthetics of these markers and how you can change them. For example:\n\n\nweight = how thick to make the lines, points, pixels\n\nopacity = transparency (like alpha in ggplot2)\ncolors need to be in “hex” form. We used the col2hex() function from the gplots library to do that\n\n\nExercise 3: Your turn\nThe starbucks data, compiled by Danny Kaplan, contains information about every Starbucks in the world at the time the data were collected, including Latitude and Longitude:\n\n# Import starbucks location data\nstarbucks &lt;- read.csv(\"https://mac-stat.github.io/data/starbucks.csv\")\n\nLet’s focus on only those in Minnesota for now:\n\n# Don't worry about the syntax\nstarbucks_mn &lt;- starbucks |&gt;   \n  filter(Country == \"US\", State.Province == \"MN\")\n\nCreate a leaflet map of the Starbucks locations in Minnesota. Keep it simple – go back to Exercise 1 for an example.\n\nleaflet(data = starbucks_mn) |&gt; \n  addTiles() |&gt; \n  addMarkers()\n\n\n\n\n\nPart 2: Static points on a map\nLeaflet is very powerful and fun. But:\n\nIt’s not great when we have lots of points to map – it takes lots of time.\nIt makes good interactive maps, but we often need a static map (eg: we can not print interactive maps!).\n\nLet’s explore how to make point maps with ggplot(), not leaflet().\nExercise 3: A simple scatterplot\nLet’s start with the ggplot() tools we already know. Construct a scatterplot of all starbucks locations, not just those in Minnesota, with:\n\nLatitude and Longitude coordinates (which goes on the y-axis?!)\nMake the points transparent (alpha = 0.2) and smaller (size = 0.2)\n\nIt’s pretty cool that the plots we already know can provide some spatial context. But what don’t you like about this plot? does not put information into easily understood context\n\nggplot(starbucks, aes(x = Latitude, y = Longitude)) +\n  geom_point()\n\n\n\n\n\n\n\nExercise 4: Adding a country-level background\nLet’s add a background map of country-level boundaries.\nPart a\nFirst, we can grab country-level boundaries from the rnaturalearth package.\n\n# Load the package\nlibrary(rnaturalearth)\n\n# Get info about country boundaries across the world\n# in a \"sf\" or simple feature format\nworld_boundaries &lt;- ne_countries(returnclass = \"sf\")\n\nIn your console, type world_boundaries to check out what’s stored there. Don’t print it our in your Rmd – printing it would be really messy there (even just the head()).\nPart b\nRun the chunks below to build up a new map.\n\n# What does this code produce?\n# What geom are we using for the point map?\nggplot(world_boundaries) + \n  geom_sf()\n\n\n\n\n\n\n\n\n# Load package needed to change map theme\nlibrary(mosaic)\n\n# Add a point for each Starbucks\n# NOTE: The Starbucks info is in our starbucks data, not world_boundaries\n# How does this change how we use geom_point?!\nggplot(world_boundaries) + \n  geom_sf() + \n  geom_point(\n    data = starbucks,\n    aes(x = Longitude, y = Latitude),\n    alpha = 0.3, size = 0.2, color = \"darkgreen\"\n  ) +\n  theme_map()\n\n\n\n\n\n\n\nPart c\nSummarize what you learned about Starbucks from this map. Starbucks is primarily located in North America, Western Europe, and East Asia, with locations being peppered in South America and Southeast Asia.\nExercise 5: Zooming in on some countries\nInstead of world_boundaries &lt;- ne_countries(returnclass = 'sf') we could zoom in on…\n\nthe continent of Africa: ne_countries(continent = 'Africa', returnclass = 'sf')\n\na set of countries: ne_countries(country = c('france', 'united kingdom', 'germany'), returnclass = 'sf')\n\nboundaries within a country: ne_states(country = 'united states of america', returnclass = 'sf')\n\n\nOur goal here will be to map the Starbucks locations in Canada, Mexico, and the US.\nPart a\nTo make this map, we again need two pieces of information.\n\nData on Starbucks for only Canada, Mexico, and the US, labeled as “CA”, “MX”, “US” in the starbucks data.\n\n\n# We'll learn this syntax soon! Don't worry about it now.\nstarbucks_cma &lt;- starbucks |&gt; \n  filter(Country %in% c('CA', 'MX', 'US'))\n\n\nA background map of state- and national-level boundaries in Canada, Mexico, and the US. This requires ne_states() in the rnaturalearth package where the countries are labeled ‘canada’, ‘mexico’, ‘united states of america’.\n\n\ncma_boundaries &lt;- ne_states(\n  country = c(\"canada\", \"mexico\", \"united states of america\"),\n  returnclass = \"sf\")\n\nPart b\nMake the map!\n\n# Just the boundaries\nggplot(cma_boundaries) + \n  geom_sf()\n\n\n\n\n\n\n\n\n# Add the points\n# And zoom in\nggplot(cma_boundaries) + \n  geom_sf() + \n  geom_point(\n    data = starbucks_cma,\n    aes(x = Longitude, y = Latitude),\n    alpha = 0.3,\n    size = 0.2,\n    color = \"darkgreen\"\n  ) +\n  coord_sf(xlim = c(-179.14, -50)) +\n  theme_map()\n\n\n\n\n\n\n\nExercise 6: A state and county-level map\nLet’s get an even higher resolution map of Starbucks locations within the states of Minnesota, Wisconsin, North Dakota, and South Dakota, with a background map at the county-level.\nPart a\nTo make this map, we again need two pieces of information.\n\nData on Starbucks for only the states of interest.\n\n\nstarbucks_midwest &lt;- starbucks |&gt; \n  filter(State.Province %in% c(\"MN\", \"ND\", \"SD\", \"WI\"))\n\n\nA background map of state- and county-level boundaries in these states. This requires st_as_sf() in the sf package, and map() in the maps package, where the countries are labeled ‘minnesota’, ‘north dakota’, etc.\n\n\n# Load packages\nlibrary(sf)\nlibrary(maps)\n\n# Get the boundaries\nmidwest_boundaries &lt;- st_as_sf(\n  maps::map(\"county\",\n            region = c(\"minnesota\", \"wisconsin\", \"north dakota\", \"south dakota\"), \n            fill = TRUE, plot = FALSE))\n\n# Check it out\nhead(midwest_boundaries)\n\nSimple feature collection with 6 features and 1 field\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -96.81268 ymin: 45.05167 xmax: -93.01397 ymax: 48.53526\nGeodetic CRS:  +proj=longlat +ellps=clrk66 +no_defs +type=crs\n                                     ID                           geom\nminnesota,aitkin       minnesota,aitkin MULTIPOLYGON (((-93.03689 4...\nminnesota,anoka         minnesota,anoka MULTIPOLYGON (((-93.51817 4...\nminnesota,becker       minnesota,becker MULTIPOLYGON (((-95.14537 4...\nminnesota,beltrami   minnesota,beltrami MULTIPOLYGON (((-95.58655 4...\nminnesota,benton       minnesota,benton MULTIPOLYGON (((-93.77027 4...\nminnesota,big stone minnesota,big stone MULTIPOLYGON (((-96.10794 4...\n\n\nPart b\nAdjust the code below to make the plot! Remove the # to run it.\n\n ggplot(midwest_boundaries) + \n   geom_sf() + \n   geom_point(\n     data = starbucks_midwest,\n     aes(x = Longitude, y = Latitude),\n     alpha = 0.7,\n     size = 0.5, \n     color = 'darkgreen'\n   ) + \n   theme_map()\n\n\n\n\n\n\n\nExercise 7: Contour maps\nEspecially when there are lots of point locations, and those locations start overlapping on a map, it can be tough to visualize areas of higher density. Consider the Starbucks locations in Canada, Mexico, and the US that we mapped earlier:\n\n# Point map (we made this earlier)\nggplot(cma_boundaries) + \n  geom_sf() + \n  geom_point(\n    data = starbucks_cma,\n    aes(x = Longitude, y = Latitude),\n    alpha = 0.3,\n    size = 0.2,\n    color = \"darkgreen\"\n  ) +\n  coord_sf(xlim = c(-179.14, -50), ylim = c(14.54, 83.11)) +\n  theme_map()\n\n\n\n\n\n\n\nNow check out the contour map.\n\n# What changed in the plot?\n# What changed in our code?!\nggplot(cma_boundaries) + \n  geom_sf() + \n  geom_density_2d(\n    data = starbucks_cma,\n    aes(x = Longitude, y = Latitude),\n    size = 0.2,\n    color = \"darkgreen\"\n  ) +\n  coord_sf(xlim = c(-179.14, -50), ylim = c(14.54, 83.11)) +\n  theme_map()\n\n\n\n\n\n\n\nPart 3: Choropleth maps\nSpatial data isn’t always in the form of point locations! For example, recall the state and county-level data on presidential elections.\n\nelections_by_state &lt;-  read.csv(\"https://mac-stat.github.io/data/election_2020_by_state.csv\")\nelections_by_counties &lt;- read.csv(\"https://mac-stat.github.io/data/election_2020_county.csv\")\n\nIn these datasets, we’re interested in the overall election outcome by region (state or county), not the specific geographic location of some observation. Let’s wrangle our data first. We’ll focus on just a few variables of interest, and create a new variable (repub_20_categories) that discretizes the repub_pct_20 variable into increments of 5 percentage points (for states) or 10 percentage points (for counties):\n\n# Don't worry about the code!\n\nelections_by_state &lt;- elections_by_state |&gt; \n  filter(state_abbr != \"DC\") |&gt; \n  select(state_name, state_abbr, repub_pct_20) |&gt; \n  mutate(repub_20_categories = \n           cut(repub_pct_20, \n               breaks = seq(30, 70, by = 5), \n               labels = c(\"30-34\", \"35-39\", \"40-44\", \"45-49\",\n                          \"50-54\", \"55-59\", \"60-64\", \"65-70\"), \n               include.lowest = TRUE))\n\nelections_by_counties &lt;- elections_by_counties |&gt; \n  select(state_name, state_abbr, county_name, county_fips,\n          repub_pct_20, median_age, median_rent) |&gt; \n  mutate(repub_20_categories = \n           cut(repub_pct_20, \n               breaks = seq(0, 100, by = 10),\n               labels = c(\"0-9\", \"10-19\", \"20-29\", \"30-39\", \"40-49\",\n                          \"50-59\", \"60-69\", \"70-79\", \"80-89\", \"90-100\"),\n               include.lowest = TRUE))\n\nExercise 8: State-level choropleth maps\nLet’s map the 2020 Republican support in each state, repub_pct_20.\nPart a\nWe again need two pieces of information.\n\nData on elections in each state, which we already have: elections_by_state.\nA background map of state boundaries in the US. The boundaries we used for point maps don’t work here. (Optional detail: they’re sf objects and we now need a data.frame object.) Instead, we can use the map_data() function from the ggplot2 package:\n\n\n# Get the latitude and longitude coordinates of state boundaries\nstates_map &lt;- map_data(\"state\")\n\n# Check it out\nhead(states_map)\n\n       long      lat group order  region subregion\n1 -87.46201 30.38968     1     1 alabama      &lt;NA&gt;\n2 -87.48493 30.37249     1     2 alabama      &lt;NA&gt;\n3 -87.52503 30.37249     1     3 alabama      &lt;NA&gt;\n4 -87.53076 30.33239     1     4 alabama      &lt;NA&gt;\n5 -87.57087 30.32665     1     5 alabama      &lt;NA&gt;\n6 -87.58806 30.32665     1     6 alabama      &lt;NA&gt;\n\n\nPause\nImportant detail: Note that the region variable in states_map, and the state_name variable in elections_by_state both label states by the full name in lower case letters. This is critical to the background map and our data being able to communicate.\n\nhead(states_map)\n\n       long      lat group order  region subregion\n1 -87.46201 30.38968     1     1 alabama      &lt;NA&gt;\n2 -87.48493 30.37249     1     2 alabama      &lt;NA&gt;\n3 -87.52503 30.37249     1     3 alabama      &lt;NA&gt;\n4 -87.53076 30.33239     1     4 alabama      &lt;NA&gt;\n5 -87.57087 30.32665     1     5 alabama      &lt;NA&gt;\n6 -87.58806 30.32665     1     6 alabama      &lt;NA&gt;\n\nhead(elections_by_state) \n\n   state_name state_abbr repub_pct_20 repub_20_categories\n1     alabama         AL        62.03               60-64\n2    arkansas         AR        62.40               60-64\n3     arizona         AZ        49.06               45-49\n4  california         CA        34.33               30-34\n5    colorado         CO        41.90               40-44\n6 connecticut         CT        39.21               35-39\n\n\nPart b\nNow map repub_pct_20 by state.\n\n# Note where the dataset, elections_by_state, is used\n# Note where the background map, states_map, is used\nggplot(elections_by_state, aes(map_id = state_name, fill = repub_pct_20)) +\n  geom_map(map = states_map) +\n  expand_limits(x = states_map$long, y = states_map$lat) +\n  theme_map() \n\n\n\n\n\n\n\n\n# Make it nicer!\nggplot(elections_by_state, aes(map_id = state_name, fill = repub_pct_20)) +\n  geom_map(map = states_map) +\n  expand_limits(x = states_map$long, y = states_map$lat) +\n  theme_map() + \n  scale_fill_gradientn(name = \"% Republican\", colors = c(\"blue\", \"purple\", \"red\"), values = scales::rescale(seq(0, 100, by = 5)))\n\n\n\n\n\n\n\nIt’s not easy to get fine control over the color scale for the quantitative repub_pct_20 variable. Instead, let’s plot the discretized version, repub_20_categories:\n\nggplot(elections_by_state, aes(map_id = state_name, fill = repub_20_categories)) +\n  geom_map(map = states_map) +\n  expand_limits(x = states_map$long, y = states_map$lat) +\n  theme_map()\n\n\n\n\n\n\n\n\n# Load package needed for refining color palette\nlibrary(RColorBrewer)\n\n# Now fix the colors\nggplot(elections_by_state, aes(map_id = state_name, fill = repub_20_categories)) +\n  geom_map(map = states_map) +\n  expand_limits(x = states_map$long, y = states_map$lat) +\n  theme_map() + \n  scale_fill_manual(values = rev(brewer.pal(8, \"RdBu\")), name = \"% Republican\")\n\n\n\n\n\n\n\nPart c\nWe can add other layers, like points, on top of a choropleth map. Add a Starbucks layer! Do you notice any relationship between Starbucks and elections? starbucks tend to be in democrat areas Or are we just doing things at this point? ;)\n\n# Get only the starbucks data from the US\nstarbucks_us &lt;- starbucks |&gt; \n  filter(Country == \"US\")\n\n# Map it\nggplot(elections_by_state, aes(map_id = state_name, fill = repub_20_categories)) +\n  geom_map(map = states_map) +\n  geom_point(\n    data = starbucks_us,\n    aes(x = Longitude, y = Latitude),\n    size = 0.05,\n    alpha = 0.2,\n    inherit.aes = FALSE\n  ) +\n  expand_limits(x = states_map$long, y = states_map$lat) +\n  theme_map() + \n  scale_fill_manual(values = rev(brewer.pal(8, \"RdBu\")), name = \"% Republican\")\n\n\n\n\n\n\n\nDetails (if you’re curious)\n\n\nmap_id is a required aesthetic for geom_map().\n\nIt specifies which variable in our dataset indicates the region (here state_name).\nIt connects this variable (state_name) to the region variable in our mapping background (states_map). These variables must have the same possible outcomes in order to be matched up (alabama, alaska, arizona,…).\n\n\n\nexpand_limits() assures that the map covers the entire area it’s supposed to, by pulling longitudes and latitudes from the states_map.\nPart d\nWe used geom_sf() for point maps. What geom do we use for choropleth maps? “geom_map()”\nExercise 9: County-level choropleth maps\nLet’s map the 2020 Republican support in each county.\nPart a\nWe again need two pieces of information.\n\nData on elections in each county, which we already have: elections_by_county.\nA background map of county boundaries in the US, stored in the county_map dataset in the socviz package:\n\n\n# Get the latitude and longitude coordinates of county boundaries\nlibrary(socviz)\ndata(county_map) \n\n# Check it out\nhead(county_map)\n\n     long      lat order  hole piece            group    id\n1 1225889 -1275020     1 FALSE     1 0500000US01001.1 01001\n2 1235324 -1274008     2 FALSE     1 0500000US01001.1 01001\n3 1244873 -1272331     3 FALSE     1 0500000US01001.1 01001\n4 1244129 -1267515     4 FALSE     1 0500000US01001.1 01001\n5 1272010 -1262889     5 FALSE     1 0500000US01001.1 01001\n6 1276797 -1295514     6 FALSE     1 0500000US01001.1 01001\n\n\nPause\nImportant detail: We officially have a headache. Our county_map refers to each county by a 5-number id. Our elections_by_counties data refers to each county by a county_fips code, which is mostly the same as id, BUT drops any 0’s at the beginning of the code.\n\nhead(county_map)\n\n     long      lat order  hole piece            group    id\n1 1225889 -1275020     1 FALSE     1 0500000US01001.1 01001\n2 1235324 -1274008     2 FALSE     1 0500000US01001.1 01001\n3 1244873 -1272331     3 FALSE     1 0500000US01001.1 01001\n4 1244129 -1267515     4 FALSE     1 0500000US01001.1 01001\n5 1272010 -1262889     5 FALSE     1 0500000US01001.1 01001\n6 1276797 -1295514     6 FALSE     1 0500000US01001.1 01001\n\nhead(elections_by_counties)\n\n  state_name state_abbr    county_name county_fips repub_pct_20 median_age\n1    Alabama         AL Autauga County        1001        71.44       37.5\n2    Alabama         AL Baldwin County        1003        76.17       41.5\n3    Alabama         AL Barbour County        1005        53.45       38.3\n4    Alabama         AL    Bibb County        1007        78.43       39.4\n5    Alabama         AL  Blount County        1009        89.57       39.6\n6    Alabama         AL Bullock County        1011        24.84       39.6\n  median_rent repub_20_categories\n1         668               70-79\n2         693               70-79\n3         382               50-59\n4         351               70-79\n5         403               80-89\n6         276               20-29\n\n\nThis just means that we have to wrangle the data so that it can communicate with the background map.\n\n# Add 0's at the beginning of any fips_code that's fewer than 5 numbers long\n# Don't worry about the syntax\nelections_by_counties &lt;- elections_by_counties |&gt; \n  mutate(county_fips = as.character(county_fips)) |&gt; \n  mutate(county_fips = \n           ifelse(nchar(county_fips) == 4, paste0(\"0\", county_fips), county_fips))\n\nPart b\nNow map Republican support by county. Let’s go straight to the discretized repub_20_categories variable, and a good color scale.\n\nggplot(elections_by_counties, aes(map_id = county_fips, fill = repub_20_categories)) +\n  geom_map(map = county_map) +\n  scale_fill_manual(values = rev(brewer.pal(10, \"RdBu\")), name = \"% Republican\") +\n  expand_limits(x = county_map$long, y = county_map$lat) +\n  theme_map() +\n  theme(legend.position = \"right\") + \n  coord_equal()\n\n\n\n\n\n\n\nExercise 10: Play around!\nConstruct county-level maps of median_rent and median_age.\n\nlibrary(RColorBrewer)\n\nggplot(elections_by_counties, aes(map_id = county_fips, fill = median_rent)) +\n  geom_map(map = county_map) +\n  expand_limits(x = county_map$long, y = county_map$lat) +\n  theme_map() \n\n\n\n\n\n\nggplot(elections_by_counties, aes(map_id = county_fips, fill = median_age)) +\n  geom_map(map = county_map) +\n  expand_limits(x = county_map$long, y = county_map$lat) +\n  theme_map() \n\n\n\n\n\n\n\nExercise 11: Choropleth maps with leaflet\nThough ggplot() is often better for this purpose, we can also make choropleth maps with leaflet(). If you’re curious, check out the leaflet documentation:\nhttps://rstudio.github.io/leaflet/choropleths.html",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Spatial Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-spatial.html#solutions",
    "href": "ica/ica-spatial.html#solutions",
    "title": "\n13  Spatial Viz\n",
    "section": "\n13.5 Solutions",
    "text": "13.5 Solutions\n\nClick for Solutions\nExample 1\nBoth addresses used between 0 and 450 therms per month. There seem to be two types of months – those with lower use around 50 therms and those with higher use around 300/400 therms.\n\nggplot(energy, aes(x = therms, fill = address)) + \n  geom_density(alpha = 0.5)\n\n\n\n\n\n\n\nExample 2\nEnergy use is seasonal, with higher usage in winter months. It seems that address a uses slightly more energy.\n\nggplot(energy, aes(y = therms, x = date, color = address)) + \n  geom_point()\n\n\n\n\n\n\nggplot(energy, aes(y = therms, x = date, color = address)) + \n  geom_line()\n\n\n\n\n\n\n\nExample 3\nAt both addresses, typical energy use increased after renovations.\n\nggplot(energy, aes(y = therms, x = renovated)) + \n  geom_boxplot() + \n  facet_wrap(~ address)\n\n\n\n\n\n\n# A density plot isn't very helpful for comparing typical therms in this example!\nggplot(energy, aes(x = therms, fill = renovated)) + \n  geom_density(alpha = 0.5) + \n  facet_wrap(~ address)\n\n\n\n\n\n\n\nExample 4\nlurking variable = outdoor temperature (as reflected by hdd)\n\n# It happened to be colder outside after renovations (higher hdd)\nggplot(energy, aes(y = hdd, x = renovated)) + \n  geom_boxplot() + \n  facet_wrap(~ address)\n\n\n\n\n\n\n# When controlling for outside temps (via hdd), energy use decreased post-renovation\nggplot(energy, aes(y = therms, x = hdd, color = renovated)) + \n  geom_point(alpha = 0.5) + \n  geom_smooth(method = \"lm\", se = FALSE) + \n  facet_wrap(~ address)\n\n\n\n\n\n\n\nExample 5\nBUT this was explained by a confounding or omitted or lurking variable: hdd (outdoor temperature)\n\nAfter renovation…\n\nit happened to be colder…\nwhich then leads to higher energy use.\n\nThus, when controlling for outdoor temps, renovations led to decreased energy use.\nExercise 3: Your turn\n\nleaflet(data = starbucks_mn) |&gt; \n  addTiles() |&gt; \n  addMarkers()\n\n\n\n\n\nExercise 3: A simple scatterplot\nIt would be nice to also have some actual reference maps of countries in the background.\n\nggplot(starbucks, aes(y = Latitude, x = Longitude)) + \n  geom_point(size = 0.5)\n\n\n\n\n\n\n\nExercise 6: A state and county-level map\nPart b\nAdjust the code below to make the plot! Remove the # to run it.\n\nggplot(midwest_boundaries) +\n  geom_sf() +\n  geom_point(\n    data = starbucks_midwest,\n    aes(x = Longitude, y = Latitude),\n    alpha = 0.7,\n    size = 0.2,\n    color = 'darkgreen'\n  ) +\n  theme_map()\n\n\n\n\n\n\n\nExercise 7: Contour maps\nEspecially when there are lots of point locations, and those locations start overlapping on a map, it can be tough to visualize areas of higher density. Consider the Starbucks locations in Canada, Mexico, and the US that we mapped earlier:\n\n# Point map (we made this earlier)\nggplot(cma_boundaries) + \n  geom_sf() + \n  geom_point(\n    data = starbucks_cma,\n    aes(x = Longitude, y = Latitude),\n    alpha = 0.3,\n    size = 0.2,\n    color = \"darkgreen\"\n  ) +\n  coord_sf(xlim = c(-179.14, -50), ylim = c(14.54, 83.11)) +\n  theme_map()\n\n\n\n\n\n\n\nNow check out the contour map.\n\n# What changed in the plot?\n# What changed in our code?!\nggplot(cma_boundaries) + \n  geom_sf() + \n  geom_density_2d(\n    data = starbucks_cma,\n    aes(x = Longitude, y = Latitude),\n    size = 0.2,\n    color = \"darkgreen\"\n  ) +\n  coord_sf(xlim = c(-179.14, -50), ylim = c(14.54, 83.11)) +\n  theme_map()\n\n\n\n\n\n\n\nExercises Part 3: Choropleth maps\nSpatial data isn’t always in the form of point locations! For example, recall the state and county-level data on presidential elections.\n\nelections_by_state &lt;-  read.csv(\"https://mac-stat.github.io/data/election_2020_by_state.csv\")\nelections_by_counties &lt;- read.csv(\"https://mac-stat.github.io/data/election_2020_county.csv\")\n\nIn these datasets, we’re interested in the overall election outcome by region (state or county), not the specific geographic location of some observation. Let’s wrangle our data first.\nWe’ll focus on just a few variables of interest, and create a new variable (repub_20_categories) that discretizes the repub_pct_20 variable into increments of 5 percentage points (for states) or 10 percentage points (for counties):\n\n# Don't worry about the code!\n\nelections_by_state &lt;- elections_by_state |&gt; \n  filter(state_abbr != \"DC\") |&gt; \n  select(state_name, state_abbr, repub_pct_20) |&gt; \n  mutate(repub_20_categories = \n           cut(repub_pct_20, \n               breaks = seq(30, 70, by = 5), \n               labels = c(\"30-34\", \"35-39\", \"40-44\", \"45-49\",\n                          \"50-54\", \"55-59\", \"60-64\", \"65-70\"), \n               include.lowest = TRUE))\n\nelections_by_counties &lt;- elections_by_counties |&gt; \n  select(state_name, state_abbr, county_name, county_fips,\n          repub_pct_20, median_age, median_rent) |&gt; \n  mutate(repub_20_categories = \n           cut(repub_pct_20, \n               breaks = seq(0, 100, by = 10),\n               labels = c(\"0-9\", \"10-19\", \"20-29\", \"30-39\", \"40-49\",\n                          \"50-59\", \"60-69\", \"70-79\", \"80-89\", \"90-100\"),\n               include.lowest = TRUE))\n\n# Add 0's at the beginning of any fips_code that's fewer than 5 numbers long\n# Don't worry about the syntax\nelections_by_counties &lt;- elections_by_counties |&gt; \n  mutate(county_fips = as.character(county_fips)) |&gt; \n  mutate(county_fips = \n           ifelse(nchar(county_fips) == 4, paste0(\"0\", county_fips), county_fips))\n\nExercise 8: State-level choropleth maps\nPart d\ngeom_map()\nExercise 10: Play around!\n\nggplot(elections_by_counties, aes(map_id = county_fips, fill = median_rent)) +\n  geom_map(map = county_map) +\n  expand_limits(x = county_map$long, y = county_map$lat) +\n  theme_map() +\n  theme(legend.position = \"right\") + \n  coord_equal() + \n  scale_fill_gradientn(name = \"median rent\", colors = c(\"white\", \"lightgreen\", \"darkgreen\"))\n\n\n\n\n\n\nggplot(elections_by_counties, aes(map_id = county_fips, fill = median_age)) +\n  geom_map(map = county_map) +\n  expand_limits(x = county_map$long, y = county_map$lat) +\n  theme_map() +\n  theme(legend.position = \"right\") + \n  coord_equal() + \n  scale_fill_gradientn(name = \"median age\", colors = terrain.colors(10))",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Spatial Viz</span>"
    ]
  },
  {
    "objectID": "ica/quarto-demo.html",
    "href": "ica/quarto-demo.html",
    "title": "\n14  My first Quarto document\n",
    "section": "",
    "text": "15 Intro\nMacalester College is in the Twin Cities. It has:\n\nfour seasons\nbagpipes\ndelightful students\n\nCheck it out for yourself:\n\n\n\n16 Exercise 1: Deduce Quarto features\nCheck out the appearance and contents of this document. Thoughts?\nIn the toolbar at the top of this document, Render the .qmd file into a .html file. Where is this file stored? Thoughts about its appearance / contents? Can you edit it?\nToggling between the .qmd and .html files, explain the purpose of the following features in the .qmd file:\n*\n**\n#\n-\n\\\n![](url)\n\n\n17 Exercise 2: Code\nHow does this appear in the .qmd? The .html? So…?!\nseq(from = 100, to = 1000, by = 50)\n\n\n18 Exercise 3: Chunks\nQuarto isn’t a mind reader – we must distinguish R code from text. We do so by putting code inside an R chunk:\n\nPut the seq() code in the chunk.\nPress the green arrow in the top right of the chunk. What happens in the qmd?\nRender. What appears in the html: R code, output, or both?\n\n\n\n19 Exercise 4: Practice\n\nUse R code to create the following sequence: 10 10 10 10\nStore the sequence as four_tens.\nUse an R function (which we haven’t learned!) to add up the numbers in four_tens.\n\n\n\n20 Exercise 5: Fix this code\nCode is a form of communication, and the code below doesn’t cut it.\nPut the code in a chunk and fix it.\nRep(x = 1, times = 10) seq(from=100,to=1000,length=20) theNumberofStudentsinthisclass&lt;-27\n\n\n21 Exercise 6: Comments\nRun the chunk below. Notice that R ignores anything in a line starting with a pound sign (#). If we took the # away we’d get an error!\n\n# This is a comment\n4 + 5\n\n[1] 9\n\n\nWe’ll utilize this feature to comment our code, i.e. leave short notes about what our code is doing. Below, replace the ??? with an appropriate comment.\n\n# ???\ntemperature_c &lt;- 10\ntemperature_f &lt;- temperature_c * 9/5 + 32\ntemperature_f\n\n[1] 50",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>My first Quarto document</span>"
    ]
  },
  {
    "objectID": "ica/ica-univariate.html",
    "href": "ica/ica-univariate.html",
    "title": "\n15  Univariate Viz\n",
    "section": "",
    "text": "15.1 Exercises\nlibrary(ggplot2)\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ lubridate 1.9.4     ✔ tibble    3.2.1\n✔ purrr     1.0.2     ✔ tidyr     1.3.1\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n# Import data\nhikes &lt;- read.csv(\"https://mac-stat.github.io/data/high_peaks.csv\")",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Univariate Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-univariate.html#exercises",
    "href": "ica/ica-univariate.html#exercises",
    "title": "\n15  Univariate Viz\n",
    "section": "",
    "text": "Exercise 1: Research Questions\nLet’s dig into the hikes data, starting with the elevation and difficulty ratings of the hikes:\n\nhead(hikes)\n\n             peak elevation difficulty ascent length time    rating\n1     Mt. Marcy        5344          5   3166   14.8 10.0  moderate\n2 Algonquin Peak       5114          5   2936    9.6  9.0  moderate\n3   Mt. Haystack       4960          7   3570   17.8 12.0 difficult\n4   Mt. Skylight       4926          7   4265   17.9 15.0 difficult\n5 Whiteface Mtn.       4867          4   2535   10.4  8.5      easy\n6       Dix Mtn.       4857          5   2800   13.2 10.0  moderate\n\n\n\nWhat features would we like a visualization of the categorical difficulty rating variable to capture? it as a category/axis\nWhat about a visualization of the quantitative elevation variable? something like a bar graph\nExercise 2: Load tidyverse\nWe’ll address the above questions using ggplot tools. Try running the following chunk and simply take note of the error message – this is one you’ll get a lot!\n\n# Use the ggplot function\nggplot(hikes, aes(x = rating))\n\n\n\n\n\n\n\nIn order to use ggplot tools, we have to first load the tidyverse package in which they live. We’ve installed the package but we need to tell R when we want to use it. Run the chunk below to load the library. You’ll need to do this within any .qmd file that uses ggplot().\n\n# Load the package\nlibrary(tidyverse)\n\nExercise 3: Bar Chart of Ratings - Part 1\nConsider some specific research questions about the difficulty rating of the hikes:\n\nHow many hikes fall into each category? most to least: 3 moderate, 2 difficult, 1 easy\nAre the hikes evenly distributed among these categories, or are some more common than others? they are not, moderate is more common and 1 is the least\n\nAll of these questions can be answered with: (1) a bar chart; of (2) the categorical data recorded in the rating column. First, set up the plotting frame:\n\nggplot(hikes, aes(x = rating))\n\n\n\n\n\n\n\nThink about:\n\nWhat did this do? What do you observe?\nWhat, in general, is the first argument of the ggplot() function?\nWhat is the purpose of writing x = rating?\nWhat do you think aes stands for?!?\nExercise 4: Bar Chart of Ratings - Part 2\nNow let’s add a geometric layer to the frame / canvas, and start customizing the plot’s theme. To this end, try each chunk below, one by one. In each chunk, make a comment about how both the code and the corresponding plot both changed.\nNOTE:\n\nPay attention to the general code properties and structure, not memorization.\nNot all of these are “good” plots. We’re just exploring ggplot.\n\n\n# COMMENT on the change in the code and the corresponding change in the plot\nggplot(hikes, aes(x = rating)) +\n  geom_bar()\n\n\n\n\n\n\n\n#adds bars for each hike in each category\n\n# COMMENT on the change in the code and the corresponding change in the plot\nggplot(hikes, aes(x = rating)) +\n  geom_bar() +\n  labs(x = \"Rating\", y = \"Number of hikes\")\n\n\n\n\n\n\n\n#adds different names for the axes, making it more straightforward\n\n# COMMENT on the change in the code and the corresponding change in the plot\nggplot(hikes, aes(x = rating)) +\n  geom_bar(fill = \"blue\") +\n  labs(x = \"Rating\", y = \"Number of hikes\")\n\n\n\n\n\n\n\n#the bars are now uncomfortably blue\n\n# COMMENT on the change in the code and the corresponding change in the plot\nggplot(hikes, aes(x = rating)) +\n  geom_bar(color = \"orange\", fill = \"blue\") +\n  labs(x = \"Rating\", y = \"Number of hikes\")\n\n\n\n\n\n\n\n#the outlines are now macalester orange\n\n# COMMENT on the change in the code and the corresponding change in the plot\nggplot(hikes, aes(x = rating)) +\n  geom_bar(color = \"orange\", fill = \"blue\")  +\n  labs(x = \"Rating\", y = \"Number of hikes\") +\n  theme_minimal()\n\n\n\n\n\n\n\n#gets rid of the grey background\nExercise 5: Bar Chart Follow-up\nPart a\nReflect on the ggplot() code.\n\nWhat’s the purpose of the +? When do we use it? to add different arguments/characteristics to the chart\nWe added the bars using geom_bar()? Why “geom”? because it’s shorter and easier to type than a full “geometry”\nWhat does labs() stand for? labels\nWhat’s the difference between color and fill? color is the general color, but fill is the inner layer of the bar\nPart b\nIn general, bar charts allow us to examine the following properties of a categorical variable:\n\n\nobserved categories: What categories did we observe? the difficulty ratings of hikes\n\nvariability between categories: Are observations evenly spread out among the categories, or are some categories more common than others? moderate is most common with easy and difficult following it\n\nWe must then translate this information into the context of our analysis, here hikes in the Adirondacks. Summarize below what you learned from the bar chart, in context. The majority of hikes in the Adirondacks have a difficulty rating of “moderate”, with “easy” and “difficult” following far behind it.\nPart c\nIs there anything you don’t like about this barplot? For example: check out the x-axis again.\nthings arent consistently capitalized and also the colors are kind of doodoo\nExercise 6: Sad Bar Chart\nLet’s now consider some research questions related to the quantitative elevation variable:\n\nAmong the hikes, what’s the range of elevation and how are the hikes distributed within this range (e.g. evenly, in clumps, “normally”)?\nWhat’s a typical elevation?\nAre there any outliers, i.e. hikes that have unusually high or low elevations?\n\nHere:\n\nConstruct a bar chart of the quantitative elevation variable.\nExplain why this might not be an effective visualization for this and other quantitative variables. (What questions does / doesn’t it help answer?) 1:it looks ugly 2: theres a more even spread, not much is ot\n\n\nggplot(hikes, aes(x = elevation)) +\n  geom_bar(color = \"red\") +\n  theme_minimal()\n\n\n\n\n\n\n\nExercise 7: A Histogram of Elevation\nQuantitative variables require different viz than categorical variables. Especially when there are many possible outcomes of the quantitative variable. It’s typically insufficient to simply count up the number of times we’ve observed a particular outcome as the bar graph did above. It gives us a sense of ranges and typical outcomes, but not a good sense of how the observations are distributed across this range. We’ll explore two methods for graphing quantitative variables: histograms and density plots.\nHistograms are constructed by (1) dividing up the observed range of the variable into ‘bins’ of equal width; and (2) counting up the number of cases that fall into each bin. Check out the example below:\n\nPart a\nLet’s dig into some details.\n\nHow many hikes have an elevation between 4500 and 4700 feet?\nHow many total hikes have an elevation of at least 5100 feet?\nPart b\nNow the bigger picture. In general, histograms allow us to examine the following properties of a quantitative variable:\n\n\ntypical outcome: Where’s the center of the data points? What’s typical?\n\nvariability & range: How spread out are the outcomes? What are the max and min outcomes?\n\nshape: How are values distributed along the observed range? Is the distribution symmetric, right-skewed, left-skewed, bi-modal, or uniform (flat)?\n\noutliers: Are there any outliers, i.e. outcomes that are unusually large/small?\n\nWe must then translate this information into the context of our analysis, here hikes in the Adirondacks. Addressing each of the features in the above list, summarize below what you learned from the histogram, in context.\nExercise 8: Building Histograms - Part 1\n2-MINUTE CHALLENGE: Thinking of the bar chart code, try to intuit what line you can tack on to the below frame of elevation to add a histogram layer. Don’t forget a +. If it doesn’t come to you within 2 minutes, no problem – all will be revealed in the next exercise.\n\nggplot(hikes, aes(x = elevation))\n\n\n\n\n\n\n\nExercise 9: Building Histograms - Part 2\nLet’s build some histograms. Try each chunk below, one by one. In each chunk, make a comment about how both the code and the corresponding plot both changed.\n\n# creates the bars, specifies it as a histogram\nggplot(hikes, aes(x = elevation)) +\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n# aww the borders are now white and it much more pleasent on my eyes\nggplot(hikes, aes(x = elevation)) +\n  geom_histogram(color = \"white\") \n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n# the fill is now blue\nggplot(hikes, aes(x = elevation)) +\n  geom_histogram(color = \"white\", fill = \"blue\") \n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n# there are now axis labels\nggplot(hikes, aes(x = elevation)) +\n  geom_histogram(color = \"white\") +\n  labs(x = \"Elevation (feet)\", y = \"Number of hikes\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n# each bar is now very wide\nggplot(hikes, aes(x = elevation)) +\n  geom_histogram(color = \"white\", binwidth = 1000) +\n  labs(x = \"Elevation (feet)\", y = \"Number of hikes\")\n\n\n\n\n\n\n\n\n# now each bar is small\nggplot(hikes, aes(x = elevation)) +\n  geom_histogram(color = \"white\", binwidth = 5) +\n  labs(x = \"Elevation (feet)\", y = \"Number of hikes\")\n\n\n\n\n\n\n\n\n# the size is now JUST RIGHT!\nggplot(hikes, aes(x = elevation)) +\n  geom_histogram(color = \"white\", binwidth = 200) +\n  labs(x = \"Elevation (feet)\", y = \"Number of hikes\")\n\n\n\n\n\n\n\nExercise 10: Histogram Follow-up\n\nWhat function added the histogram layer / geometry? geom_histogram()\nWhat’s the difference between color and fill? color is everything up to the border, fill will not include the border\nWhy does adding color = \"white\" improve the visualization? because it contrasts with the background\nWhat did binwidth do? it changes the width of each bar\nWhy does the histogram become ineffective if the binwidth is too big (e.g. 1000 feet)? you arent able to see all the bars\nWhy does the histogram become ineffective if the binwidth is too small (e.g. 5 feet)? it is rather tough to see each bar\nExercise 11: Density Plots\nDensity plots are essentially smooth versions of the histogram. Instead of sorting observations into discrete bins, the “density” of observations is calculated across the entire range of outcomes. The greater the number of observations, the greater the density! The density is then scaled so that the area under the density curve always equals 1 and the area under any fraction of the curve represents the fraction of cases that lie in that range.\nCheck out a density plot of elevation. Notice that the y-axis (density) has no contextual interpretation – it’s a relative measure. The higher the density, the more common are elevations in that range.\n\nggplot(hikes, aes(x = elevation)) +\n  geom_density()\n\n\n\n\n\n\n\nQuestions\n\n\nINTUITION CHECK: Before tweaking the code and thinking back to geom_bar() and geom_histogram(), how do you anticipate the following code will change the plot?\n\n\ngeom_density(color = \"blue\") the border will be blue\n\ngeom_density(fill = \"orange\") the interior will be orange\n\n\nTRY IT! Test out those lines in the chunk below. Was your intuition correct?\n\n\nggplot(hikes, aes(x = elevation)) +\n  geom_density() +\n  geom_density(color = \"blue\") +\n  geom_density(fill = \"orange\")\n\n\n\n\n\n\n\n\nExamine the density plot. How does it compare to the histogram? What does it tell you about the typical elevation, variability / range in elevations, and shape of the distribution of elevations within this range? it’s smoother, shows a more general evened out trend rather than specific marked out chunks\nExercise 12: Density Plots vs Histograms\nThe histogram and density plot both allow us to visualize the behavior of a quantitative variable: typical outcome, variability / range, shape, and outliers. What are the pros/cons of each? What do you like/not like about each? HISTOGRAM: very clear, great for conveying the direct numbers in sheets DENSITY PLOT: much better for showing the variation in the data, makes trends much more clear\nExercise 13: Code = communication\nWe obviously won’t be done until we talk about communication. All code above has a similar general structure (where the details can change):\n\nggplot(___, aes(x = ___)) + \n  geom___(color = \"___\", fill = \"___\") + \n  labs(x = \"___\", y = \"___\")\n\n\nThough not necessary to the code working, it’s common, good practice to indent or tab the lines of code after the first line (counterexample below). Why?\n\n\n# easier to track beginning\nggplot(hikes, aes(x = elevation)) +\ngeom_histogram(color = \"white\", binwidth = 200) +\nlabs(x = \"Elevation (feet)\", y = \"Number of hikes\")\n\n\n\n\n\n\n\n\nThough not necessary to the code working, it’s common, good practice to put a line break after each + (counterexample below). Why?\n\n\n# makes it much more difficult to read each part \nggplot(hikes, aes(x = elevation)) + geom_histogram(color = \"white\", binwidth = 200) + labs(x = \"Elevation (feet)\", y = \"Number of hikes\")\n\n\n\n\n\n\n\nExercise 14: Practice\nPart a\nPractice your viz skills to learn about some of the variables in one of the following datasets from the previous class:\n\n# Data on students in this class\nsurvey &lt;- read.csv(\"https://hash-mac.github.io/stat112site-s25/data/survey.csv\")\n\n# World Cup data\nworld_cup &lt;- read.csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-11-29/worldcups.csv\")\n\n\nggplot(survey, aes(x = fav_temp_c)) +\n  geom_histogram(color = \"yellow\", bindiwth = 200000) +\n  labs(x = \"Favorite Temperature (C)\", y = \"Count\")\n\nWarning in geom_histogram(color = \"yellow\", bindiwth = 2e+05): Ignoring unknown\nparameters: `bindiwth`\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nPart b\nCheck out the RStudio Data Visualization cheat sheet to learn more features of ggplot.\n\n\n\n\n\n\nCheck → Commit → Push\n\n\n\nWhen done, don’t forgot to click Render Book and check the resulting HTML files. If happy, jump to GitHub Desktop and commit the changes with the message Finish activity 3 and push to GitHub. Wait few seconds, then visit your portfolio website and make sure the changes are there.",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Univariate Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-univariate.html#solutions",
    "href": "ica/ica-univariate.html#solutions",
    "title": "\n15  Univariate Viz\n",
    "section": "\n15.2 Solutions",
    "text": "15.2 Solutions\n\nClick for Solutions\nExercise 1: Research Questions\n\nFor example: how many hikes are there in each category? are any categories more common than others?\nFor example: What’s a typical elevation? What’s the range in elevations?\nExercise 3: Bar Chart of Ratings - Part 1\n\nggplot(hikes, aes(x = rating))\n\n\n\n\n\n\n\n\njust a blank canvas\nname of the dataset\nindicate which variable to plot on x-axis\n\naesthetics\nExercise 4: Bar Chart of Ratings - Part 2\n\n# Add a bar plot LAYER\nggplot(hikes, aes(x = rating)) +\n  geom_bar()\n\n\n\n\n\n\n# Add meaningful axis labels\nggplot(hikes, aes(x = rating)) +\n  geom_bar() +\n  labs(x = \"Rating\", y = \"Number of hikes\")\n\n\n\n\n\n\n# FILL the bars with blue\nggplot(hikes, aes(x = rating)) +\n  geom_bar(fill = \"blue\") +\n  labs(x = \"Rating\", y = \"Number of hikes\")\n\n\n\n\n\n\n# COLOR the outline of the bars in orange\nggplot(hikes, aes(x = rating)) +\n  geom_bar(color = \"orange\", fill = \"blue\") +\n  labs(x = \"Rating\", y = \"Number of hikes\")\n\n\n\n\n\n\n# Change the theme to a white background\nggplot(hikes, aes(x = rating)) +\n  geom_bar(color = \"orange\", fill = \"blue\")  +\n  labs(x = \"Rating\", y = \"Number of hikes\") + \n  theme_minimal()\n\n\n\n\n\n\n\nExercise 5: Bar Chart Follow-up\nPart a\n\nTo indicate we’re still adding layers to / modifying our plot.\nBars are the geometric elements we’re adding in this layer.\nlabels\n\nfill fills in the bars. color outlines the bars.\nPart b\nMost hikes are moderate, the fewest number are difficult.\nPart c\nI don’t like that the categories are alphabetical, not in order of difficulty level.\nExercise 6: Sad Bar Chart\nThere are too many different outcomes of elevation.\n\nggplot(hikes, aes(x = elevation)) + \n  geom_bar()\n\n\n\n\n\n\n\nExercise 7: A Histogram of Elevation\nPart a\n\n6\n1 + 1 = 2\nPart b\nElevations range from roughly 3700 to 5500 feet. Elevations vary from hike to hike relatively normally (with a bell shape) around a typical elevation of roughly 4500 feet.\nExercise 9: Building Histograms - Part 2\n\n# Add a histogram layer\nggplot(hikes, aes(x = elevation)) +\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n# Outline the bars in white\nggplot(hikes, aes(x = elevation)) +\n  geom_histogram(color = \"white\") \n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n# Fill the bars in blue\nggplot(hikes, aes(x = elevation)) +\n  geom_histogram(color = \"white\", fill = \"blue\") \n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n# Add axis labels\nggplot(hikes, aes(x = elevation)) +\n  geom_histogram(color = \"white\") +\n  labs(x = \"Elevation (feet)\", y = \"Number of hikes\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n# Change the width of the bins to 1000 feet\nggplot(hikes, aes(x = elevation)) +\n  geom_histogram(color = \"white\", binwidth = 1000) +\n  labs(x = \"Elevation (feet)\", y = \"Number of hikes\")\n\n\n\n\n\n\n# Change the width of the bins to 5 feet\nggplot(hikes, aes(x = elevation)) +\n  geom_histogram(color = \"white\", binwidth = 5) +\n  labs(x = \"Elevation (feet)\", y = \"Number of hikes\")\n\n\n\n\n\n\n# Change the width of the bins to 200 feet\nggplot(hikes, aes(x = elevation)) +\n  geom_histogram(color = \"white\", binwidth = 200) +\n  labs(x = \"Elevation (feet)\", y = \"Number of hikes\")\n\n\n\n\n\n\n\nExercise 10: Histogram Follow-up\n\ngeom_histogram()\n\ncolor outlined the bars and fill filled them\neasier to distinguish between the bars\nchanged the bin width\nwe lump too many hikes together and lose track of the nuances\nwe don’t lump enough hikes together and lose track of the bigger picture trends\nExercise 11: Density plots\n\nggplot(hikes, aes(x = elevation)) +\n geom_density(color = \"blue\", fill = \"orange\")\n\n\n\n\n\n\n\nExercise 13: Code = Communication\n\nClarifies that the subsequent lines are a continuation of the first. That is, we’re not done with the plot yet. These lines are all part of the same idea.\nThis is like a run-on sentence. It’s tough to track the distinct steps that go into building the plot.",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Univariate Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-bivariate.html",
    "href": "ica/ica-bivariate.html",
    "title": "\n16  Bivariate Viz\n",
    "section": "",
    "text": "16.1 Review\nLet’s review some univariate concepts and code using our class survey data. If the answers aren’t at the top of your mind, don’t fret! We’ve barely started speaking this new language, and learned a ton of vocab last week, so you naturally won’t remember it all.\n# Import data\nsurvey &lt;- read.csv(\"https://ajohns24.github.io/data/112/about_us_2024.csv\")\n\n# How many students have now filled out the survey?\nnrow(survey) \n\n[1] 28\n\n# What type of variables do we have?\nstr(survey)\n\n'data.frame':   28 obs. of  4 variables:\n $ cafe_mac         : chr  \"Cheesecake\" \"Cheese pizza\" \"udon noodles\" \"egg rolls\" ...\n $ minutes_to_campus: int  15 10 4 7 5 35 5 15 7 20 ...\n $ fave_temp        : num  18 24 18 10 18 7 75 24 13 16 ...\n $ hangout          : chr  \"the mountains\" \"a beach\" \"the mountains\" \"a beach\" ...",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Bivariate Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-bivariate.html#review",
    "href": "ica/ica-bivariate.html#review",
    "title": "\n16  Bivariate Viz\n",
    "section": "",
    "text": "EXAMPLE 1: Hangout Preferences\nStudents were asked, in that moment, where they’d most like to spend time outside. How did they answer? Was there a lot of agreement or a lot of variability in answers? Build and interpret a plot that helps address these questions while reviewing:\n\n“code as communication”\nconnecting with the components of a plot:\n\nset up a frame\n\nadd a layer / geometric element\nchange the theme, e.g. axis labels, color, fill\n\n\n\n\n# Attach a package needed to use the ggplot function\nlibrary(ggplot2)\nlibrary(tidyverse)\n# Make a ggplot\nggplot(survey, aes(x = hangout)) + \n  geom_bar(color = \"red\") +\n  labs(x = \"Hangout Spots\", y = \"Number of responses\")\n\n\n\n\n\n\n\nEXAMPLE 2: Temperature Preferences\nStudents were asked about their ideal outdoor temperature, in degrees Celsius. How did they answer? What was the typical response? What was the range in responses? Were there any outliers? Build and interpret 2 plots that help address these questions.\n\nggplot(survey, aes(x = fave_temp)) + \n  geom_histogram(color = \"orange\") +\n  labs(x = \"Favorite Temperature (C)\", y = \"Number of responses\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nBar Charts vs. Histograms\n\n\n\nBar charts & histograms can appear pretty similar, but they do different things.\n\n\nBar charts count up the number of observations of each outcome of a variable. They’re good for categorical variables, or quantitative variables with only a handful of possible outcomes.\n\nHistograms count up the number of observations that fall into different numerical ranges of variable. They’re good for quantitative variables, especially those with many different observed outcomes.",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Bivariate Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-bivariate.html#new-stuff",
    "href": "ica/ica-bivariate.html#new-stuff",
    "title": "\n16  Bivariate Viz\n",
    "section": "\n16.2 New stuff",
    "text": "16.2 New stuff\nThus far, we’ve been studying one variable at a time, using univariate plots. But once we get a sense of how individual variables behave on their own, our questions often turn to relationships among variables. For example, in our hikes data:\n\nHow much time does it take to complete a hike? ——&gt; How is time related to a hike’s elevation? What about its length?\nHow does difficult rating vary from hike to hike? ——-&gt; How is difficulty rating related to a hike’s ascent?\n\n\n16.2.1 Exploring relationships\nExploring univariate patterns often sparks follow-up questions about relationships between 2+ variables. Often, but not always, variables take on specific roles:\n\n\nresponse variable: the variable whose variability we would like to explain (time to complete a hike)\n\npredictors: variables that might explain some of the variability in the response (a hike’s elevation or length)\n\nVisualizations can help explore:\n\nrelationship trends (direction and form)\nrelationship strength (degree of variability from the trend)\n\noutliers in the relationship\n\nEXAMPLE 3\nFor each pair of variables below, sketch on paper a visualization of their relationship. Focus on general viz process, don’t worry about the exact details. The data here are totally made up.\n\n3pm temperature (response) vs 9am temperature (predictor)\n\n\ndata.frame(temp_3pm = c(24, 26, 20, 15, 15, 15), temp_9am = c(14, 18, 15, 13, 11, 11))\n\n  temp_3pm temp_9am\n1       24       14\n2       26       18\n3       20       15\n4       15       13\n5       15       11\n6       15       11\n\n\n\n3pm temperature (response) vs location (predictor)\n\n\nweather &lt;- data.frame(temp_3pm = c(24, 26, 20, 15, 15, 0, 40, 60, 57, 44, 51, 75),\n                      location = rep(c(\"A\", \"B\"), each = 6))\nweather\n\n   temp_3pm location\n1        24        A\n2        26        A\n3        20        A\n4        15        A\n5        15        A\n6         0        A\n7        40        B\n8        60        B\n9        57        B\n10       44        B\n11       51        B\n12       75        B\n\n\nThink: How might we modify the below density plot of temp_3pm to distinguish between locations?\n\nggplot(weather, aes(x = temp_3pm)) +\n      geom_density()\n\n\n\n\n\n\n\n\n\nrain_today (the response) and location (the predictor)\n\n\nweather &lt;- data.frame(rain_today = c(\"no\", \"no\", \"no\", \"no\", \"yes\", \"no\", \"yes\", \"no\", \"yes\", \"yes\", \"no\", \"yes\"),\n                        location = c(rep(\"A\", 7), rep(\"B\", 5)))\n    weather\n\n   rain_today location\n1          no        A\n2          no        A\n3          no        A\n4          no        A\n5         yes        A\n6          no        A\n7         yes        A\n8          no        B\n9         yes        B\n10        yes        B\n11         no        B\n12        yes        B\n\n\nThink: How might we modify the below bar plot of location to distinguish between days on which it did or didn’t rain?\n\nggplot(weather, aes(x = location)) +\n      geom_bar()\n\n\n\n\n\n\n\n\n16.2.2 General guidance for building bivariate plots\nAs with univariate plots, an appropriate visualization for the relationship between 2 variables depends upon whether the variables are quantitative or categorical. In general:\n\nEach quantitative variable requires a new axis (or a quantitative scale if we run out of axes).\nEach categorical variable requires a new way to “group” the graphic (eg: using colors, shapes, separate facets, etc)\nFor visualizations in which overlap in glyphs or plots obscures the patterns, try faceting or transparency.",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Bivariate Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-bivariate.html#exercises-required",
    "href": "ica/ica-bivariate.html#exercises-required",
    "title": "\n16  Bivariate Viz\n",
    "section": "\n16.3 Exercises (required)",
    "text": "16.3 Exercises (required)\nGithub user Tony McGovern has compiled and made available 2020/2016/2012 presidential election results for most of 3000+ U.S. counties, except Alaska. (Image: Wikimedia Commons)\n\nA wrangled version of this data, is imported below, after being combined with:\n\n2013 county-level demographics from the df_county_demographics data set from the choroplethr R package\nhistorical voting trends in the state in which the county falls (from https://www.270towin.com/content/blue-and-red-states):\n\nred = consistently Republican\nblue = consistently Democratic\npurple = something in between\n\n\n\n\n# Load data\nelections &lt;- read.csv(\"https://mac-stat.github.io/data/election_2020_county.csv\")\n\n# Check it out\nhead(elections)\n\n  state_name state_abbr historical    county_name county_fips total_votes_20\n1    Alabama         AL        red Autauga County        1001          27770\n2    Alabama         AL        red Baldwin County        1003         109679\n3    Alabama         AL        red Barbour County        1005          10518\n4    Alabama         AL        red    Bibb County        1007           9595\n5    Alabama         AL        red  Blount County        1009          27588\n6    Alabama         AL        red Bullock County        1011           4613\n  repub_pct_20 dem_pct_20 winner_20 total_votes_16 repub_pct_16 dem_pct_16\n1        71.44      27.02     repub          24661        73.44      23.96\n2        76.17      22.41     repub          94090        77.35      19.57\n3        53.45      45.79     repub          10390        52.27      46.66\n4        78.43      20.70     repub           8748        76.97      21.42\n5        89.57       9.57     repub          25384        89.85       8.47\n6        24.84      74.70       dem           4701        24.23      75.09\n  winner_16 total_votes_12 repub_pct_12 dem_pct_12 winner_12 total_population\n1     repub          23909        72.63      26.58     repub            54907\n2     repub          84988        77.39      21.57     repub           187114\n3     repub          11459        48.34      51.25       dem            27321\n4     repub           8391        73.07      26.22     repub            22754\n5     repub          23980        86.49      12.35     repub            57623\n6       dem           5318        23.51      76.31       dem            10746\n  percent_white percent_black percent_asian percent_hispanic per_capita_income\n1            76            18             1                2             24571\n2            83             9             1                4             26766\n3            46            46             0                5             16829\n4            75            22             0                2             17427\n5            88             1             0                8             20730\n6            22            71             0                6             18628\n  median_rent median_age\n1         668       37.5\n2         693       41.5\n3         382       38.3\n4         351       39.4\n5         403       39.6\n6         276       39.6\n\n\nWe’ll use this data to explore voting outcomes within the U.S.’s 2-party system. Here’s a list of candidates by year:\n\n\nyear\nRepublican candidate\nDemocratic candidate\n\n\n\n2020\nDonald Trump\nJoe Biden\n\n\n2016\nDonald Trump\nHillary Clinton\n\n\n2012\nMitt Romney\nBarack Obama\n\n\n\nExercise 0: Review\nPart a\nHow many, or roughly what percent, of the 3000+ counties did the Republican candidate win in 2020?\n\nTake a guess.\nThen make a plot of the winner variable.\nThen discuss what follow-up questions you might have (and that our data might help us answer).\n\n\nggplot(elections, aes(x = winner_20)) +\n  geom_bar() +\n  labs(x = \"2020 County Winners\")\n\n\n\n\n\n\n\nPart b\nThe repub_pct_20 variable provides more detail about the Republican support in each county. Construct a plot of repub_pct_20.\nNotice that the distribution of Republican support from county to county is slightly left skewed or negatively skewed. Left skewed! What follow-up questions do you have? None\n\nggplot(elections, aes(x = repub_pct_20)) +\n  geom_histogram()\n\n\n\n\n\n\n\nExercise 1: Quantitative vs Quantitative Intuition Check\n\n\n\n\n\n\nBe Quick\n\n\n\nDon’t spend more than 3 minutes on this!\n\n\nBelow is a scatterplot of the Republican support in 2020 vs 2016. Notice that:\n\nboth variables are quantitative, and get their own axes\nthe response variable is on the y-axis, demonstrating how repub_pct_20 might be predicted by repub_pct_16, not vice versa\n\nTry to replicate this using ggplot(). THINK:\n\nWhat info do you need to set up the canvas?\nWhat geometric layer (geom_???) might add these dots / points for each county? We haven’t learned this yet, just take some guesses.\n\n\nExercise 2: 2 Quantitiative Variables\nRun each chunk below to build up a a scatterplot of repub_pct_20 vs repub_pct_16 with different glyphs representing each county. Address or think about any prompts in the comments (#).\n\n# Set up the plotting frame\n#The x AND y axes are already being defined\nggplot(elections, aes(y = repub_pct_20, x = repub_pct_16))\n\n\n# Add a layer of points for each county\n#yassssss points\nggplot(elections, aes(y = repub_pct_20, x = repub_pct_16)) +\n  geom_point()\n\n\n# Change the shape of the points\n# aww the shapes are so pretty\nggplot(elections, aes(y = repub_pct_20, x = repub_pct_16)) +\n  geom_point(shape = 10)\n\n\n# YOU TRY: Modify the code to make the points \"orange\"\n# NOTE: Try to anticipate if \"color\" or \"fill\" will be useful here. Then try both.\nggplot(elections, aes(y = repub_pct_20, x = repub_pct_16)) +\n  geom_point(color = \"orange\", fill = \"blue\")\n\n\n\n\n\n\n\n\n# Add a layer that represents each county by the state it's in\n# Take note of the geom and the info it needs to run!\nggplot(elections, aes(y = repub_pct_20, x = repub_pct_16)) +\n  geom_text(aes(label = state_abbr))\n\nExercise 3: Reflect\nSummarize the relationship between the Republican support in 2020 and 2016. Be sure to comment on:\n\nthe strength of the relationship (weak/moderate/strong)\n\nthe direction of the relationship (positive/negative)\n\noutliers (in what state do counties deviate from the national trend? Any ideas why this might be the case?) While for most places republican support did not change too much from 2016 to 2020 (giving it a strong positive relationship), some counties in places like texas and utah shifted more in support of trump.\nExercise 4: Visualizing trend\nThe trend of the relationship between repub_pct_20 and repub_pct_16 is clearly positive and (mostly) linear. We can highlight this trend by adding a model “smooth” to the plot:\n\nggplot(elections, aes(y = repub_pct_20, x = repub_pct_16)) +\n  geom_point() +\n  geom_smooth()\n\nPart a\nConstruct a new plot that contains the model smooth but does not include the individual point glyphs.\n\nggplot(elections, aes(y = repub_pct_20, x = repub_pct_16)) +\n  geom_smooth()\n\n\n\n\n\n\n\nPart b\nBy default, geom_smooth() adds a smooth, localized model line. To examine the “best” linear model, we can specify method = \"lm\". It’s pretty similar in this example!\n\nggplot(elections, aes(y = repub_pct_20, x = repub_pct_16)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\n\nExercise 5: Your Turn\nTo examine how the 2020 results are related to some county demographics, construct scatterplots of repub_pct_20 vs median_rent, and repub_pct_20 vs median_age. Summarize the relationship between these two variables and comment on which is the better predictor of repub_pct_20, median_rent or median_age.\n\n# Scatterplot of repub_pct_20 vs median_rent\nggplot(elections, aes(x = repub_pct_20, y = median_rent)) + \n  geom_point() +\n  geom_smooth(method = \"lm\") \n\n\n\n\n\n\n# Scatterplot of repub_pct_20 vs median_age\n\nggplot(elections, aes(x = repub_pct_20, y = median_age)) + \n  geom_point() +\n  geom_smooth(method = \"lm\")\n\n\n\n\n\n\n\ncounties with higher median ages and lower median rents tend to support trump more than others. while both have correlations, the lower median rent is a much stronger predictor.\nExercise 6: A Sad Scatterplot\nNext, let’s explore the relationship between a county’s 2020 Republican support repub_pct_20 and the historical political trends in its state. In this case repub_pct_20 is quantitative, but historical is categorical. Explain why a scatterplot might not be an effective visualization for exploring this relationship. (What questions does / doesn’t it help answer?)\n\nggplot(elections, aes(y = repub_pct_20, x = historical)) +\n  geom_point()\n\n\n\n\n\n\n\nscatterplots work best when there is an even gradient between choices, not defined boxes\nExercise 7: Quantitative vs Categorical – Violins & Boxes\nThough the above scatterplot did group the counties by historical category, it’s nearly impossible to pick out meaningful patterns in 2020 Republican support in each category. Let’s try adding 2 different geom layers to the frame:\n\n# Side-by-side violin plots\nggplot(elections, aes(y = repub_pct_20, x = historical)) +\n  geom_violin()\n\n\n# Side-by-side boxplots (defined below)\nggplot(elections, aes(y = repub_pct_20, x = historical)) +\n  geom_boxplot()\n\nBox plots are constructed from five numbers - the minimum, 25th percentile, median, 75th percentile, and maximum value of a quantitative variable:\n\nREFLECT:\nSummarize what you’ve learned about the 2020 Republican county-level support within and between red/purple/blue states. support for trump was highest in historically red counties, with purple and blue counties following behind in that order.\nExercise 8: Quantitative vs Categorical – Intuition Check\n\n\n\n\n\n\nBe Quick\n\n\n\nDon’t spend more than 3 minutes on this!\n\n\nWe can also visualize the relationship between repub_pct_20 and historical using our familiar density plots. In the plot below, notice that we simply created a separate density plot for each historical category. (The plot itself is “bad” but we’ll fix it below.) Try to adjust the code chunk below, which starts with a density plot of repub_pct_20 alone, to re-create this image.\n\n\nggplot(elections, aes(x = repub_pct_20)) +\n  geom_density()\n\n\n\n\n\n\n\nExercise 9: Quantitative vs Categorical – Density Plots\nWork through the chunks below and address the comments therein.\n\n# Name two \"bad\" things about this plot\nggplot(elections, aes(x = repub_pct_20, fill = historical)) +\n  geom_density()\n\naxes aren’t great, purple and blue are covered and they also do not correspond to their colors\n\n# What does scale_fill_manual do?\nggplot(elections, aes(x = repub_pct_20, fill = historical)) +\n  geom_density() +\n  scale_fill_manual(values = c(\"blue\", \"purple\", \"red\"))\n\nallows you to choose fill color\n\n# What does alpha = 0.5 do?\n# Play around with different values of alpha, between 0 and 1\nggplot(elections, aes(x = repub_pct_20, fill = historical)) +\n  geom_density(alpha = 0.5) +\n  scale_fill_manual(values = c(\"blue\", \"purple\", \"red\"))\n\nchanges opacity\n\n# What does facet_wrap do?!\nggplot(elections, aes(x = repub_pct_20, fill = historical)) +\n  geom_density() +\n  scale_fill_manual(values = c(\"blue\", \"purple\", \"red\")) +\n  facet_wrap(~ historical)\n\nseperates each group\n\n# Let's try a similar grouping strategy with a histogram instead of density plot.\n# Why is this terrible?\nggplot(elections, aes(x = repub_pct_20, fill = historical)) +\n  geom_histogram(color = \"white\") +\n  scale_fill_manual(values = c(\"blue\", \"purple\", \"red\"))\n\nthis does not need to be a histogram\nExercise 10\nWe’ve now learned 3 (of many) ways to visualize the relationship between a quantitative and categorical variable: side-by-side violins, boxplots, and density plots.\n\nWhich do you like best? i am a big fan of density plots have to admit\n\nWhat is one pro of density plots relative to boxplots? boxplots are very general in statistics, density plots show everything\n\nWhat is one con of density plots relative to boxplots? its tough to find medians and percentiles in density plots\n\nExercise 11: Categorical vs Categorical – Intuition Check\nFinally, let’s simply explore who won each county in 2020 (winner_20) and how this breaks down by historical voting trends in the state. That is, let’s explore the relationship between 2 categorical variables! Following the same themes as above, we can utilize grouping features such as fill/color or facets to distinguish between different categories of winner_20 and historical.\n\n\n\n\n\n\nBe Quick\n\n\n\nSpend at most 5 minutes on the following intuition check. Adjust the code below to recreate the following two plots.\n\n\n\n\n# Plot 1: adjust this to recreate the top plot\nggplot(elections, aes(x = historical, fill = winner_20)) +\n  geom_bar(color = \"white\") +\n  scale_fill_manual(values = c(\"blue\", \"red\" ))\n\n\n\n\n\n\n\n\n# Plot 2: adjust this to recreate the bottom plot\nggplot(elections, aes(x = winner_20)) +\n  geom_bar() +\n  facet_wrap(~historical)\n\n\n\n\n\n\n\nExercise 12: Categorical vs Categorical\nConstruct the following 4 bar plot visualizations.\n\n# A stacked bar plot\n# How are the \"historical\" and \"winner_20\" variables mapped to the plot, i.e. what roles do they play?\nggplot(elections, aes(x = historical, fill = winner_20)) +\n  geom_bar()\n\nhistorical is used as the x axis/categorizer, winner_20 is distinguishing between repub and democrat\n\n# A faceted bar plot\nggplot(elections, aes(x = winner_20)) +\n  geom_bar() +\n  facet_wrap(~ historical)\n\n\n# A side-by-side bar plot\n# Note the new argument to geom_bar\nggplot(elections, aes(x = historical, fill = winner_20)) +\n  geom_bar(position = \"dodge\")\n\n\n# A proportional bar plot\n# Note the new argument to geom_bar\nggplot(elections, aes(x = historical, fill = winner_20)) +\n  geom_bar(position = \"fill\")\n\nPart a\nName one pro and one con of using the “proportional bar plot” instead of one of the other three options. it makes it very easy to see which is most popular, but it’s hard to tell which is less\nPart b\nWhat’s your favorite bar plot from part and why? i do love a proportianal bar plot its very pretty\nExercise 13: Practice (now or later)\n\n\n\n\n\n\nDecide\n\n\n\nDecide what’s best for you:\n\nTry this extra practice now.\nReflect on the above exercises and come back to this extra practice later (but before the next class).\n\n\n\nImport some daily weather data from a few locations in Australia:\n\nweather &lt;- read.csv(\"https://mac-stat.github.io/data/weather_3_locations.csv\")\n\nConstruct plots that address the research questions in each chunk. You might make multiple plots–there are many ways to do things!. However, don’t just throw spaghetti at the wall.\nReflect before doing anything. What types of variables are these? How might you plot just 1 of the variables, and then tweak the plot to incorporate the other?\n\n# How do 3pm temperatures (temp3pm) differ by location?\nggplot(weather, aes(x = location, y = temp3pm)) +\n  geom_violin()\n\n\n\n\n\n\n\n\n# How might we predict the 3pm temperature (temp3pm) by the 9am temperature (temp9am)?\nggplot(weather, aes(x = temp9am, y = temp3pm)) + \n  geom_point() +\n  geom_smooth(method = \"lm\")\n\n\n\n\n\n\n\n\n# How do the number of rainy days (raintoday) differ by location?\nggplot(weather, aes(x = location, fill = raintoday)) +\n  geom_bar(position = \"dodge\")",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Bivariate Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-bivariate.html#exercises-optional",
    "href": "ica/ica-bivariate.html#exercises-optional",
    "title": "\n16  Bivariate Viz\n",
    "section": "\n16.4 Exercises (optional)",
    "text": "16.4 Exercises (optional)\nThe above visualizations are foundational and important. But they’re not the only way to visualize the variables in our dataset.\nOptional Exercise 1: Many Categories\nSuppose we wanted to better understand how the 2020 Republican support varied from county to county within each state. Since repub_pct_20 is quantitative and state_abbr is categorical, we could make a density plot of repub_pct_20 for each state. Reflect on why this is bad.\n\nggplot(elections, aes(x = repub_pct_20, fill = state_abbr)) + \n  geom_density(alpha = 0.5)\n\n\n\n\n\n\n\nA facet wrap would also be bad!\n\nggplot(elections, aes(x = repub_pct_20)) + \n  geom_density(alpha = 0.5) + \n  facet_wrap(~ state_abbr)\n\n\n\n\n\n\n\nWhen we want to compare the distribution of some quantitative outcome among many groups / categories, a ridgeline plot can be a good option. These are also called joy plots, named after the album cover for “Unknown Pleasures” by Joy Division. (Look it up!) To make a ridgeline plot, we can use the geom_density_ridges() function from the ggridges package.\n\n# Install ggridges package\nlibrary(ggridges)\n\n# Make our first joy plot\n# THINK: What DON'T you like about this?\nggplot(elections, aes(x = repub_pct_20, y = state_abbr)) + \n  geom_density_ridges()\n\n\n# Let's put the states in order by Republican support, not alphabet\n# How do you think fct_reorder works? We'll learn about this later in the semester.\nggplot(elections, aes(x = repub_pct_20, y = fct_reorder(state_abbr, repub_pct_20))) + \n  geom_density_ridges(alpha = 0.5)\n\n\n# YOUR TURN: color/fill the ridges according to a state's historical voting patterns \n# and add meaningful axis labels\n\nFollow-up questions\n\nWhich states tend to have the most variability in outcomes from county to county? The least?\nWhat other interesting patterns do you notice?\nDoes this plot prompt any other questions?\nOptional Exercise 2: Total Outcomes by State\nLet’s import some new data and counts up the total votes (Republican and Democratic) by state, not county. This was wrangled from the elections data!\n\nelections_by_state &lt;- read.csv(\"https://mac-stat.github.io/data/election_2020_by_state.csv\")\n\nFor example, we might make a scatterplot of the 2020 vs 2016 outcomes:\n\nggplot(elections_by_state, aes(y = repub_pct_20, x = repub_pct_16)) + \n  geom_point()\n\n\n\n\n\n\n\nBUT this isn’t the easiest way to communicate or identify the changes from 1 year to the next.\n\n# YOU TRY\n# Start by creating a \"scatterplot\" of state_abbr (y-axis) by 2020 Republican support on the x-axis\n# Color the points red\n# Scroll to solutions below when you're ready\n\n\n# Check it out\nggplot(elections_by_state, aes(x = repub_pct_20, y = state_abbr)) + \n  geom_point(color = \"red\")\n\n\n\n\n\n\n\n\n# YOU TRY\n# Reorder the states in terms of their 2020 Republican support (not alphabet)\n# Scroll to solutions below when you're ready\n\n\n# Check it out\nggplot(elections_by_state, aes(x = repub_pct_20, y = fct_reorder(state_abbr, repub_pct_20))) + \n  geom_point(color = \"red\")\n\n\n\n\n\n\n\n\n# Finally, add ANOTHER layer of points for the 2016 outcomes\n# What info does this new geom_point() layer need to run?\nggplot(elections_by_state, aes(x = repub_pct_20, y = fct_reorder(state_abbr, repub_pct_20))) + \n  geom_point(color = \"red\") + \n  geom_point(aes(x = repub_pct_16, y = state_abbr))\n\n\n\n\n\n\n\nReflect on the following\n\nWhat do you think this plot needs? Try it! You might need to do some digging online.\nSummarize the main takeaways from the plots. Which states changed the most from 2016 to 2020? The least? Where did the Republican support increase? Where did it decrease?\nWhat other questions are you left with?",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Bivariate Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-bivariate.html#solutions",
    "href": "ica/ica-bivariate.html#solutions",
    "title": "\n16  Bivariate Viz\n",
    "section": "\n16.5 Solutions",
    "text": "16.5 Solutions\n\nClick for Solutions\n\n# Import data\nsurvey &lt;- read.csv(\"https://ajohns24.github.io/data/112/about_us_2024.csv\")\n\n# How many students have now filled out the survey?\nnrow(survey)\n\n[1] 28\n\n# What type of variables do we have?\nstr(survey)\n\n'data.frame':   28 obs. of  4 variables:\n $ cafe_mac         : chr  \"Cheesecake\" \"Cheese pizza\" \"udon noodles\" \"egg rolls\" ...\n $ minutes_to_campus: int  15 10 4 7 5 35 5 15 7 20 ...\n $ fave_temp        : num  18 24 18 10 18 7 75 24 13 16 ...\n $ hangout          : chr  \"the mountains\" \"a beach\" \"the mountains\" \"a beach\" ...\n\n\nEXAMPLE 1: Hangout preferences\n\n# Attach a package needed to use the ggplot function\nlibrary(tidyverse)\n\n# Make a ggplot\nggplot(survey, aes(x = hangout)) + \n  geom_bar()\n\n\n\n\n\n\n\nEXAMPLE 2: Temperature preferences\n\nggplot(survey, aes(x = fave_temp)) + \n  geom_histogram(color = \"white\", binwidth = 5)\n\n\n\n\n\n\nggplot(survey, aes(x = fave_temp)) + \n  geom_density()\n\n\n\n\n\n\n\n\n16.5.1 Exercise 0:\n\nggplot(elections, aes(x = winner_20)) + \n  geom_bar()\n\n\n\n\n\n\nggplot(elections, aes(x = repub_pct_20)) + \n  geom_histogram(color = \"white\")\n\n\n\n\n\n\nggplot(elections, aes(x = repub_pct_20)) + \n  geom_density()\n\n\n\n\n\n\n\nExercise 1: quantitative vs quantitative intuition check\nSee next exercise.\nExercise 2: 2 quantitiative variables\n\n# Set up the plotting frame\n# How does this differ than the frame for our histogram of repub_pct_20 alone?\n# ANSWER: we added a y-axis variable\nggplot(elections, aes(y = repub_pct_20, x = repub_pct_16))\n\n\n\n\n\n\n# Add a layer of points for each county\n# Take note of the geom: geom_point\nggplot(elections, aes(y = repub_pct_20, x = repub_pct_16)) +\n  geom_point()\n\n\n\n\n\n\n# Change the shape of the points\n# What happens if you change the shape to another number?\nggplot(elections, aes(y = repub_pct_20, x = repub_pct_16)) +\n  geom_point(shape = 3)\n\n\n\n\n\n\n# YOU TRY: Modify the code to make the points \"orange\"\n# NOTE: Try to anticipate if \"color\" or \"fill\" will be useful here. Then try both.\nggplot(elections, aes(y = repub_pct_20, x = repub_pct_16)) +\n  geom_point(color = \"orange\")\n\n\n\n\n\n\n# Add a layer that represents each county by the state it's in\n# Take note of the geom and the info it needs to run!\nggplot(elections, aes(y = repub_pct_20, x = repub_pct_16)) +\n  geom_text(aes(label = state_abbr))\n\n\n\n\n\n\n\nExercise 3: Reflect\nThere’s a strong, positive association – the higher the Republican support in 2016, the higher it was in 2020. There are some counties in Texas and Utah where the R support in 2020 was disproportionately higher than in 2016.\nExercise 4: Visualizing trend\n\nggplot(elections, aes(y = repub_pct_20, x = repub_pct_16)) +\n  geom_point() +\n  geom_smooth()\n\n\n\n\n\n\n\nPart a\n\nggplot(elections, aes(y = repub_pct_20, x = repub_pct_16)) +\n  geom_smooth()\n\n\n\n\n\n\n\nPart b\n\nggplot(elections, aes(y = repub_pct_20, x = repub_pct_16)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\n\n\n\n\n\n\n\nExercise 5: Your turn\nThere’s a moderate, positive association between R support and median age – the older the average age in a county, the higher the R support tends to be. However, there’s a stronger, negative association between R support and median rent – the higher the rent (a proxy for cost of living), the lower the R support tends to be.\n\n# Scatterplot of repub_pct_20 vs median_rent\nggplot(elections, aes(y = repub_pct_20, x = median_rent)) +\n  geom_point() \n\n\n\n\n\n\n# Scatterplot of repub_pct_20 vs median_age\nggplot(elections, aes(y = repub_pct_20, x = median_age)) +\n  geom_point() \n\n\n\n\n\n\n\nExercise 6: A sad scatterplot\nSee next exercise.\nExercise 7: quantitative vs categorical – violins & boxes\n\n# Side-by-side violin plots\nggplot(elections, aes(y = repub_pct_20, x = historical)) +\n  geom_violin()\n\n\n\n\n\n\n# Side-by-side boxplots (defined below)\nggplot(elections, aes(y = repub_pct_20, x = historical)) +\n  geom_boxplot()\n\n\n\n\n\n\n\nREFLECT:\nThere’s quite a bit of range in county-level R support within blue, purple, and red states. However, R support tends to be higher in red states and lower in blue states.\nExercise 8: quantitative vs categorical – intuition check\nSee next exercise.\nExercise 9: quantitative vs categorical – density plots\n\n# The colors used don't match up with the blue, purple, red labels\n# The density plots are on top of each other\nggplot(elections, aes(x = repub_pct_20, fill = historical)) +\n  geom_density()\n\n\n\n\n\n\n# scale_fill_manual \"hard codes\" or defines what colors to use for the fill categories\nggplot(elections, aes(x = repub_pct_20, fill = historical)) +\n  geom_density() +\n  scale_fill_manual(values = c(\"blue\", \"purple\", \"red\"))\n\n\n\n\n\n\n# alpha = 0.5 adds transparency\n# the closer alpha is to 0, the more transparent.\n# the closer alpha is to 1, the more opaque.\nggplot(elections, aes(x = repub_pct_20, fill = historical)) +\n  geom_density(alpha = 0.5) +\n  scale_fill_manual(values = c(\"blue\", \"purple\", \"red\"))\n\n\n\n\n\n\n# facet_wrap separates the density plots into \"facets\" for each historical group\nggplot(elections, aes(x = repub_pct_20, fill = historical)) +\n  geom_density() +\n  scale_fill_manual(values = c(\"blue\", \"purple\", \"red\")) +\n  facet_wrap(~ historical)\n\n\n\n\n\n\n# Let's try a similar grouping strategy with a histogram instead of density plot.\n# Why is this terrible?\nggplot(elections, aes(x = repub_pct_20, fill = historical)) +\n  geom_histogram(color = \"white\") +\n  scale_fill_manual(values = c(\"blue\", \"purple\", \"red\"))\n\n\n\n\n\n\n\nExercise 10\n\nOne pro of density plots relative to boxplots: doesn’t oversimplify the data / boil the data down to just 5 numbers.\nName one con of density plots relative to boxplots: boxplots can be easier to interpret\nExercise 11: categorical vs categorical intuition check\nsee exercise below\nExercise 12: categorical vs categorical\n\n# A stacked bar plot\n# historical = x axis / bar categories\n# winner_20 = fills the bars\nggplot(elections, aes(x = historical, fill = winner_20)) +\n  geom_bar()\n\n\n\n\n\n\n# A faceted bar plot\nggplot(elections, aes(x = winner_20)) +\n  geom_bar() +\n  facet_wrap(~ historical)\n\n\n\n\n\n\n# A side-by-side bar plot\n# Note the new argument to geom_bar\nggplot(elections, aes(x = historical, fill = winner_20)) +\n  geom_bar(position = \"dodge\")\n\n\n\n\n\n\n# A proportional bar plot\n# Note the new argument to geom_bar\nggplot(elections, aes(x = historical, fill = winner_20)) +\n  geom_bar(position = \"fill\")\n\n\n\n\n\n\n\nPart a\npro = easier to compare the relative outcomes in blue vs purple vs red states con = lose track of how many counties fall into blue vs purple vs red states\nExercise 13: Practice (now or later)\n\nweather &lt;- read.csv(\"https://mac-stat.github.io/data/weather_3_locations.csv\")\n\n# How do 3pm temperatures (temp3pm) differ by location?\nggplot(weather, aes(x = temp3pm, fill = location)) + \n  geom_density(alpha = 0.5)\n\n\n\n\n\n\nggplot(weather, aes(y = temp3pm, x = location)) + \n  geom_boxplot()\n\n\n\n\n\n\n# How might we predict the 3pm temperature (temp3pm) by the 9am temperature (temp9am)?\nggplot(weather, aes(y = temp3pm, x = temp9am)) + \n  geom_point()\n\n\n\n\n\n\n# How do the number of rainy days (raintoday) differ by location?\nggplot(weather, aes(x = location, fill = raintoday)) + \n  geom_bar()\n\n\n\n\n\n\n\nOptional exercise 1: Dealing with lots of categories\n\n# Install ggridges package\nlibrary(ggridges)\n\n# Make our first joy plot\n# THINK: What DON'T you like about this?\nggplot(elections, aes(x = repub_pct_20, y = state_abbr)) + \n  geom_density_ridges()\n\n\n\n\n\n\n# Let's put the states in order by Republican support, not alphabet\n# How do you think fct_reorder works? We'll learn about this later in the semester.\nggplot(elections, aes(x = repub_pct_20, y = fct_reorder(state_abbr, repub_pct_20))) + \n  geom_density_ridges(alpha = 0.5)\n\n\n\n\n\n\n# YOUR TURN: color/fill the ridges according to a state's historical voting patterns \n# and add meaningful axis labels\nggplot(elections, aes(x = repub_pct_20, y = fct_reorder(state_abbr, repub_pct_20), fill = historical)) + \n  geom_density_ridges(alpha = 0.5) + \n  labs(y = \"state\", x = \"2020 Republican support (%)\") + \n  scale_fill_manual(values = c(\"blue\", \"purple\", \"red\"))\n\n\n\n\n\n\n\nOptional exercise 2: total outcomes by state\n\nelections_by_state &lt;- read.csv(\"https://mac-stat.github.io/data/election_2020_by_state.csv\")\n\nggplot(elections_by_state, aes(y = repub_pct_20, x = repub_pct_16)) + \n  geom_point()\n\n\n\n\n\n\n# YOU TRY\n# Start by creating a \"scatterplot\" of state_abbr (y-axis) by 2020 Republican support on the x-axis\n# Color the points red\nggplot(elections_by_state, aes(x = repub_pct_20, y = state_abbr)) + \n  geom_point(color = \"red\")\n\n\n\n\n\n\n# YOU TRY\n# Reorder the states in terms of their 2020 Republican support (not alphabet)\nggplot(elections_by_state, aes(x = repub_pct_20, y = fct_reorder(state_abbr, repub_pct_20))) + \n  geom_point(color = \"red\")\n\n\n\n\n\n\n# Finally, add ANOTHER layer of points for the 2016 outcomes\n# What info does this new geom_point() layer need to run?\nggplot(elections_by_state, aes(x = repub_pct_20, y = fct_reorder(state_abbr, repub_pct_20))) + \n  geom_point(color = \"red\") + \n  geom_point(aes(x = repub_pct_16, y = state_abbr))",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Bivariate Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-effective.html",
    "href": "ica/ica-effective.html",
    "title": "\n17  Effective Viz\n",
    "section": "",
    "text": "17.1 Warm-up\nRecall: Benefits of Visualizations",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Effective Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-effective.html#warm-up",
    "href": "ica/ica-effective.html#warm-up",
    "title": "\n17  Effective Viz\n",
    "section": "",
    "text": "Understand what we’re working with:\n\nscales & typical outcomes\noutliers, i.e. unusual cases\npatterns & relationships\n\n\nRefine research questions & inform next steps of our analysis.\nCommunicate our findings and tell a story.\n\nNo One Right Viz\nThere is no one right way to visualize a data set, eg, check out the 100 ways used to visualize one dataset: https://100.datavizproject.com/ The visualized data was featured in this TidyTuesday!\nActivity: Plot Critique\nIn groups:\n\nScroll through the plots.\nIdentify at least 1 plot that you feel illuminates some important aspect of the data.\nIdentify at least 1 plot that does NOT illuminate the data in a good way.\nUgly, Bad, Wrong Viz\nOne way to identify effective viz is to understand what makes a viz ineffective. In the Fundamentals of Data Visualization, Wilke breaks down ineffective viz into 3 categories:\n\nWrong\nThe viz is “objectively incorrect”, as in the numbers / trends being displayed are wrong.\nBad\nThe viz is “unclear, confusing, overly complicated, or deceiving”.\nUgly\nThe viz correct and clear but The aesthetics are problematic.\n\nActivity: Critical Analysis\nLet’s try some critical analysis on specific examples. For your assigned viz, identify the following:\n\nThe story the viz is trying to communicate.\nWhether the viz is good, ugly, bad, wrong, or some combination.\nAreas for improvement.\n\n\n\n\n\nIMAGE 1. Source: N. Yau, Visualize This, 2011, p. 223-225.\n\n\n\n\n\n\n\nIMAGE 2. Source: N. Yau, Visualize This, 2011, p. 242.\n\n\n\n\n\n\n\nIMAGE 3. Climate change.\n\n\n\n\n\n\n\nIMAGE 4. Source: http://viz.wtf/\n\n\n\n\n\n\n\nIMAGE 5. Source: N. Yau, Visualize This, 2011, p. 220.\n\n\n\n\n\n\n\nIMAGE 6. Source: (https://www.reddit.com/r/dataisugly/comments/vlirox/0_1_19_20_39/)\n\n\n\nFollow-up to Climate Change Plot\n\n\n\n\nIMAGE 3. Climate change.\n\n\n\nEffective & Ineffective Viz Examples\n\nExamples of good viz:\n\nFlowingData’s “Best visualizations of…”\n\n\nExamples of bad viz:\n\nWTF Visualizations\nBad viz in the wild\n\n\nEffective Viz\nYou can take a whole course in Data Viz at Mac! The topic of effective viz is too big and nuanced to boil down into a simple list. Here are some basics:\nProfessionalism\nOnce you’re ready to “share out” your viz, it should have…\n\nmeaningful axis labels\na figure caption (depending upon where the viz will appear)\nAccessibility\nOnce you’re ready to “share out” your viz, it should…\n\nhave “alt text”, a written description of the viz that can be read out by a screen reader (video)\nuse a color palette that is distinguishable across common forms of color blindness\nDesign Details\nIn designing your viz, think about comparison. Good viz make it easy for people to perceive things that are similar and things that are different.\nEthics\nMichael Correll of Tableau Research (pdf) wrote “Data visualizations have a potentially enormous influence on how data are used to make decisions across all areas of human endeavor.” Thus ethics are critical from the data we use, to the plots we build, to the way in which we communicate this work. This is a very broad topic, and we’ll focus here on data visualization alone. Relatedly, and at a minimum:\n\nData viz should not mislead, i.e. “wrong” viz are unethical.**\nYet ethics in data viz goes much deeper. Correll describes three related principles to strive for:\n\nVisibility\nMake the invisible visible. Visualize hidden labor, hidden uncertainty, hidden impacts. Credit your sources, data and otherwise.\nPrivacy\nCollect data with empathy. Encourage small Data, anthropomorphize data, obfuscate data to protect privacy.\nPower\nChallenge structures of power. Support data due process, act as data advocates, pressure unethical analytical behavior.\n\n\nTo this list, Data Feminism authors Catherine D’Ignazio and Lauren F. Klein added:\n\nEmotion & Embodiment\nValue multiple forms of knowledge, including the knowledge that comes from people as living, feeling bodies in the world.\nPluralism\nThe most complete knowledge comes from synthesizing multiple perspectives\nContext\nData are not neutral or objective",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Effective Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-effective.html#exercises",
    "href": "ica/ica-effective.html#exercises",
    "title": "\n17  Effective Viz\n",
    "section": "\n17.2 Exercises",
    "text": "17.2 Exercises\nExercise 1: Professionalism\nLet’s examine weather in 3 Australian locations.\nThe following plot is fine for things like homework or just playing around. But we’ll make it more “professional” looking below.\n\nggplot(weather, aes(y = temp3pm, x = temp9am, color = location)) + \n  geom_point()\n\n\n\n\n\n\n\nPart a\nReplace A, B, C, and D in the code below to:\n\nAdd a short, but descriptive title. Under 10 words.\nChange the x- and y-axis labels, currently just the names of the variables in the dataset. These should be short and include units.\nChange the legend title to “Location” (just for practice, not because it’s better than “location”).\n\n\nggplot(weather, aes(y = temp3pm, x = temp9am, color = location)) + \n  geom_point() + \n  labs(x = \"9AM Temperature (C)\", y = \"3PM Temperature (C)\", title = \"Comparing Temperature Variance\", color = \"City\")  \n\n\n\n\n\n\n\nPart b\nWhen we’re including our plot in an article, paper, book, or other similar outlet, we should (and are expected to) provide a more descriptive figure caption. Typically, this is instead of a title and is more descriptive of what exactly is being plotted.\n\nAdd a figure caption in the top of the chunk.\nInclude your x-axis, y-axis, and legend labels from Part a.\nRender your Rmd and check out how the figure caption appears.\n\n\nggplot(weather, aes(y = temp3pm, x = temp9am, color = location)) + \n  geom_point() + \n  labs(x = \"9AM Temperature (C)\", y = \"3PM Temperature (C)\", color = \"City\")  \n\n\n\nTemperatures in Uluru are often highest, with each having a positive correlation with 3pm and 9am temperature.\n\n\n\n\nExercise 2: Accessibility\nLet’s now make a graphic more accessible.\n\nggplot(weather, aes(x = temp3pm, fill = location)) + \n  geom_density(alpha = 0.5) + \n  labs(x = \"3pm temperature (Celsius)\")  \n\n\n\nDensity plots of 3pm temperatures in 3 Australian locations.\n\n\n\nPart a\nLet’s add some alt text that can be picked up by screen readers. This is a great resource on writing alt text for data viz. In short, whereas figure captions are quick descriptions which assume that the viz is accessible, alt text is a longer description which assumes the viz is not accessible. Alt text should concisely articulate:\n\nWhat your visualization is (e.g. a density plot of 3pm temperatures in Hobart, Uluru, and Wollongong, Australia).\nA 1-sentence description of the most important takeaway.\nA link to your data source if it’s not already in the caption.\n\nAdd appropriate alt text at the top of the chunk, in fig-alt. Then knit your Rmd, and hover over the image in your knitted html file to check out the alt text.\n\nggplot(weather, aes(x = temp3pm, fill = location)) + \n  geom_density(alpha = 0.5) + \n  labs(x = \"3pm temperature (Celsius)\")  \n\n\n\nDensity plots of 3pm temperatures in 3 Australian locations.\n\n\n\n\nPart b\nColor is another important accessibility consideration. Let’s check out the color accessibility of our density plot.\n\nRun the ggplot() code from Part a in your console. The viz will pop up in the Plots tab.\nIn the Plots tab, click “Export” then “Save as image”. Save the image somewhere.\nNavigate to https://www.color-blindness.com/coblis-color-blindness-simulator/\n\nAbove the image of crayons (I think it’s crayons?), click “Choose file” and choose the plot file you just saved.\nClick the various simulator buttons (eg: Red-Weak/Protanomaly) to check out how the colors in this plot might appear to others.\nSummarize what you learn. What impact might our color choices have on one’s ability to interpret the viz?\nPart c\nWe can change our color schemes! There are many color-blind friendly palettes in R. In the future, we’ll set a default, more color-blind friendly color theme at the top of our Rmds. We can also do this individually for any plot that uses color. Run the chunks below to explore various options.\n\nggplot(weather, aes(x = temp3pm, fill = location)) + \n  geom_density(alpha = 0.5) + \n  labs(x = \"3pm temperature (Celsius)\") + \n  scale_fill_viridis_d()    \n\n\n\n\n\n\n\n\n# In the color scale line:\n# Change \"fill\" to \"color\" since we use color in the aes()\n# Change \"d\" (discrete) to \"c\" (continuous) since maxtemp is on a continuous scale\nggplot(weather, aes(y = temp3pm, x = temp9am, color = maxtemp)) + \n  geom_point(alpha = 0.5) + \n  labs(x = \"3pm temperature (Celsius)\") + \n  scale_color_viridis_c()\n\n\n\n\n\n\n\n\nExercise 3: Ethics\nLet’s scratch the surface of ethics in data viz. Central to this discussion is the consideration of impact.\nPart a\nAt a minimum, our data viz should not mislead. Reconsider the climate change example from above. Why is this plot unethical and what impact might it have on policy, public opinion, etc? it is designed to lead the reader into thinking that climate change doesn’t exist\n\nPart b\nAgain, data viz ethical considerations go beyond whether or not a plot is misleading. As described in the warm-up, we need to consider: visibility, privacy, power, emotion & embodiment, pluralism, & context. Depending upon the audience and goals of a data viz, addressing these points might require more nuance. Mainly, the viz tools we’ve learned are a great base or foundation, but aren’t the only approaches to data viz. \nPick one or more of the following examples of data viz to discuss with your group. How do the approaches taken:\n\nemphasize one or more of: visibility, privacy, power, emotion, embodiment, pluralism, and/or context?\nimprove upon what we might be able to convey with a simpler bar chart, scatterplot, etc?\n\n\nExample: W.E.B. Du Bois (1868–1963)\nDu Bois (“Doo Boys”) was a “sociologist, socialist, historian, civil rights activist, Pan-Africanist, author, writer, and editor”1. He was also a pioneer in elevating emotion and embodiment in data visualization. For the Paris World Fair of 1900, Du Bois and his team of students from Atlanta University presented 60 data visualizations of the Black experience in America, less than 50 years after the abolishment of slavery. Du Bois noted: “I wanted to set down its aim and method in some outstanding way which would bring my work to notice by the thinking world.” That is, he wanted to increase the impact of his work by partnering technical visualizations with design that better connects to lived experiences. NOTE: This work uses language common to that time period and addresses the topic of slavery. Check out:\n\nA complete set of the data visualizations provided by Anthony Starks (@ajstarks).\nAn article by Allen Hillery (@AlDatavizguy).\n\n\nExample: One person’s experience with long COVID\nNYT article\n\nExample: Decolonizing data viz\nblog post\n\nExample: Visualizing climate change through art\nFutures North with Prof John Kim & Mac students (by Prof Kim, Mac research students)\n\nExample: Personal data collection\nDear Data\n\nPart c\nFor a deeper treatment of similar topics, and more examples, read Data Feminism.\n\nExercise 4: Critique\nPractice critiquing some more complicated data viz listed at Modern Data Science with R, Exercise 2.5.\nThink about the following questions:\n\nWhat story does the data graphic tell? What is the main message that you take away from it?\nCan the data graphic be described in terms of the Grammar of Graphics (frame, glyphs, aesthetics, facet, scale, guide)? If so, please describe.\nCritique and/or praise the visualization choices made by the designer. Do they work? Are they misleading? Thought-provoking? Are there things that you would have done differently?\n\n\nExercise 5: Design Details\nThis final exercise is just “food for thought”. It’s more of a discussion than an exercise, and gets into some of the finer design details and data viz theory. Go as deep or not deep as you’d like here.\nIn refining the details of our data viz, Visualize This and Storytelling with Data provide some of their guiding principles. But again, every context is different.\n\nPut yourself in a reader’s shoes. What parts of the data need explanation?\nShine a light on your data. Try to remove any “chart junk” that distracts from the data.\nVary color and style to emphasize the viz elements that are most important to the story you’re telling.\nIt is easier to judge length than it is to judge area or angles.\nBe thoughtful about how your categories are ordered for categorical data.\n\nGetting into even more of the nitty gritty, we need to be mindful of what geometric elements and aesthetics we use. The following elements/aesthetics are listed in roughly descending order of human ability to perceive and compare nearby objects:2\n\nPosition\nLength\nAngle\nDirection\nShape (but only a very few different shapes)\nArea\nVolume\nShade\nColor. (Color is the most difficult, because it is a 3-dimensional quantity.)\n\nFinally, here are some facts to keep in mind about visual perception from Now You See It.\nPart a: Selectivity\nVisual perception is selective, and our attention is often drawn to contrasts from the norm.\nImplication: We should design visualizations so that the features we want to highlight stand out in contrast from those that are not worth the audience’s attention.\nExample: What stands out in this example image? This is originally from C. Ware, Information Visualization: Perception for Design, 2004? Source: S. Few, Now You See It, 2009, p. 33.\nshapes of border, and color, although kind of nothing stands out\n\nPart b: Familiarity\nOur eyes are drawn to familiar patterns. We observe what we know and expect.\nImplication: Visualizations work best when they display information as patterns that familiar and easy to spot.\nExample: Do you notice anything embedded in this rose image from coolbubble.com? Source: S. Few, Now You See It, 2009, p. 34.\n\nPart c: Revisit\nRevisit Part b. Do you notice anything in the shadows? Go to https://mac-stat.github.io/images/112/rose2.png for an image.\n\nWrapping up\nIf you finish early:\n\nWork on homework if not done already\nComplete any activities you haven’t finished yet, eg, spatial viz, the optional but fun exercises in the Multivariate viz and Bivariate viz activities.\nIf you’ve done all that, explore some datasets in TidyTuesday.",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Effective Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-effective.html#solutions",
    "href": "ica/ica-effective.html#solutions",
    "title": "\n17  Effective Viz\n",
    "section": "\n17.3 Solutions",
    "text": "17.3 Solutions\nThe exercises today are discussion based. There are no “solutions”. Happy to chat in office hours about any ideas here!",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Effective Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-effective.html#footnotes",
    "href": "ica/ica-effective.html#footnotes",
    "title": "\n17  Effective Viz\n",
    "section": "",
    "text": "https://en.wikipedia.org/wiki/W._E._B._Du_Bois↩︎\nB. S. Baumer, D. T. Kaplan, and N. J. Horton, Modern Data Science with R, 2017, p. 15.↩︎",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Effective Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-wrangling.html",
    "href": "ica/ica-wrangling.html",
    "title": "\n18  Wrangling\n",
    "section": "",
    "text": "18.1 Motivation\nRecall the elections data by U.S. county:\n# Load tidyverse & data\nlibrary(tidyverse)\nelections &lt;- read.csv(\"https://mac-stat.github.io/data/election_2020_county.csv\")\nWe’ve used data viz to explore some general patterns in the election outcomes. For example, a map!\n# Get a background map\nlibrary(socviz)\ndata(county_map)\n\n# Make a choropleth map\nlibrary(RColorBrewer)  # For the color scale\nlibrary(ggthemes) # For theme_map\nelections |&gt; \n  mutate(county_fips = as.character(county_fips)) |&gt; \n  mutate(county_fips = \n           ifelse(nchar(county_fips) == 4, paste0(\"0\", county_fips), county_fips)) |&gt; \n  ggplot(aes(map_id = county_fips, fill = cut(repub_pct_20, breaks = seq(0, 100, by = 10)))) +\n    geom_map(map = county_map) +\n    scale_fill_manual(values = rev(brewer.pal(10, \"RdBu\")), name = \"% Republican\") +\n    expand_limits(x = county_map$long, y = county_map$lat)  + \n    theme_map() +\n    theme(legend.position = \"right\") + \n    coord_equal()\nConsider some fairly basic follow-up questions, each of which we cannot answer precisely (or sometimes even at all) using our data viz tools:",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Wrangling</span>"
    ]
  },
  {
    "objectID": "ica/ica-wrangling.html#motivation",
    "href": "ica/ica-wrangling.html#motivation",
    "title": "\n18  Wrangling\n",
    "section": "",
    "text": "How many total people voted for the Democratic and Republican candidates in 2020?\nWhat about in each state?\nIn just the state of Minnesota:\n\nWhich counties had the highest and lowest Democratic vote in 2020?\nHow did the Democratic vote in each county change from 2016 to 2020?",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Wrangling</span>"
    ]
  },
  {
    "objectID": "ica/ica-wrangling.html#goals",
    "href": "ica/ica-wrangling.html#goals",
    "title": "\n18  Wrangling\n",
    "section": "\n18.2 Goals",
    "text": "18.2 Goals\nWe really cannot do anything with data (viz, modeling, etc) unless we can wrangle the data. The following is a typical quote. I agree with the 90% – data wrangling isn’t something we have to do before we can do data science, it is data science! But let’s rethink the 10% – data wrangling is a fun and empowering puzzle!\n\nThe goals of data wrangling are to explore how to:\n\nGet data into the tidy shape / format we need for analysis. For example, we might want to:\n\nkeep only certain observations\ndefine new variables\nreformat or “clean” existing variables\ncombine various datasets\nprocess “string” or text data\n\n\nNumerically (not just visually) explore and summarize various characteristics of the variables in our dataset.",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Wrangling</span>"
    ]
  },
  {
    "objectID": "ica/ica-wrangling.html#tools",
    "href": "ica/ica-wrangling.html#tools",
    "title": "\n18  Wrangling\n",
    "section": "\n18.3 Tools",
    "text": "18.3 Tools\nWe’ll continue to use packages that are part of the tidyverse which share a common general grammar and structure.",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Wrangling</span>"
    ]
  },
  {
    "objectID": "ica/ica-wrangling.html#warm-up",
    "href": "ica/ica-wrangling.html#warm-up",
    "title": "\n18  Wrangling\n",
    "section": "\n18.4 Warm-Up",
    "text": "18.4 Warm-Up\nThere are lots and lots of steps that can go into data wrangling, thus lots and lots of relevant R functions. BUT just 6 functions can get us very far. People refer to these as the 6 main wrangling verbs or functions:\n\nwhy “verbs”? in the tidyverse grammar, functions serve as action words\n\nthe 6 verbs are all stored in the dplyr package within the tidyverse\n\neach verb acts on a data frame and returns a data frame\n\n\n\nverb\naction\n\n\n\narrange\n\narrange the rows according to some column\n\n\n\nfilter\n\nfilter out or obtain a subset of the rows\n\n\n\nselect\n\nselect a subset of columns\n\n\n\nmutate\n\nmutate or create a column\n\n\n\nsummarize\ncalculate a numerical summary of a column\n\n\n\ngroup_by\n\ngroup the rows by a specified column\n\n\n\n\n\n18.4.1 Example 1\nWhich verb would help us…\n\nkeep only information about state names, county names, and the 2020 and 2016 Democratic support (not the 2012 results, demographics, etc) select\n\nget only the data on Minnesota filter\n\ndefine a new variable which calculates the change in Democratic support from 2016 to 2020, using dem_pct_20 and dem_pct_16 mutate\n\nsort the counties from highest to lowest Democratic support arrange\n\ndetermine the total number of votes cast across all counties summarize\n\n\n18.4.2 Example 2: Select Columns\nTo get a sense for the code structure, let’s explore a couple verbs together. To start, let’s simplify our dataset to include only some variables of interest. Specifically, select() only the columns relevant to state names, county names, and the 2020 and 2016 Democratic support:\n\n# What's the first argument? The second?\nselect(elections, c(state_name, county_name, dem_pct_20, dem_pct_16))\n\nLet’s re-do this with the pipe function |&gt;:\n\nelections |&gt; \n  select(state_name, county_name, dem_pct_20, dem_pct_16)\n\n\n\n\n\n\n\nPipe Function |&gt;\n\n\n\n|&gt; “passes” objects, usually datasets, to a function:\nobject |&gt; function() is the same as function(object)\n\n\n\n18.4.3 Example 3: Filter Rows\nLet’s filter() out only the rows related to Minnesota (MN):\n\n# Without a pipe\nfilter(elections, state_name == \"Minnesota\")\n\n\n# With a pipe\nelections |&gt; \n  filter(state_name == \"Minnesota\")\n\n\n\n\n\n\n\n== vs =\n\n\n\nWe use a == b to check whether a matches b.\nWe use a = b to define that a is equal to b. We typically use = for this purpose inside a function, and &lt;- for this purpose outside a function.\n\n# Ex: \"=\" defines x\nx = 2\nx\n\n[1] 2\n\n\n\n# Ex: \"==\" checks whether x is/matches 3\nx == 3\n\n[1] FALSE\n\n\n\n\n\n18.4.4 Example 4: Filter and Select\nLet’s combine select() and filter() to create a new dataset with info about the county names, and 2020 and 2016 Democratic support among Minnesota counties.\n\n# Without pipes\nfilter(select(elections, c(state_name, county_name, dem_pct_20, dem_pct_16)), state_name == \"Minnesota\")\n\n\n# With pipes: all verbs in 1 row\nelections |&gt; select(state_name, county_name, dem_pct_20, dem_pct_16) |&gt; filter(state_name == \"Minnesota\")\n\n\n# With pipes: each verb in a new row\nelections |&gt; \n  select(state_name, county_name, dem_pct_20, dem_pct_16) |&gt; \n  filter(state_name == \"Minnesota\")\n\n\n# We can even do this with UN-tidyverse code in \"base\" R\nelections[elections$state_name == \"Minnesota\", c(1, 4, 8, 12)]\n\n\n\n\n\n\n\nReflection\n\n\n\nWhy will we typically use:\n\ntidyverse code\nthe pipe function |&gt;\n\neach verb on a new row to make each line of code legible and easy to understand\n\n\n\n\n\n18.4.5 Example 5: Order of Operations\nSometimes, the order of operations matters, eg, putting on socks then shoes produces a different result than putting on shoes then socks. However, sometimes order doesn’t matter, eg, pouring cereal into a bowl then adding milk produces the same result as pouring milk into a bow then adding cereal (though one order is obviously better than the other ;)) Above (also copied below), we selected some columns and then filtered some rows:\n\nelections |&gt; \n  select(state_name, county_name, dem_pct_20, dem_pct_16) |&gt; \n  filter(state_name == \"Minnesota\")\n\nWould we get the same result if we reversed select() and filter()? Think first, then try it.\n\n# Try it\nelections |&gt;\n  filter(state_name == \"Minnesota\") |&gt;\n  select(state_name, county_name, dem_pct_20, dem_pct_16)\n\n   state_name              county_name dem_pct_20 dem_pct_16\n1   Minnesota            Aitkin County      35.98      34.12\n2   Minnesota             Anoka County      47.79      41.01\n3   Minnesota            Becker County      33.96      30.47\n4   Minnesota          Beltrami County      47.24      40.76\n5   Minnesota            Benton County      32.70      28.33\n6   Minnesota         Big Stone County      35.41      33.75\n7   Minnesota        Blue Earth County      50.84      43.38\n8   Minnesota             Brown County      32.48      27.54\n9   Minnesota           Carlton County      49.58      46.85\n10  Minnesota            Carver County      46.37      39.03\n11  Minnesota              Cass County      34.68      31.16\n12  Minnesota          Chippewa County      33.67      32.00\n13  Minnesota           Chisago County      34.15      30.92\n14  Minnesota              Clay County      50.74      44.57\n15  Minnesota        Clearwater County      26.76      26.04\n16  Minnesota              Cook County      65.58      56.90\n17  Minnesota        Cottonwood County      30.03      29.45\n18  Minnesota         Crow Wing County      34.17      30.88\n19  Minnesota            Dakota County      55.73      48.22\n20  Minnesota             Dodge County      33.47      29.36\n21  Minnesota           Douglas County      32.56      28.80\n22  Minnesota         Faribault County      31.98      29.27\n23  Minnesota          Fillmore County      37.48      35.28\n24  Minnesota          Freeborn County      40.96      37.92\n25  Minnesota           Goodhue County      41.23      36.99\n26  Minnesota             Grant County      35.58      31.97\n27  Minnesota          Hennepin County      70.46      63.82\n28  Minnesota           Houston County      42.42      39.42\n29  Minnesota           Hubbard County      34.42      30.04\n30  Minnesota            Isanti County      29.45      27.09\n31  Minnesota            Itasca County      40.61      38.12\n32  Minnesota           Jackson County      29.99      27.36\n33  Minnesota           Kanabec County      30.02      28.64\n34  Minnesota         Kandiyohi County      36.12      33.56\n35  Minnesota           Kittson County      38.12      34.83\n36  Minnesota       Koochiching County      38.41      36.53\n37  Minnesota     Lac qui Parle County      35.79      33.92\n38  Minnesota              Lake County      50.64      47.54\n39  Minnesota Lake of the Woods County      27.87      24.80\n40  Minnesota          Le Sueur County      33.73      31.10\n41  Minnesota           Lincoln County      30.08      28.65\n42  Minnesota              Lyon County      35.94      31.54\n43  Minnesota            McLeod County      30.64      26.64\n44  Minnesota          Mahnomen County      48.26      44.84\n45  Minnesota          Marshall County      25.33      25.55\n46  Minnesota            Martin County      30.02      26.11\n47  Minnesota            Meeker County      28.58      26.17\n48  Minnesota        Mille Lacs County      29.98      28.65\n49  Minnesota          Morrison County      22.33      20.74\n50  Minnesota             Mower County      46.00      42.33\n51  Minnesota            Murray County      29.60      27.90\n52  Minnesota          Nicollet County      50.31      44.02\n53  Minnesota            Nobles County      33.65      31.81\n54  Minnesota            Norman County      40.80      39.11\n55  Minnesota           Olmsted County      54.16      45.75\n56  Minnesota        Otter Tail County      32.85      28.93\n57  Minnesota        Pennington County      35.29      32.17\n58  Minnesota              Pine County      33.87      33.36\n59  Minnesota         Pipestone County      26.44      23.58\n60  Minnesota              Polk County      34.88      32.06\n61  Minnesota              Pope County      35.27      33.46\n62  Minnesota            Ramsey County      71.50      65.73\n63  Minnesota          Red Lake County      31.47      28.86\n64  Minnesota           Redwood County      28.43      24.94\n65  Minnesota          Renville County      30.71      27.99\n66  Minnesota              Rice County      48.76      44.81\n67  Minnesota              Rock County      29.69      28.56\n68  Minnesota            Roseau County      25.98      23.90\n69  Minnesota         St. Louis County      56.64      51.92\n70  Minnesota             Scott County      45.52      38.31\n71  Minnesota         Sherburne County      32.48      27.74\n72  Minnesota            Sibley County      28.60      25.29\n73  Minnesota           Stearns County      37.58      32.38\n74  Minnesota            Steele County      37.47      32.77\n75  Minnesota           Stevens County      37.80      39.55\n76  Minnesota             Swift County      34.35      33.80\n77  Minnesota              Todd County      24.79      23.30\n78  Minnesota          Traverse County      35.46      35.23\n79  Minnesota           Wabasha County      35.78      32.86\n80  Minnesota            Wadena County      26.35      24.43\n81  Minnesota            Waseca County      33.65      29.63\n82  Minnesota        Washington County      53.46      46.96\n83  Minnesota          Watonwan County      38.20      36.49\n84  Minnesota            Wilkin County      29.91      27.23\n85  Minnesota            Winona County      49.07      43.97\n86  Minnesota            Wright County      34.49      29.41\n87  Minnesota   Yellow Medicine County      30.54      29.01\n\n\n\n18.4.6 Example 6: Storing Results\nTypically:\n\nWe want to store our data wrangling results.\nIt’s good practice to do so under a new name. We want to preserve, thus don’t want to overwrite, the original data (especially if our code contains errors!!).\n\n\n# Store the results\nmn &lt;- elections |&gt; \n  select(state_name, county_name, dem_pct_20, dem_pct_16) |&gt; \n  filter(state_name == \"Minnesota\")\n\n# Always check it out to confirm it's what you want it to be!\nhead(mn)\n\n  state_name      county_name dem_pct_20 dem_pct_16\n1  Minnesota    Aitkin County      35.98      34.12\n2  Minnesota     Anoka County      47.79      41.01\n3  Minnesota    Becker County      33.96      30.47\n4  Minnesota  Beltrami County      47.24      40.76\n5  Minnesota    Benton County      32.70      28.33\n6  Minnesota Big Stone County      35.41      33.75\n\nnrow(mn)\n\n[1] 87\n\nnrow(elections)\n\n[1] 3109",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Wrangling</span>"
    ]
  },
  {
    "objectID": "ica/ica-wrangling.html#exercises",
    "href": "ica/ica-wrangling.html#exercises",
    "title": "\n18  Wrangling\n",
    "section": "\n18.5 Exercises",
    "text": "18.5 Exercises\nExercise 1: select Practice\nUse select() to create a simplified dataset that we’ll use throughout the exercises below.\n\nStore this dataset as elections_small.\nOnly keep the following variables: state_name, county_name, total_votes_20, repub_pct_20, dem_pct_20, total_votes_16, dem_pct_16\n\n\n\n# Define elections_small\nelections_small &lt;- elections |&gt;\n  select(state_name, county_name,total_votes_20, repub_pct_20, dem_pct_20, total_votes_16, dem_pct_16)\nhead(elections_small)\n\n  state_name    county_name total_votes_20 repub_pct_20 dem_pct_20\n1    Alabama Autauga County          27770        71.44      27.02\n2    Alabama Baldwin County         109679        76.17      22.41\n3    Alabama Barbour County          10518        53.45      45.79\n4    Alabama    Bibb County           9595        78.43      20.70\n5    Alabama  Blount County          27588        89.57       9.57\n6    Alabama Bullock County           4613        24.84      74.70\n  total_votes_16 dem_pct_16\n1          24661      23.96\n2          94090      19.57\n3          10390      46.66\n4           8748      21.42\n5          25384       8.47\n6           4701      75.09\n\n# Check out the first 6 rows to confirm your code did what you think it did!\n\nExercise 2: filter Demo\nWhereas select() selects certain variables or columns, filter() keeps certain units of observation or rows relative to their outcome on certain variables. To this end, we must:\n\nIdentify the variable(s) that are relevant to the filter.\n\nUse a “logical comparison operator” to define which values of the variable to keep:\n\n\nsymbol\nmeaning\n\n\n\n==\nequal to\n\n\n!=\nnot equal to\n\n\n&gt;\ngreater than\n\n\n&gt;=\ngreater than or equal to\n\n\n&lt;\nless than\n\n\n&lt;=\nless than or equal to\n\n\n%in% c(???, ???)\na list of multiple values\n\n\n\n\nUse quotes \"\" when specifying outcomes of interest for a categorical variable.\n\n\n\n\n\n\n\nCommenting/Uncommenting Code\n\n\n\nTo comment/uncomment several lines of code at once, highlight them then click ctrl/cmd+shift+c.\n\n\n\n# Keep only data on counties in Hawaii\nelections_small |&gt;\n  filter(state_name == \"Hawaii\")\n\n  state_name     county_name total_votes_20 repub_pct_20 dem_pct_20\n1     Hawaii   Hawaii County          87814        30.63      66.88\n2     Hawaii Honolulu County         382114        35.66      62.51\n3     Hawaii    Kauai County          33497        34.58      63.36\n4     Hawaii     Maui County          71044        31.14      66.59\n  total_votes_16 dem_pct_16\n1          64865      63.61\n2         285683      61.48\n3          26335      62.49\n4          51942      64.45\n\n\n\n#What does this do?\nelections_small |&gt;\n  filter(state_name %in% c(\"Hawaii\", \"Delaware\"))\n\n  state_name       county_name total_votes_20 repub_pct_20 dem_pct_20\n1   Delaware       Kent County          87025        47.12      51.19\n2   Delaware New Castle County         287633        30.72      67.81\n3   Delaware     Sussex County         129352        55.07      43.82\n4     Hawaii     Hawaii County          87814        30.63      66.88\n5     Hawaii   Honolulu County         382114        35.66      62.51\n6     Hawaii      Kauai County          33497        34.58      63.36\n7     Hawaii       Maui County          71044        31.14      66.59\n  total_votes_16 dem_pct_16\n1          74253      44.91\n2         261468      62.30\n3         105814      37.17\n4          64865      63.61\n5         285683      61.48\n6          26335      62.49\n7          51942      64.45\n\n \"filters results to only Hawaii and Delaware's county results\"\n\n[1] \"filters results to only Hawaii and Delaware's county results\"\n\n\n\n# Keep only data on counties where the Republican got MORE THAN 93.97% of the vote in 2020\nelections_small |&gt;\n  filter(repub_pct_20 &gt; 93.97)\n\n  state_name    county_name total_votes_20 repub_pct_20 dem_pct_20\n1      Texas  Borden County            416        95.43       3.85\n2      Texas    King County            159        94.97       5.03\n3      Texas Roberts County            550        96.18       3.09\n  total_votes_16 dem_pct_16\n1            365       8.49\n2            159       3.14\n3            550       3.64\n\n\n\n# Keep only data on counties where the Republican got AT LEAST 93.97% of the vote in 2020\n# This should have 1 more row (observation) than your answer above\nelections_small |&gt;\n  filter(repub_pct_20 &gt;= 93.97)\n\n  state_name     county_name total_votes_20 repub_pct_20 dem_pct_20\n1    Montana Garfield County            813        93.97       5.04\n2      Texas   Borden County            416        95.43       3.85\n3      Texas     King County            159        94.97       5.03\n4      Texas  Roberts County            550        96.18       3.09\n  total_votes_16 dem_pct_16\n1            715       4.76\n2            365       8.49\n3            159       3.14\n4            550       3.64\n\n\nWe can also filter with respect to 2 rules! Here, think what variables are relevant.\n\n# Keep only data on counties in Texas where the Democrat got more than 65% of the vote in 2020\n# Do this 2 ways.\n# Method 1: 2 filters with 1 condition each\nelections_small |&gt;\n filter(state_name == \"Texas\") |&gt;\n filter(dem_pct_20 &gt; 65)\n\n  state_name     county_name total_votes_20 repub_pct_20 dem_pct_20\n1      Texas  El Paso County         267215        31.56      66.66\n2      Texas Presidio County           2217        32.52      65.99\n3      Texas   Travis County         610349        26.43      71.41\n4      Texas   Zavala County           4379        34.03      65.40\n  total_votes_16 dem_pct_16\n1         210458      69.14\n2           2203      66.18\n3         462511      66.26\n4           3390      77.67\n\n# Method 2: 1 filter with 2 conditions\nelections_small |&gt;\n filter(state_name ==\"Texas\", dem_pct_20 &gt; 65)\n\n  state_name     county_name total_votes_20 repub_pct_20 dem_pct_20\n1      Texas  El Paso County         267215        31.56      66.66\n2      Texas Presidio County           2217        32.52      65.99\n3      Texas   Travis County         610349        26.43      71.41\n4      Texas   Zavala County           4379        34.03      65.40\n  total_votes_16 dem_pct_16\n1         210458      69.14\n2           2203      66.18\n3         462511      66.26\n4           3390      77.67\n\n\nExercise 3: arrange Demo\narrange() arranges or sorts the rows in a dataset according to a given column or variable, in ascending or descending order:\narrange(variable), arrange(desc(variable))\n\n# Arrange the counties in elections_small from lowest to highest percentage of 2020 Republican support\n# Print out just the first 6 rows\nelections_small |&gt;\n  arrange(repub_pct_20) |&gt;\n  head()\n\n            state_name            county_name total_votes_20 repub_pct_20\n1 District of Columbia   District of Columbia         344356         5.40\n2             Maryland Prince George's County         424855         8.73\n3             Maryland         Baltimore city         237461        10.69\n4             Virginia        Petersburg city          14118        11.22\n5             New York        New York County         694904        12.26\n6           California   San Francisco County         443458        12.72\n  dem_pct_20 total_votes_16 dem_pct_16\n1      92.15         280272      92.85\n2      89.26         351091      89.33\n3      87.28         208980      85.44\n4      87.75          13717      87.52\n5      86.78         591368      87.17\n6      85.27         365295      85.53\n\n\n\n# Arrange the counties in elections_small from highest to lowest percentage of 2020 Republican support\n# Print out just the first 6 rows\nelections_small |&gt;\n  arrange(desc(repub_pct_20)) |&gt;\n  head()\n\n  state_name      county_name total_votes_20 repub_pct_20 dem_pct_20\n1      Texas   Roberts County            550        96.18       3.09\n2      Texas    Borden County            416        95.43       3.85\n3      Texas      King County            159        94.97       5.03\n4    Montana  Garfield County            813        93.97       5.04\n5      Texas Glasscock County            653        93.57       5.97\n6   Nebraska     Grant County            402        93.28       4.98\n  total_votes_16 dem_pct_16\n1            550       3.64\n2            365       8.49\n3            159       3.14\n4            715       4.76\n5            602       5.65\n6            394       5.08\n\n\nExercise 4: mutate Demo\nmutate() can either transform / mutate an existing variable (column), or define a new variable based on existing ones.\nPart a\n\n# What did this code do?\nelections_small |&gt;\n  mutate(diff_20 = repub_pct_20 - dem_pct_20) |&gt;\n  head()\n\n  state_name    county_name total_votes_20 repub_pct_20 dem_pct_20\n1    Alabama Autauga County          27770        71.44      27.02\n2    Alabama Baldwin County         109679        76.17      22.41\n3    Alabama Barbour County          10518        53.45      45.79\n4    Alabama    Bibb County           9595        78.43      20.70\n5    Alabama  Blount County          27588        89.57       9.57\n6    Alabama Bullock County           4613        24.84      74.70\n  total_votes_16 dem_pct_16 diff_20\n1          24661      23.96   44.42\n2          94090      19.57   53.76\n3          10390      46.66    7.66\n4           8748      21.42   57.73\n5          25384       8.47   80.00\n6           4701      75.09  -49.86\n\n#Creates a new variable measuring the difference between the two parties support\n\n\n# What did this code do?\nelections_small |&gt;\n  mutate(repub_votes_20 = round(total_votes_20 * repub_pct_20/100)) |&gt;\n  head()\n\n  state_name    county_name total_votes_20 repub_pct_20 dem_pct_20\n1    Alabama Autauga County          27770        71.44      27.02\n2    Alabama Baldwin County         109679        76.17      22.41\n3    Alabama Barbour County          10518        53.45      45.79\n4    Alabama    Bibb County           9595        78.43      20.70\n5    Alabama  Blount County          27588        89.57       9.57\n6    Alabama Bullock County           4613        24.84      74.70\n  total_votes_16 dem_pct_16 repub_votes_20\n1          24661      23.96          19839\n2          94090      19.57          83542\n3          10390      46.66           5622\n4           8748      21.42           7525\n5          25384       8.47          24711\n6           4701      75.09           1146\n\n#creates a variable measuring the amount of republican votes taken from the total votes\n\n\n# What did this code do?\nelections_small |&gt;\n  mutate(repub_win_20 = repub_pct_20 &gt; dem_pct_20) |&gt;\n  head()\n\n  state_name    county_name total_votes_20 repub_pct_20 dem_pct_20\n1    Alabama Autauga County          27770        71.44      27.02\n2    Alabama Baldwin County         109679        76.17      22.41\n3    Alabama Barbour County          10518        53.45      45.79\n4    Alabama    Bibb County           9595        78.43      20.70\n5    Alabama  Blount County          27588        89.57       9.57\n6    Alabama Bullock County           4613        24.84      74.70\n  total_votes_16 dem_pct_16 repub_win_20\n1          24661      23.96         TRUE\n2          94090      19.57         TRUE\n3          10390      46.66         TRUE\n4           8748      21.42         TRUE\n5          25384       8.47         TRUE\n6           4701      75.09        FALSE\n\n#Creates a variable displaying if republicans won or not\n\nPart b\n\n# You try\n# Define a variable that calculates the change in Dem support in 2020 vs 2016\nelections_small |&gt;\n mutate(dem_support_change = dem_pct_20 - dem_pct_16) |&gt;\n head()\n\n  state_name    county_name total_votes_20 repub_pct_20 dem_pct_20\n1    Alabama Autauga County          27770        71.44      27.02\n2    Alabama Baldwin County         109679        76.17      22.41\n3    Alabama Barbour County          10518        53.45      45.79\n4    Alabama    Bibb County           9595        78.43      20.70\n5    Alabama  Blount County          27588        89.57       9.57\n6    Alabama Bullock County           4613        24.84      74.70\n  total_votes_16 dem_pct_16 dem_support_change\n1          24661      23.96               3.06\n2          94090      19.57               2.84\n3          10390      46.66              -0.87\n4           8748      21.42              -0.72\n5          25384       8.47               1.10\n6           4701      75.09              -0.39\n\n\n\n# You try\n# Define a variable that determines whether the Dem support was higher in 2020 than in 2016 (TRUE/FALSE)\nelections_small |&gt;\n mutate(dem_higher_yesno = dem_pct_20 &gt; dem_pct_16) |&gt;\n head()\n\n  state_name    county_name total_votes_20 repub_pct_20 dem_pct_20\n1    Alabama Autauga County          27770        71.44      27.02\n2    Alabama Baldwin County         109679        76.17      22.41\n3    Alabama Barbour County          10518        53.45      45.79\n4    Alabama    Bibb County           9595        78.43      20.70\n5    Alabama  Blount County          27588        89.57       9.57\n6    Alabama Bullock County           4613        24.84      74.70\n  total_votes_16 dem_pct_16 dem_higher_yesno\n1          24661      23.96             TRUE\n2          94090      19.57             TRUE\n3          10390      46.66            FALSE\n4           8748      21.42            FALSE\n5          25384       8.47             TRUE\n6           4701      75.09            FALSE\n\n\nExercise 5: Pipe Series\nLet’s now combine these verbs into a pipe series!\nPart a\n\n\n\n\n\n\nThink then Run\n\n\n\nBEFORE running the below chunk, what do you think it will produce? A graph of Wisconsin republican counties from 2020, arranged by the highest amount of votes\n\n\n\nelections_small |&gt;\n  filter(state_name == \"Wisconsin\",\n         repub_pct_20 &lt; dem_pct_20) |&gt;\n  arrange(desc(total_votes_20)) |&gt;\n  head()\n\n  state_name       county_name total_votes_20 repub_pct_20 dem_pct_20\n1  Wisconsin  Milwaukee County         458971        29.27      69.13\n2  Wisconsin       Dane County         344791        22.85      75.46\n3  Wisconsin       Rock County          85360        43.51      54.66\n4  Wisconsin  La Crosse County          67884        42.25      55.75\n5  Wisconsin Eau Claire County          58275        43.49      54.26\n6  Wisconsin    Portage County          40603        47.53      50.31\n  total_votes_16 dem_pct_16\n1         434970      66.44\n2         304729      71.38\n3          75043      52.42\n4          62785      51.61\n5          54080      50.43\n6          38123      48.59\n\n\nPart b\n\n\n\n\n\n\nThink then Run\n\n\n\nBEFORE trying, what do you think will happen if you change the order of filter and arrange:\n\nwe won’t get an error, but the results will be different\n\n\n\n\n# Now try it. Change the order of filter and arrange below.\nelections_small |&gt;  \n  arrange(desc(total_votes_20)) |&gt;\n  filter(state_name == \"Wisconsin\",\n         repub_pct_20 &lt; dem_pct_20) |&gt;\n  head()\n\n  state_name       county_name total_votes_20 repub_pct_20 dem_pct_20\n1  Wisconsin  Milwaukee County         458971        29.27      69.13\n2  Wisconsin       Dane County         344791        22.85      75.46\n3  Wisconsin       Rock County          85360        43.51      54.66\n4  Wisconsin  La Crosse County          67884        42.25      55.75\n5  Wisconsin Eau Claire County          58275        43.49      54.26\n6  Wisconsin    Portage County          40603        47.53      50.31\n  total_votes_16 dem_pct_16\n1         434970      66.44\n2         304729      71.38\n3          75043      52.42\n4          62785      51.61\n5          54080      50.43\n6          38123      48.59\n\n\nPart c\nSo the order of filter() and arrange() did not matter – rerranging them produces the same results. BUT what is one advantage of filtering before arranging? *keeping them in that order means that any errors from filtering arent hidden by arranging them\nPart d\n\n\n\n\n\n\nThink then Run\n\n\n\nBEFORE running the below chunk, what do you think it will produce? Creates a sheet of Delaware republican counties that won in 2020, alongside the amount of support by each party\n\n\n\nelections_small |&gt;\n  filter(state_name == \"Delaware\") |&gt;\n  mutate(repub_win_20 = repub_pct_20 &gt; dem_pct_20) |&gt;\n  select(county_name, repub_pct_20, dem_pct_20, repub_win_20)\n\n        county_name repub_pct_20 dem_pct_20 repub_win_20\n1       Kent County        47.12      51.19        FALSE\n2 New Castle County        30.72      67.81        FALSE\n3     Sussex County        55.07      43.82         TRUE\n\n\nPart e\n\n\n\n\n\n\nThink then Run\n\n\n\nBEFORE trying, what do you think will happen if you change the order of mutate and select:\n\nthe results will be the same\n\n\n\n\n# # Now try it. Change the order of mutate and select below.\n# elections_small |&gt;\n#   filter(state_name == \"Delaware\") |&gt;\n#   select(county_name, repub_pct_20, dem_pct_20, repub_win_20) |&gt;\n#   mutate(repub_win_20 = repub_pct_20 &gt; dem_pct_20) \n\nExercise 6: DIY Pipe Series\nWe’ve now learned 4 of the 6 wrangling verbs: select, filter, mutate, arrange. Let’s practice combining these into pipe series. Here are some hot tips:\n\nBefore writing any code, translate the prompt: how many distinct wrangling steps are needed and what verb do we need in each step?\nAdd each verb one at a time – don’t try writing a whole chunk at once.\n\nPart a\nShow just the counties in Minnesota and their Democratic 2020 vote percentage, from highest to lowest. Your answer should have just 2 columns.\n\nelections_small |&gt;\n  filter(state_name == \"Minnesota\") |&gt;\n  select(county_name, dem_pct_20) |&gt;\n  arrange(desc(dem_pct_20))\n\n                county_name dem_pct_20\n1             Ramsey County      71.50\n2           Hennepin County      70.46\n3               Cook County      65.58\n4          St. Louis County      56.64\n5             Dakota County      55.73\n6            Olmsted County      54.16\n7         Washington County      53.46\n8         Blue Earth County      50.84\n9               Clay County      50.74\n10              Lake County      50.64\n11          Nicollet County      50.31\n12           Carlton County      49.58\n13            Winona County      49.07\n14              Rice County      48.76\n15          Mahnomen County      48.26\n16             Anoka County      47.79\n17          Beltrami County      47.24\n18            Carver County      46.37\n19             Mower County      46.00\n20             Scott County      45.52\n21           Houston County      42.42\n22           Goodhue County      41.23\n23          Freeborn County      40.96\n24            Norman County      40.80\n25            Itasca County      40.61\n26       Koochiching County      38.41\n27          Watonwan County      38.20\n28           Kittson County      38.12\n29           Stevens County      37.80\n30           Stearns County      37.58\n31          Fillmore County      37.48\n32            Steele County      37.47\n33         Kandiyohi County      36.12\n34            Aitkin County      35.98\n35              Lyon County      35.94\n36     Lac qui Parle County      35.79\n37           Wabasha County      35.78\n38             Grant County      35.58\n39          Traverse County      35.46\n40         Big Stone County      35.41\n41        Pennington County      35.29\n42              Pope County      35.27\n43              Polk County      34.88\n44              Cass County      34.68\n45            Wright County      34.49\n46           Hubbard County      34.42\n47             Swift County      34.35\n48         Crow Wing County      34.17\n49           Chisago County      34.15\n50            Becker County      33.96\n51              Pine County      33.87\n52          Le Sueur County      33.73\n53          Chippewa County      33.67\n54            Nobles County      33.65\n55            Waseca County      33.65\n56             Dodge County      33.47\n57        Otter Tail County      32.85\n58            Benton County      32.70\n59           Douglas County      32.56\n60             Brown County      32.48\n61         Sherburne County      32.48\n62         Faribault County      31.98\n63          Red Lake County      31.47\n64          Renville County      30.71\n65            McLeod County      30.64\n66   Yellow Medicine County      30.54\n67           Lincoln County      30.08\n68        Cottonwood County      30.03\n69           Kanabec County      30.02\n70            Martin County      30.02\n71           Jackson County      29.99\n72        Mille Lacs County      29.98\n73            Wilkin County      29.91\n74              Rock County      29.69\n75            Murray County      29.60\n76            Isanti County      29.45\n77            Sibley County      28.60\n78            Meeker County      28.58\n79           Redwood County      28.43\n80 Lake of the Woods County      27.87\n81        Clearwater County      26.76\n82         Pipestone County      26.44\n83            Wadena County      26.35\n84            Roseau County      25.98\n85          Marshall County      25.33\n86              Todd County      24.79\n87          Morrison County      22.33\n\n\nPart b\nCreate a new dataset named mn_wi that sorts the counties in Minnesota and Wisconsin from lowest to highest in terms of the change in Democratic vote percentage in 2020 vs 2016. This dataset should include the following variables (and only these variables): state_name, county_name, dem_pct_20, dem_pct_16, and a variable measuring the change in Democratic vote percentage in 2020 vs 2016.\n\n# Define the dataset\n# Only store the results once you're confident that they're correct\nmn_wi &lt;- elections_small |&gt;\n  filter(state_name %in% c(\"Minnesota\", \"Wisconsin\")) |&gt;\n  mutate(dem_diff = dem_pct_20 - dem_pct_16) |&gt;\n  select(state_name, county_name, dem_pct_20, dem_pct_16, dem_diff)\n\n# Check out the first 6 rows to confirm your results\nhead(mn_wi)\n\n  state_name      county_name dem_pct_20 dem_pct_16 dem_diff\n1  Minnesota    Aitkin County      35.98      34.12     1.86\n2  Minnesota     Anoka County      47.79      41.01     6.78\n3  Minnesota    Becker County      33.96      30.47     3.49\n4  Minnesota  Beltrami County      47.24      40.76     6.48\n5  Minnesota    Benton County      32.70      28.33     4.37\n6  Minnesota Big Stone County      35.41      33.75     1.66\n\n\nPart c\nConstruct and discuss a plot of the county-level change in Democratic vote percent in 2020 vs 2016, and how this differs between Minnesota and Wisconsin.\n\nggplot(mn_wi, aes(x = dem_diff)) +\n  geom_histogram() +\n  facet_wrap(~state_name)\n\n\n\n\n\n\n\nExercise 7: summarize Demo\n6 verbs: select, filter, arrange, mutate, summarize, group_by\nLet’s talk about the last 2 verbs. summarize() (or equivalently summarise()) takes an entire data frame as input and outputs a single row with one or more summary statistics. For each chunk below, indicate what the code does.\n\n# What does this do?\nelections_small |&gt;\n  summarize(median(repub_pct_20))\n\n  median(repub_pct_20)\n1                68.29\n\n#gives the median of all levels of republican county support\n\n\n# What does this do?\nelections_small |&gt;\n  summarize(median_repub = median(repub_pct_20))\n\n  median_repub\n1        68.29\n\n#gives that same median but this time from a seperately created variable\n\n\n# What does this do?\nelections_small |&gt;\n  summarize(median_repub = median(repub_pct_20), total_votes = sum(total_votes_20))\n\n  median_repub total_votes\n1        68.29   157949293\n\n#gives the median republican support like before but this time with another column for the sum of all votes\n\nExercise 8: summarize + group_by demo\nFinally, group_by() groups the units of observation or rows of a data frame by a specified set of variables. Alone, this function doesn’t change the appearance of our dataset or seem to do anything at all:\n\nelections_small |&gt;\n  group_by(state_name)\n\n# A tibble: 3,109 × 7\n# Groups:   state_name [50]\n   state_name county_name  total_votes_20 repub_pct_20 dem_pct_20 total_votes_16\n   &lt;chr&gt;      &lt;chr&gt;                 &lt;int&gt;        &lt;dbl&gt;      &lt;dbl&gt;          &lt;int&gt;\n 1 Alabama    Autauga Cou…          27770         71.4      27.0           24661\n 2 Alabama    Baldwin Cou…         109679         76.2      22.4           94090\n 3 Alabama    Barbour Cou…          10518         53.4      45.8           10390\n 4 Alabama    Bibb County            9595         78.4      20.7            8748\n 5 Alabama    Blount Coun…          27588         89.6       9.57          25384\n 6 Alabama    Bullock Cou…           4613         24.8      74.7            4701\n 7 Alabama    Butler Coun…           9488         57.5      41.8            8685\n 8 Alabama    Calhoun Cou…          50983         68.8      29.8           47376\n 9 Alabama    Chambers Co…          15284         57.3      41.6           13778\n10 Alabama    Cherokee Co…          12301         86.0      13.2           10503\n# ℹ 3,099 more rows\n# ℹ 1 more variable: dem_pct_16 &lt;dbl&gt;\n\n\nThough it does change the underlying structure of the dataset:\n\n#Check out the structure before and after group_by\nelections_small |&gt;\n  class()\n\n[1] \"data.frame\"\n\nelections_small |&gt;\n  group_by(state_name) |&gt;\n  class()\n\n[1] \"grouped_df\" \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\nWhere it really shines is in partnership with summarize().\n\n# What does this do?\n# (What if we didn't use group_by?)\nelections_small |&gt;\n  group_by(state_name) |&gt;\n  summarize(median_repub = median(repub_pct_20), total_votes = sum(total_votes_20))\n\n# A tibble: 50 × 3\n   state_name           median_repub total_votes\n   &lt;chr&gt;                       &lt;dbl&gt;       &lt;int&gt;\n 1 Alabama                      70.6     2323304\n 2 Arizona                      57.9     3387326\n 3 Arkansas                     72.1     1219069\n 4 California                   44.8    17495906\n 5 Colorado                     56.2     3256953\n 6 Connecticut                  41.0     1824280\n 7 Delaware                     47.1      504010\n 8 District of Columbia          5.4      344356\n 9 Florida                      64.6    11067456\n10 Georgia                      68       4997716\n# ℹ 40 more rows\n\n\n\n\n\n\n\n\nReflect\n\n\n\nNotice that group_by() with summarize() produces new data frame or tibble! But the units of observation are now states instead of counties within states.\n\n\nExercise 9: DIY\nLet’s practice (some of) our 6 verbs: select, filter, arrange, mutate, summarize, group_by Remember:\n\nBefore writing any code, translate the given prompts: how many distinct wrangling steps are needed and what verb do we need in each step?\nAdd each verb one at a time.\n\nPart a\nNOTE: Part a is a challenge exercise. If you get really stuck, move on to Part b which is the same overall question, but with hints.\n\n# Sort the *states* from the most to least total votes cast in 2020\nelections_small |&gt; \n  group_by(state_name) |&gt; \n  summarize(total = sum(total_votes_20)) |&gt; \n  arrange(desc(total))\n\n# A tibble: 50 × 2\n   state_name        total\n   &lt;chr&gt;             &lt;int&gt;\n 1 California     17495906\n 2 Texas          11317911\n 3 Florida        11067456\n 4 New York        8616205\n 5 Pennsylvania    6925255\n 6 Illinois        6038850\n 7 Ohio            5922202\n 8 Michigan        5539302\n 9 North Carolina  5524801\n10 Georgia         4997716\n# ℹ 40 more rows\n\n\n\n# In 2020, what were the total number of votes for the Democratic candidate and the total number of votes for the Republican candidate in each *state*?\nelections_small |&gt;\n  group_by(state_name) |&gt;\n  mutate(dem_votes_20 = round(total_votes_20 * dem_pct_20 / 100), \n         repub_votes_20 = round(total_votes_20 * repub_pct_20 / 100)) |&gt; \n  group_by(state_name) |&gt; \n  summarize(dem_total = sum(dem_votes_20),\n            repub_total = sum(repub_votes_20))\n\n# A tibble: 50 × 3\n   state_name           dem_total repub_total\n   &lt;chr&gt;                    &lt;dbl&gt;       &lt;dbl&gt;\n 1 Alabama                 849664     1441155\n 2 Arizona                1672127     1661671\n 3 Arkansas                423919      760641\n 4 California            11109642     6006031\n 5 Colorado               1804393     1364627\n 6 Connecticut            1080677      715315\n 7 Delaware                296274      200601\n 8 District of Columbia    317324       18595\n 9 Florida                5297131     5668600\n10 Georgia                2473661     2461869\n# ℹ 40 more rows\n\n\n\n# What states did the Democratic candidate win in 2020?\nelections_small |&gt; \n  mutate(dem_votes_20 = round(total_votes_20 * dem_pct_20 / 100), \n         repub_votes_20 = round(total_votes_20 * repub_pct_20 / 100)) |&gt; \n  group_by(state_name) |&gt; \n  summarize(dem_total = sum(dem_votes_20),\n            repub_total = sum(repub_votes_20)) |&gt; \n  filter(dem_total &gt; repub_total)\n\n# A tibble: 26 × 3\n   state_name           dem_total repub_total\n   &lt;chr&gt;                    &lt;dbl&gt;       &lt;dbl&gt;\n 1 Arizona                1672127     1661671\n 2 California            11109642     6006031\n 3 Colorado               1804393     1364627\n 4 Connecticut            1080677      715315\n 5 Delaware                296274      200601\n 6 District of Columbia    317324       18595\n 7 Georgia                2473661     2461869\n 8 Hawaii                  366121      196865\n 9 Illinois               3471916     2446931\n10 Maine                   430466      359897\n# ℹ 16 more rows\n\n\nPart b\n\n# Sort the states from the most to least total votes cast in 2020\n# HINT: Calculate the total number of votes in each state, then sort\nelections_small |&gt;\n  group_by(state_name) |&gt;\n  summarize(total = total_votes_20) |&gt;\n  arrange(desc(total))\n\n# A tibble: 3,109 × 2\n# Groups:   state_name [50]\n   state_name   total\n   &lt;chr&gt;        &lt;int&gt;\n 1 California 4263443\n 2 Illinois   2321399\n 3 Arizona    2069475\n 4 Texas      1640818\n 5 California 1601722\n 6 California 1521725\n 7 Washington 1210507\n 8 Florida    1156816\n 9 California  996156\n10 Nevada      972510\n# ℹ 3,099 more rows\n\n\n\n# In 2020, what were the total number of votes for the Democratic candidate and the total number of votes for the Republican candidate in each state?\n# HINT: First calculate the number of Dem and Repub votes in each *county*\n# Then group and summarize these by state\n\n\n# What states did the Democratic candidate win in 2020?\n# HINT: Start with the results from the previous chunk, and then keep only some rows\n\nExercise 10: Practice on New Data\nRecall the World Cup football/soccer data from TidyTuesday:\n\nworld_cup &lt;- read.csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-11-29/worldcups.csv\")\n\nYou can find a codebook here. Use (some of) our 6 verbs (select, filter, arrange, mutate, summarize, group_by) and data viz to address the following prompts.\n\n# In what years did Brazil win the World Cup?\nworld_cup |&gt;\n  filter(winner == \"Brazil\")\n\n  year               host winner         second        third       fourth\n1 1958             Sweden Brazil         Sweden       France West Germany\n2 1962              Chile Brazil Czechoslovakia        Chile   Yugoslavia\n3 1970             Mexico Brazil          Italy West Germany      Uruguay\n4 1994                USA Brazil          Italy       Sweden     Bulgaria\n5 2002 Japan, South Korea Brazil        Germany       Turkey  South Korea\n  goals_scored teams games attendance\n1          126    16    35     868000\n2           89    16    32     776000\n3           95    16    32    1673975\n4          141    24    52    3568567\n5          161    32    64    2724604\n\n\n\n# What were the 6 World Cups with the highest attendance?\nworld_cup |&gt;\n  arrange(desc(attendance)) |&gt;\nhead()\n\n  year               host  winner    second       third      fourth\n1 1994                USA  Brazil     Italy      Sweden    Bulgaria\n2 2014             Brazil Germany Argentina Netherlands      Brazil\n3 2006            Germany   Italy    France     Germany    Portugal\n4 2018             Russia  France   Croatia     Belgium     England\n5 1998             France  France    Brazil     Croatia Netherlands\n6 2002 Japan, South Korea  Brazil   Germany      Turkey South Korea\n  goals_scored teams games attendance\n1          141    24    52    3568567\n2          171    32    64    3441450\n3          147    32    64    3367000\n4          169    32    64    3031768\n5          171    32    64    2859234\n6          161    32    64    2724604\n\n\n\n# Construct a univariate plot of goals_scored (no wrangling necessary)\n# This provides a visual summary of how the number of goals_scored varies from World Cup to World Cup\nggplot(world_cup, aes(x = goals_scored)) +\n  geom_histogram(color = \"white\") \n\n\n\n\n\n\n\n\n# Let's follow up the plot with some more precise numerical summaries\n# Calculate the min, median, and max number of goals_scored across all World Cups\n# NOTE: Visually compare these numerical summaries to what you observed in the plot\nworld_cup |&gt;\n  summarize(min(goals_scored), median(goals_scored), max(goals_scored))\n\n  min(goals_scored) median(goals_scored) max(goals_scored)\n1                70                  126               171\n\n\n\n# Construct a bivariate plot of how the number of goals_scored in the World Cup has changed over the years\n# No wrangling necessary\nggplot(world_cup, aes(x = year, y = goals_scored)) +\n  geom_point() +\n  geom_line()\n\n\n\n\n\n\n\n\n# Our above summaries might be a bit misleading.\n# The number of games played at the World Cup varies.\n# Construct a bivariate plot of how the typical number of goals per game has changed over the years\nper_game_data &lt;- world_cup |&gt; \n  mutate(goals_per_game = goals_scored / games)\n\nggplot(per_game_data, aes(x = year, y = goals_per_game)) +\n  geom_point() +\n  geom_line()\n\n\n\n\n\n\n\nExercise 11: Practice on Your Data\nReturn to the TidyTuesday data you’re using in Homework 3. Use your new wrangling skills to play around. What new insights can you gain?!",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Wrangling</span>"
    ]
  },
  {
    "objectID": "ica/ica-wrangling.html#solutions",
    "href": "ica/ica-wrangling.html#solutions",
    "title": "\n18  Wrangling\n",
    "section": "\n18.6 Solutions",
    "text": "18.6 Solutions\n\nClick for Solutions\n\n18.6.1 Example 1\n\nselect\nfilter\nmutate\narrange\nsummarize\nExercise 1: select Practice\n\n# Define elections_small\nelections_small &lt;- elections |&gt;\n  select(state_name, county_name, total_votes_20, repub_pct_20, dem_pct_20, total_votes_16, dem_pct_16)\n\n# Check out the first 6 rows to confirm your code did what you think it did!\nhead(elections_small)\n\n  state_name    county_name total_votes_20 repub_pct_20 dem_pct_20\n1    Alabama Autauga County          27770        71.44      27.02\n2    Alabama Baldwin County         109679        76.17      22.41\n3    Alabama Barbour County          10518        53.45      45.79\n4    Alabama    Bibb County           9595        78.43      20.70\n5    Alabama  Blount County          27588        89.57       9.57\n6    Alabama Bullock County           4613        24.84      74.70\n  total_votes_16 dem_pct_16\n1          24661      23.96\n2          94090      19.57\n3          10390      46.66\n4           8748      21.42\n5          25384       8.47\n6           4701      75.09\n\n\nExercise 2: filter Demo\n\n# Keep only data on counties in Hawaii\nelections_small |&gt;\n filter(state_name == \"Hawaii\")\n\n  state_name     county_name total_votes_20 repub_pct_20 dem_pct_20\n1     Hawaii   Hawaii County          87814        30.63      66.88\n2     Hawaii Honolulu County         382114        35.66      62.51\n3     Hawaii    Kauai County          33497        34.58      63.36\n4     Hawaii     Maui County          71044        31.14      66.59\n  total_votes_16 dem_pct_16\n1          64865      63.61\n2         285683      61.48\n3          26335      62.49\n4          51942      64.45\n\n\n\n# Keep counties in Hawaii AND Delaware\nelections_small |&gt; \n  filter(state_name %in% c(\"Hawaii\", \"Delaware\"))\n\n  state_name       county_name total_votes_20 repub_pct_20 dem_pct_20\n1   Delaware       Kent County          87025        47.12      51.19\n2   Delaware New Castle County         287633        30.72      67.81\n3   Delaware     Sussex County         129352        55.07      43.82\n4     Hawaii     Hawaii County          87814        30.63      66.88\n5     Hawaii   Honolulu County         382114        35.66      62.51\n6     Hawaii      Kauai County          33497        34.58      63.36\n7     Hawaii       Maui County          71044        31.14      66.59\n  total_votes_16 dem_pct_16\n1          74253      44.91\n2         261468      62.30\n3         105814      37.17\n4          64865      63.61\n5         285683      61.48\n6          26335      62.49\n7          51942      64.45\n\n\n\n# Keep only data on counties where the Republican got MORE THAN 93.97% of the vote in 2020\nelections_small |&gt; \n  filter(repub_pct_20 &gt; 93.97)\n\n  state_name    county_name total_votes_20 repub_pct_20 dem_pct_20\n1      Texas  Borden County            416        95.43       3.85\n2      Texas    King County            159        94.97       5.03\n3      Texas Roberts County            550        96.18       3.09\n  total_votes_16 dem_pct_16\n1            365       8.49\n2            159       3.14\n3            550       3.64\n\n\n\n# Keep only data on counties where the Republican got AT LEAST 93.97% of the vote in 2020\n# This should have 1 more row than your answer above\nelections_small |&gt; \n  filter(repub_pct_20 &gt;= 93.97)\n\n  state_name     county_name total_votes_20 repub_pct_20 dem_pct_20\n1    Montana Garfield County            813        93.97       5.04\n2      Texas   Borden County            416        95.43       3.85\n3      Texas     King County            159        94.97       5.03\n4      Texas  Roberts County            550        96.18       3.09\n  total_votes_16 dem_pct_16\n1            715       4.76\n2            365       8.49\n3            159       3.14\n4            550       3.64\n\n\n\n# Keep only data on counties in Texas where the Democrat got more than 65% of the vote in 2020\n# Do this 2 ways.\n# Method 1: 2 filters with 1 condition each\nelections_small |&gt;\n filter(state_name == \"Texas\") |&gt;\n filter(dem_pct_20 &gt; 65)\n\n  state_name     county_name total_votes_20 repub_pct_20 dem_pct_20\n1      Texas  El Paso County         267215        31.56      66.66\n2      Texas Presidio County           2217        32.52      65.99\n3      Texas   Travis County         610349        26.43      71.41\n4      Texas   Zavala County           4379        34.03      65.40\n  total_votes_16 dem_pct_16\n1         210458      69.14\n2           2203      66.18\n3         462511      66.26\n4           3390      77.67\n\n# Method 2: 1 filter with 2 conditions\nelections_small |&gt;\n filter(state_name == \"Texas\", dem_pct_20 &gt; 65)\n\n  state_name     county_name total_votes_20 repub_pct_20 dem_pct_20\n1      Texas  El Paso County         267215        31.56      66.66\n2      Texas Presidio County           2217        32.52      65.99\n3      Texas   Travis County         610349        26.43      71.41\n4      Texas   Zavala County           4379        34.03      65.40\n  total_votes_16 dem_pct_16\n1         210458      69.14\n2           2203      66.18\n3         462511      66.26\n4           3390      77.67\n\n\nExercise 3: arrange Demo\n\n# Arrange the counties in elections_small from lowest to highest percentage of 2020 Republican support\n# Print out just the first 6 rows\nelections_small |&gt;\n  arrange(repub_pct_20) |&gt;\n  head()\n\n            state_name            county_name total_votes_20 repub_pct_20\n1 District of Columbia   District of Columbia         344356         5.40\n2             Maryland Prince George's County         424855         8.73\n3             Maryland         Baltimore city         237461        10.69\n4             Virginia        Petersburg city          14118        11.22\n5             New York        New York County         694904        12.26\n6           California   San Francisco County         443458        12.72\n  dem_pct_20 total_votes_16 dem_pct_16\n1      92.15         280272      92.85\n2      89.26         351091      89.33\n3      87.28         208980      85.44\n4      87.75          13717      87.52\n5      86.78         591368      87.17\n6      85.27         365295      85.53\n\n\n\n# Arrange the counties in elections_small from highest to lowest percentage of 2020 Republican support\n# Print out just the first 6 rows\nelections_small |&gt;\n  arrange(desc(repub_pct_20)) |&gt;\n  head()\n\n  state_name      county_name total_votes_20 repub_pct_20 dem_pct_20\n1      Texas   Roberts County            550        96.18       3.09\n2      Texas    Borden County            416        95.43       3.85\n3      Texas      King County            159        94.97       5.03\n4    Montana  Garfield County            813        93.97       5.04\n5      Texas Glasscock County            653        93.57       5.97\n6   Nebraska     Grant County            402        93.28       4.98\n  total_votes_16 dem_pct_16\n1            550       3.64\n2            365       8.49\n3            159       3.14\n4            715       4.76\n5            602       5.65\n6            394       5.08\n\n\nExercise 4: mutate Demo\n\n# Define diff_20, the difference btwn the Repub and Dem percent in 2020\nelections_small |&gt; \n  mutate(diff_20 = repub_pct_20 - dem_pct_20) |&gt; \n  head()\n\n  state_name    county_name total_votes_20 repub_pct_20 dem_pct_20\n1    Alabama Autauga County          27770        71.44      27.02\n2    Alabama Baldwin County         109679        76.17      22.41\n3    Alabama Barbour County          10518        53.45      45.79\n4    Alabama    Bibb County           9595        78.43      20.70\n5    Alabama  Blount County          27588        89.57       9.57\n6    Alabama Bullock County           4613        24.84      74.70\n  total_votes_16 dem_pct_16 diff_20\n1          24661      23.96   44.42\n2          94090      19.57   53.76\n3          10390      46.66    7.66\n4           8748      21.42   57.73\n5          25384       8.47   80.00\n6           4701      75.09  -49.86\n\n\n\n# Define repub_votes_20, the number (not percent) of Repub votes in 2020\nelections_small |&gt; \n  mutate(repub_votes_20 = round(total_votes_20 * repub_pct_20/100)) |&gt; \n  head()\n\n  state_name    county_name total_votes_20 repub_pct_20 dem_pct_20\n1    Alabama Autauga County          27770        71.44      27.02\n2    Alabama Baldwin County         109679        76.17      22.41\n3    Alabama Barbour County          10518        53.45      45.79\n4    Alabama    Bibb County           9595        78.43      20.70\n5    Alabama  Blount County          27588        89.57       9.57\n6    Alabama Bullock County           4613        24.84      74.70\n  total_votes_16 dem_pct_16 repub_votes_20\n1          24661      23.96          19839\n2          94090      19.57          83542\n3          10390      46.66           5622\n4           8748      21.42           7525\n5          25384       8.47          24711\n6           4701      75.09           1146\n\n\n\n# Define repub_win_20, whether the Repub won in 2020 (TRUE or FALSE!)\nelections_small |&gt; \n  mutate(repub_win_20 = repub_pct_20 &gt; dem_pct_20) |&gt; \n  head()\n\n  state_name    county_name total_votes_20 repub_pct_20 dem_pct_20\n1    Alabama Autauga County          27770        71.44      27.02\n2    Alabama Baldwin County         109679        76.17      22.41\n3    Alabama Barbour County          10518        53.45      45.79\n4    Alabama    Bibb County           9595        78.43      20.70\n5    Alabama  Blount County          27588        89.57       9.57\n6    Alabama Bullock County           4613        24.84      74.70\n  total_votes_16 dem_pct_16 repub_win_20\n1          24661      23.96         TRUE\n2          94090      19.57         TRUE\n3          10390      46.66         TRUE\n4           8748      21.42         TRUE\n5          25384       8.47         TRUE\n6           4701      75.09        FALSE\n\n\nExercise 5: Pipe Series\nPart c\nIt’s more “computationally efficient” to get rid of some rows before arranging.\nPart e\nWe can’t select a variable before we define it!\nExercise 6: DIY Pipe Series\nPart a\nHere’s my translation:\n\njust the counties in Minnesota —&gt; filter\njust the counties in Minnesota and their Democratic 2020 vote percentage —&gt; select\nfrom highest to lowest —&gt; arrange\n\n\n# Remember to try this 1 line at a time\nelections_small |&gt; \n  filter(state_name == \"Minnesota\") |&gt; \n  select(county_name, dem_pct_20) |&gt; \n  arrange(desc(dem_pct_20))\n\n                county_name dem_pct_20\n1             Ramsey County      71.50\n2           Hennepin County      70.46\n3               Cook County      65.58\n4          St. Louis County      56.64\n5             Dakota County      55.73\n6            Olmsted County      54.16\n7         Washington County      53.46\n8         Blue Earth County      50.84\n9               Clay County      50.74\n10              Lake County      50.64\n11          Nicollet County      50.31\n12           Carlton County      49.58\n13            Winona County      49.07\n14              Rice County      48.76\n15          Mahnomen County      48.26\n16             Anoka County      47.79\n17          Beltrami County      47.24\n18            Carver County      46.37\n19             Mower County      46.00\n20             Scott County      45.52\n21           Houston County      42.42\n22           Goodhue County      41.23\n23          Freeborn County      40.96\n24            Norman County      40.80\n25            Itasca County      40.61\n26       Koochiching County      38.41\n27          Watonwan County      38.20\n28           Kittson County      38.12\n29           Stevens County      37.80\n30           Stearns County      37.58\n31          Fillmore County      37.48\n32            Steele County      37.47\n33         Kandiyohi County      36.12\n34            Aitkin County      35.98\n35              Lyon County      35.94\n36     Lac qui Parle County      35.79\n37           Wabasha County      35.78\n38             Grant County      35.58\n39          Traverse County      35.46\n40         Big Stone County      35.41\n41        Pennington County      35.29\n42              Pope County      35.27\n43              Polk County      34.88\n44              Cass County      34.68\n45            Wright County      34.49\n46           Hubbard County      34.42\n47             Swift County      34.35\n48         Crow Wing County      34.17\n49           Chisago County      34.15\n50            Becker County      33.96\n51              Pine County      33.87\n52          Le Sueur County      33.73\n53          Chippewa County      33.67\n54            Nobles County      33.65\n55            Waseca County      33.65\n56             Dodge County      33.47\n57        Otter Tail County      32.85\n58            Benton County      32.70\n59           Douglas County      32.56\n60             Brown County      32.48\n61         Sherburne County      32.48\n62         Faribault County      31.98\n63          Red Lake County      31.47\n64          Renville County      30.71\n65            McLeod County      30.64\n66   Yellow Medicine County      30.54\n67           Lincoln County      30.08\n68        Cottonwood County      30.03\n69           Kanabec County      30.02\n70            Martin County      30.02\n71           Jackson County      29.99\n72        Mille Lacs County      29.98\n73            Wilkin County      29.91\n74              Rock County      29.69\n75            Murray County      29.60\n76            Isanti County      29.45\n77            Sibley County      28.60\n78            Meeker County      28.58\n79           Redwood County      28.43\n80 Lake of the Woods County      27.87\n81        Clearwater County      26.76\n82         Pipestone County      26.44\n83            Wadena County      26.35\n84            Roseau County      25.98\n85          Marshall County      25.33\n86              Todd County      24.79\n87          Morrison County      22.33\n\n\nPart b\nHere’s my translation:\n\ncounties in Minnesota and Wisconsin —&gt; filter\nchange in Democratic vote percentage in 2020 vs 2016 —&gt; mutate (we don’t already have this)\nsorts the counties from highest to lowest —&gt; arrange\ninclude the following variables (and only these variables) —&gt; select\n\n\n# Remember to try this 1 line at a time before storing!\nmn_wi &lt;- elections_small |&gt; \n  filter(state_name %in% c(\"Minnesota\", \"Wisconsin\")) |&gt; \n  select(state_name, county_name, dem_pct_20, dem_pct_16) |&gt;\n  mutate(dem_change = dem_pct_20 - dem_pct_16) |&gt; \n  arrange(dem_change)\n  \n# Check it out\nhead(mn_wi)\n\n  state_name        county_name dem_pct_20 dem_pct_16 dem_change\n1  Minnesota     Stevens County      37.80      39.55      -1.75\n2  Wisconsin      Forest County      34.06      35.12      -1.06\n3  Wisconsin    Kewaunee County      32.87      33.73      -0.86\n4  Wisconsin       Clark County      30.37      31.19      -0.82\n5  Wisconsin       Adams County      36.63      37.40      -0.77\n6  Wisconsin Trempealeau County      40.86      41.57      -0.71\n\n\nPart c\nThere was a stronger Dem shift from 2016 to 2020 in Minnesota. Further, in most counties across both states, the percent Dem tended to be higher in 2020 than in 2016.\n\nggplot(mn_wi, aes(x = dem_change, fill = state_name)) + \n  geom_density(alpha = 0.5)\n\n\n\n\n\n\nggplot(mn_wi, aes(y = dem_change, x = state_name)) + \n  geom_boxplot()\n\n\n\n\n\n\n\nExercise 7: summarize Demo\n\n# Calculate the median Repub vote percentage in 2020 across all counties\nelections_small |&gt; \n  summarize(median(repub_pct_20))\n\n  median(repub_pct_20)\n1                68.29\n\n\n\n# Calculate the median Repub vote percentage in 2020 across all counties\n# AND name it \"median_repub\"\nelections_small |&gt; \n  summarize(median_repub = median(repub_pct_20))\n\n  median_repub\n1        68.29\n\n\n\n# Calculate the median Repub vote percentage in 2020 across all counties\n# AND the total number of votes across all counties\n# AND name the results\nelections_small |&gt; \n  summarize(median_repub = median(repub_pct_20), total_votes = sum(total_votes_20))\n\n  median_repub total_votes\n1        68.29   157949293\n\n\nExercise 8: summarize + group_by demo\n\n# Calculate the median 2020 Repub percent and total votes BY STATE\nelections_small |&gt; \n  group_by(state_name) |&gt; \n  summarize(median_repub = median(repub_pct_20), total_votes = sum(total_votes_20)) \n\n# A tibble: 50 × 3\n   state_name           median_repub total_votes\n   &lt;chr&gt;                       &lt;dbl&gt;       &lt;int&gt;\n 1 Alabama                      70.6     2323304\n 2 Arizona                      57.9     3387326\n 3 Arkansas                     72.1     1219069\n 4 California                   44.8    17495906\n 5 Colorado                     56.2     3256953\n 6 Connecticut                  41.0     1824280\n 7 Delaware                     47.1      504010\n 8 District of Columbia          5.4      344356\n 9 Florida                      64.6    11067456\n10 Georgia                      68       4997716\n# ℹ 40 more rows\n\n\nExercise 9: DIY\nPart a\n\n# Sort the states from the most to least total votes in 2020\nelections_small |&gt; \n  group_by(state_name) |&gt; \n  summarize(total = sum(total_votes_20)) |&gt; \n  arrange(desc(total))\n\n# A tibble: 50 × 2\n   state_name        total\n   &lt;chr&gt;             &lt;int&gt;\n 1 California     17495906\n 2 Texas          11317911\n 3 Florida        11067456\n 4 New York        8616205\n 5 Pennsylvania    6925255\n 6 Illinois        6038850\n 7 Ohio            5922202\n 8 Michigan        5539302\n 9 North Carolina  5524801\n10 Georgia         4997716\n# ℹ 40 more rows\n\n\n\n# In 2020, what were the total number of votes for the Democratic candidate and the total number of votes for the Republican candidate in each *state*?\nelections_small |&gt; \n  mutate(dem_votes_20 = round(total_votes_20 * dem_pct_20 / 100), \n         repub_votes_20 = round(total_votes_20 * repub_pct_20 / 100)) |&gt; \n  group_by(state_name) |&gt; \n  summarize(dem_total = sum(dem_votes_20),\n            repub_total = sum(repub_votes_20))\n\n# A tibble: 50 × 3\n   state_name           dem_total repub_total\n   &lt;chr&gt;                    &lt;dbl&gt;       &lt;dbl&gt;\n 1 Alabama                 849664     1441155\n 2 Arizona                1672127     1661671\n 3 Arkansas                423919      760641\n 4 California            11109642     6006031\n 5 Colorado               1804393     1364627\n 6 Connecticut            1080677      715315\n 7 Delaware                296274      200601\n 8 District of Columbia    317324       18595\n 9 Florida                5297131     5668600\n10 Georgia                2473661     2461869\n# ℹ 40 more rows\n\n\n\n# What states did the Democratic candidate win in 2020?\nelections_small |&gt; \n  mutate(dem_votes_20 = round(total_votes_20 * dem_pct_20 / 100), \n         repub_votes_20 = round(total_votes_20 * repub_pct_20 / 100)) |&gt; \n  group_by(state_name) |&gt; \n  summarize(dem_total = sum(dem_votes_20),\n            repub_total = sum(repub_votes_20)) |&gt; \n  filter(dem_total &gt; repub_total)\n\n# A tibble: 26 × 3\n   state_name           dem_total repub_total\n   &lt;chr&gt;                    &lt;dbl&gt;       &lt;dbl&gt;\n 1 Arizona                1672127     1661671\n 2 California            11109642     6006031\n 3 Colorado               1804393     1364627\n 4 Connecticut            1080677      715315\n 5 Delaware                296274      200601\n 6 District of Columbia    317324       18595\n 7 Georgia                2473661     2461869\n 8 Hawaii                  366121      196865\n 9 Illinois               3471916     2446931\n10 Maine                   430466      359897\n# ℹ 16 more rows\n\n\nExercise 10: Practice on New Data\n\n# In what years did Brazil win the World Cup?\nworld_cup |&gt; \n  filter(winner == \"Brazil\")\n\n  year               host winner         second        third       fourth\n1 1958             Sweden Brazil         Sweden       France West Germany\n2 1962              Chile Brazil Czechoslovakia        Chile   Yugoslavia\n3 1970             Mexico Brazil          Italy West Germany      Uruguay\n4 1994                USA Brazil          Italy       Sweden     Bulgaria\n5 2002 Japan, South Korea Brazil        Germany       Turkey  South Korea\n  goals_scored teams games attendance\n1          126    16    35     868000\n2           89    16    32     776000\n3           95    16    32    1673975\n4          141    24    52    3568567\n5          161    32    64    2724604\n\n\n\n# What were the 6 World Cups with the highest attendance?\nworld_cup |&gt; \n  arrange(desc(attendance)) |&gt; \n  head()\n\n  year               host  winner    second       third      fourth\n1 1994                USA  Brazil     Italy      Sweden    Bulgaria\n2 2014             Brazil Germany Argentina Netherlands      Brazil\n3 2006            Germany   Italy    France     Germany    Portugal\n4 2018             Russia  France   Croatia     Belgium     England\n5 1998             France  France    Brazil     Croatia Netherlands\n6 2002 Japan, South Korea  Brazil   Germany      Turkey South Korea\n  goals_scored teams games attendance\n1          141    24    52    3568567\n2          171    32    64    3441450\n3          147    32    64    3367000\n4          169    32    64    3031768\n5          171    32    64    2859234\n6          161    32    64    2724604\n\n\n\n# Construct a univariate plot of goals_scored (no wrangling necessary)\n# This provides a visual summary of how the number of goals_scored varies from World Cup to World Cup\nggplot(world_cup, aes(x = goals_scored)) + \n  geom_histogram(color = \"white\")\n\n\n\n\n\n\n\n\n# Let's follow up the plot with some more precise numerical summaries\n# Calculate the min, median, and max number of goals_scored across all World Cups\n# NOTE: Visually compare these numerical summaries to what you observed in the plot\nworld_cup |&gt; \n  summarize(min(goals_scored), median(goals_scored), max(goals_scored))\n\n  min(goals_scored) median(goals_scored) max(goals_scored)\n1                70                  126               171\n\n\n\n# Construct a bivariate plot of how the number of goals_scored in the World Cup has changed over the years\n# No wrangling necessary\nggplot(world_cup, aes(x = year, y = goals_scored)) + \n  geom_point() + \n  geom_line()\n\n\n\n\n\n\n\n\n# Our above summaries might be a bit misleading.\n# The number of games played at the World Cup varies.\n# Construct a bivariate plot of how the typical number of goals per game has changed over the years\nper_game_data &lt;- world_cup |&gt; \n  mutate(goals_per_game = goals_scored / games)\n\nggplot(per_game_data, aes(x = year, y = goals_per_game)) + \n  geom_point() + \n  geom_line()",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Wrangling</span>"
    ]
  },
  {
    "objectID": "ica/ica-dates.html",
    "href": "ica/ica-dates.html",
    "title": "\n19  Reshaping\n",
    "section": "",
    "text": "19.1 Review",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Reshaping</span>"
    ]
  },
  {
    "objectID": "ica/ica-dates.html#review",
    "href": "ica/ica-dates.html#review",
    "title": "\n19  Reshaping\n",
    "section": "",
    "text": "EXAMPLE 1: warm-up counts and proportions\nRecall the penguins we worked with last class:\n\nlibrary(tidyverse)\npenguins &lt;- read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-07-28/penguins.csv')\n\nTally up the number of male/female penguins by species in 2 ways:\n\n# Using count()\npenguins |&gt;\n  count(species, sex)\n\n# A tibble: 8 × 3\n  species   sex        n\n  &lt;chr&gt;     &lt;chr&gt;  &lt;int&gt;\n1 Adelie    female    73\n2 Adelie    male      73\n3 Adelie    &lt;NA&gt;       6\n4 Chinstrap female    34\n5 Chinstrap male      34\n6 Gentoo    female    58\n7 Gentoo    male      61\n8 Gentoo    &lt;NA&gt;       5\n\n# Using group_by() and summarize()\npenguins |&gt; \n  group_by(species, sex) |&gt; \n  summarize(n())\n\n# A tibble: 8 × 3\n# Groups:   species [3]\n  species   sex    `n()`\n  &lt;chr&gt;     &lt;chr&gt;  &lt;int&gt;\n1 Adelie    female    73\n2 Adelie    male      73\n3 Adelie    &lt;NA&gt;       6\n4 Chinstrap female    34\n5 Chinstrap male      34\n6 Gentoo    female    58\n7 Gentoo    male      61\n8 Gentoo    &lt;NA&gt;       5\n\n\nDefine a new column that includes the proportion or relative frequencies of male/female penguins in each species.\n\nWe can’t do this by adjusting our count() code, but can adjust the group_by() and summarize() code since it’s still tracking the group categories in the background.\nDoes the order of species and sex in group_by() matter?\n\n\npenguins |&gt;\n  #changes proportion to the species within each sex\n  group_by(sex, species) |&gt; \n  summarize(n = n()) |&gt; \n  mutate(proportion = n / sum(n))\n\n# A tibble: 8 × 4\n# Groups:   sex [3]\n  sex    species       n proportion\n  &lt;chr&gt;  &lt;chr&gt;     &lt;int&gt;      &lt;dbl&gt;\n1 female Adelie       73      0.442\n2 female Chinstrap    34      0.206\n3 female Gentoo       58      0.352\n4 male   Adelie       73      0.435\n5 male   Chinstrap    34      0.202\n6 male   Gentoo       61      0.363\n7 &lt;NA&gt;   Adelie        6      0.545\n8 &lt;NA&gt;   Gentoo        5      0.455\n\n\nEXAMPLE 2: New data\nWhat will the following code do? Think about it before running.\n\n#creates an average body mass for each sex within species\npenguin_avg &lt;- penguins |&gt; \n  group_by(species, sex) |&gt; \n  summarize(avg_body_mass = mean(body_mass_g, na.rm = TRUE)) |&gt; \n  na.omit()\n\nEXAMPLE 3: units of observation\nTo get the information on average body masses, we reshaped our original data.\n\nDid the reshaping process change the units of observation?\n\n\n# Units of observation = penguins\nhead(penguins)\n\n# A tibble: 6 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;chr&gt;   &lt;chr&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;dbl&gt;       &lt;dbl&gt;\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           40.3          18                 195        3250\n4 Adelie  Torgersen           NA            NA                  NA          NA\n5 Adelie  Torgersen           36.7          19.3               193        3450\n6 Adelie  Torgersen           39.3          20.6               190        3650\n# ℹ 2 more variables: sex &lt;chr&gt;, year &lt;dbl&gt;\n\n# Units of observation = species and sexes within species\nhead(penguin_avg)\n\n# A tibble: 6 × 3\n# Groups:   species [3]\n  species   sex    avg_body_mass\n  &lt;chr&gt;     &lt;chr&gt;          &lt;dbl&gt;\n1 Adelie    female         3369.\n2 Adelie    male           4043.\n3 Chinstrap female         3527.\n4 Chinstrap male           3939.\n5 Gentoo    female         4680.\n6 Gentoo    male           5485.\n\n\n\nDid the reshaping process result in any information loss from the original data? yes",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Reshaping</span>"
    ]
  },
  {
    "objectID": "ica/ica-dates.html#reshaping-data",
    "href": "ica/ica-dates.html#reshaping-data",
    "title": "\n19  Reshaping\n",
    "section": "\n19.2 Reshaping Data",
    "text": "19.2 Reshaping Data\nThere are two general types of reshaped data:\n\naggregate data\nFor example, using group_by() with summarize() gains aggregate information about our observations but loses data on individual observations.\nraw data, reshaped\nWe often want to retain all information on individual observations, but need to reshape it in order to perform the task at hand.\n\nEXAMPLE 4: reshape it with your mind\nLet’s calculate the difference in average body mass, male vs female, for each species. Since penguin_avg is small, we could do these calculations by hand. But this doesn’t scale up to bigger datasets.\n\nSketch out (on paper, in your head, anything) how this data would need to be reshaped, without losing any information, in order to calculate the differences in average body mass using our wrangling verbs. Make it as specific as possible, with column labels, entries, correct numbers, etc.\nIdentify the units of observation.\n\n\npenguin_avg\n\n# A tibble: 6 × 3\n# Groups:   species [3]\n  species   sex    avg_body_mass\n  &lt;chr&gt;     &lt;chr&gt;          &lt;dbl&gt;\n1 Adelie    female         3369.\n2 Adelie    male           4043.\n3 Chinstrap female         3527.\n4 Chinstrap male           3939.\n5 Gentoo    female         4680.\n6 Gentoo    male           5485.\n\n\nWider vs Longer formats\nMaking our data longer or wider reshapes the data, changing the units of observation while retaining all raw information:\n\nMake the data longer, i.e. combine values from multiple variables into 1 variable. EXAMPLE: 1999 and 2000 represent two years. We want to combine their results into 1 variable without losing any information.\n\n\n\nMake the data wider, i.e. spread out the values across new variables. EXAMPLE: cases and pop represent two categories within type. To compare or combine their count outcomes side-by-side, we can separate them into their own variables.\n\n\nEXAMPLE 5: pivot wider\nBecause it’s a small enough dataset to examine all at once, let’s start with our penguin_avg data:\n\npenguin_avg\n\n# A tibble: 6 × 3\n# Groups:   species [3]\n  species   sex    avg_body_mass\n  &lt;chr&gt;     &lt;chr&gt;          &lt;dbl&gt;\n1 Adelie    female         3369.\n2 Adelie    male           4043.\n3 Chinstrap female         3527.\n4 Chinstrap male           3939.\n5 Gentoo    female         4680.\n6 Gentoo    male           5485.\n\n\nWith the goal of being able to calculate the difference in average body mass, male vs female, for each species, let’s make the dataset wider. That is, let’s get one row per species with separate columns for the average body mass by sex. Put this code into a chunk and run it:\n\npenguin_avg |&gt; \npivot_wider(names_from = sex, values_from = avg_body_mass)\n\n# A tibble: 3 × 3\n# Groups:   species [3]\n  species   female  male\n  &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt;\n1 Adelie     3369. 4043.\n2 Chinstrap  3527. 3939.\n3 Gentoo     4680. 5485.\n\n\n\n\n\n\n\n\nPivot Wider\n\n\n\n\n\nnames_from = the variable whose values we want to separate into their own columns, i.e. where we want to get the new column names from\n\n\nvalues_from = which variable to take the new column values from\n\n\n\n\nFOLLOW-UP:\n\nWhat are the units of observation? penguin species and sexes\n\nDid we lose any information when we widened the data? no\n\nUse the wide data to calculate the difference in average body mass, male vs female, for each species.\n\n\npenguin_avg |&gt; \n  pivot_wider(names_from = sex, values_from = avg_body_mass) |&gt; \n  mutate(diff = male - female)\n\n# A tibble: 3 × 4\n# Groups:   species [3]\n  species   female  male  diff\n  &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Adelie     3369. 4043.  675.\n2 Chinstrap  3527. 3939.  412.\n3 Gentoo     4680. 5485.  805.\n\n\nEXAMPLE 6: Pivot longer\nLet’s store our wide data:\n\npenguin_avg_wide &lt;- penguin_avg |&gt; \n  pivot_wider(names_from = sex, values_from = avg_body_mass)\n\npenguin_avg_wide\n\n# A tibble: 3 × 3\n# Groups:   species [3]\n  species   female  male\n  &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt;\n1 Adelie     3369. 4043.\n2 Chinstrap  3527. 3939.\n3 Gentoo     4680. 5485.\n\n\nSuppose we wanted to change this data back to a longer format. In general, this happens when some variables (here female and male) represent two categories or values of some broader variable (here sex), and we want to combine them into that 1 variable without losing any information. Let’s pivot_longer():\n\n# We can either communicate which variables we WANT to collect into a single column (female, male)\npenguin_avg_wide |&gt; \n  pivot_longer(cols = c(female, male), names_to = \"sex\", values_to = \"avg_body_mass\")\n\n# A tibble: 6 × 3\n# Groups:   species [3]\n  species   sex    avg_body_mass\n  &lt;chr&gt;     &lt;chr&gt;          &lt;dbl&gt;\n1 Adelie    female         3369.\n2 Adelie    male           4043.\n3 Chinstrap female         3527.\n4 Chinstrap male           3939.\n5 Gentoo    female         4680.\n6 Gentoo    male           5485.\n\n# Or which variable(s) we do NOT want to collect into a single column (sex)\npenguin_avg_wide |&gt; \n  pivot_longer(cols = -species, names_to = \"sex\", values_to = \"avg_body_mass\")\n\n# A tibble: 6 × 3\n# Groups:   species [3]\n  species   sex    avg_body_mass\n  &lt;chr&gt;     &lt;chr&gt;          &lt;dbl&gt;\n1 Adelie    female         3369.\n2 Adelie    male           4043.\n3 Chinstrap female         3527.\n4 Chinstrap male           3939.\n5 Gentoo    female         4680.\n6 Gentoo    male           5485.\n\n\n\n\n\n\n\n\nPivot Longer\n\n\n\n\n\ncols = the columns (variables) to collect into a single, new variable. We can also specify what variables we don’t want to collect\n\nnames_to = the name of the new variable which will include the names or labels of the collected variables\n\nvalues_to = the name of the new variable which will include the values of the collected variables\n\n\n\nFOLLOW-UP:\n\nWhat are the units of observation? species and sexes\n\nDid we lose any information when we lengthened the data? no\n\nWhy did we put the variables in quotes “” here but not when we used pivot_wider()? because you’re making a new variable\n\nEXAMPLE 7: Practice\nLet’s make up some data on the orders of 2 different customers at 3 different restaurants:\n\nfood &lt;- data.frame(\n  customer = rep(c(\"A\", \"B\"), each = 3),\n  restaurant = rep(c(\"Shish\", \"FrenchMeadow\", \"DunnBros\"), 2),\n  order = c(\"falafel\", \"salad\", \"coffee\", \"baklava\", \"pastry\", \"tea\")\n)\nfood\n\n  customer   restaurant   order\n1        A        Shish falafel\n2        A FrenchMeadow   salad\n3        A     DunnBros  coffee\n4        B        Shish baklava\n5        B FrenchMeadow  pastry\n6        B     DunnBros     tea\n\n\nThe units of observation in food are customer / restaurant combinations. Wrangle this data so that the units of observation are customers, spreading the restaurants into separate columns.\n\nfood |&gt;\n  pivot_wider(names_from = restaurant, values_from = order)\n\n# A tibble: 2 × 4\n  customer Shish   FrenchMeadow DunnBros\n  &lt;chr&gt;    &lt;chr&gt;   &lt;chr&gt;        &lt;chr&gt;   \n1 A        falafel salad        coffee  \n2 B        baklava pastry       tea     \n\n\nConsider 2 more customers:\n\nmore_food &lt;- data.frame(\n  customer = c(\"C\", \"D\"),\n  Shish = c(\"coffee\", \"maza\"),\n  FrenchMeadow = c(\"soup\", \"sandwich\"),\n  DunnBros = c(\"cookie\", \"coffee\")\n)\nmore_food\n\n  customer  Shish FrenchMeadow DunnBros\n1        C coffee         soup   cookie\n2        D   maza     sandwich   coffee\n\n\nWrangle this data so that the 3 restaurant columns are combined into 1, hence the units of observation are customer / restaurant combinations.\n\nmore_food |&gt; \n  pivot_longer(cols = -customer, names_to = \"restaurant\", values_to = \"order\")\n\n# A tibble: 6 × 3\n  customer restaurant   order   \n  &lt;chr&gt;    &lt;chr&gt;        &lt;chr&gt;   \n1 C        Shish        coffee  \n2 C        FrenchMeadow soup    \n3 C        DunnBros     cookie  \n4 D        Shish        maza    \n5 D        FrenchMeadow sandwich\n6 D        DunnBros     coffee",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Reshaping</span>"
    ]
  },
  {
    "objectID": "ica/ica-dates.html#exercises",
    "href": "ica/ica-dates.html#exercises",
    "title": "\n19  Reshaping\n",
    "section": "\n19.3 Exercises",
    "text": "19.3 Exercises\nExercise 1: What’s the problem?\nConsider data on a sleep study in which subjects received only 3 hours of sleep per night. Each day, their reaction time to a stimulus (in ms) was recorded.1\n\nsleep_wide &lt;- read.csv(\"https://mac-stat.github.io/data/sleep_wide.csv\")\n\nhead(sleep_wide)\n\n  Subject  day_0  day_1  day_2  day_3  day_4  day_5  day_6  day_7  day_8  day_9\n1     308 249.56 258.70 250.80 321.44 356.85 414.69 382.20 290.15 430.59 466.35\n2     309 222.73 205.27 202.98 204.71 207.72 215.96 213.63 217.73 224.30 237.31\n3     310 199.05 194.33 234.32 232.84 229.31 220.46 235.42 255.75 261.01 247.52\n4     330 321.54 300.40 283.86 285.13 285.80 297.59 280.24 318.26 305.35 354.05\n5     331 287.61 285.00 301.82 320.12 316.28 293.32 290.08 334.82 293.75 371.58\n6     332 234.86 242.81 272.96 309.77 317.46 310.00 454.16 346.83 330.30 253.86\n\n\nPart a\nWhat are the units of observation in sleep_wide?\nPart b\nSuppose I ask you to plot each subject’s reaction time (y-axis) vs the number of days of sleep restriction (x-axis). “Sketch” out in words what the first few rows of the data need to look like in order to do this. It might help to think about what you’d need to complete the plotting frame:\nggplot(___, aes(y = ___, x = ___, color = ___))\nPart c\nHow can you obtain the dataset you sketched in part b?\n\njust using sleep_wide\n\npivot_longer()\npivot_wider()\nExercise 2: Pivot longer\nTo plot reaction time by day for each subject, we need to reshape the data into a long format where each row represents a subject/day combination. Specifically, we want a dataset with 3 columns and a first few rows that look something like this:\n\n\nSubject\nday\nreaction_time\n\n\n\n308\n0\n249.56\n\n\n308\n1\n258.70\n\n\n308\n2\n250.80\n\n\n\nPart a\nUse pivot_longer() to create the long-format dataset above. Show the first 3 lines (head(3)), which should be similar to those above. Follow-up: Thinking forward to plotting reaction time vs day for each subject, what would you like to fix / change about this dataset?\n\n# For cols, try 2 appproaches: using - and starts_with\n# ___ |&gt; \n#   pivot_longer(cols = ___, names_to = \"___\", values_to = \"___\")\n\nPart b\nRun this chunk:\n\nsleep_long &lt;- sleep_wide |&gt;\n  pivot_longer(cols = -Subject,\n               names_to = \"day\",\n               names_prefix = \"day_\",\n               values_to = \"reaction_time\")\n\nhead(sleep_long)\n\n# A tibble: 6 × 3\n  Subject day   reaction_time\n    &lt;int&gt; &lt;chr&gt;         &lt;dbl&gt;\n1     308 0              250.\n2     308 1              259.\n3     308 2              251.\n4     308 3              321.\n5     308 4              357.\n6     308 5              415.\n\n\nFollow-up:\n\nBesides putting each argument on a different line for readability and storing the results, what changed in the code?\nHow did this impact how the values are recorded in the day column?\nPart c\nUsing sleep_long, construct a line plot of reaction time vs day for each subject. This will look goofy no matter what you do. Why? HINT: look back at head(sleep_long). What class or type of variables are Subject and day? What do we want them to be?\nExercise 3: Changing variable classes & plotting\nLet’s finalize sleep_long by mutating the Subject variable to be a factor (categorical) and the day variable to be numeric (quantitative). Take note of the mutate() code! You’ll use this type of code a lot.\n\nsleep_long &lt;- sleep_wide |&gt;\n  pivot_longer(cols = -Subject,\n               names_to = \"day\",\n               names_prefix = \"day_\",\n               values_to = \"reaction_time\") |&gt; \n  mutate(Subject = as.factor(Subject), day = as.numeric(day))\n\n# Check it out\n# Same data, different class\nhead(sleep_long)\n\n# A tibble: 6 × 3\n  Subject   day reaction_time\n  &lt;fct&gt;   &lt;dbl&gt;         &lt;dbl&gt;\n1 308         0          250.\n2 308         1          259.\n3 308         2          251.\n4 308         3          321.\n5 308         4          357.\n6 308         5          415.\n\n\nPart a\nNow make some plots.\n\n# Make a line plot of reaction time by day for each subject\n# Put these all on the same frame\n\n\n# Make a line plot of reaction time by day for each subject\n# Put these all on separate frames (one per subject)\n\nPart b\nSummarize what you learned from the plots. For example:\n\nWhat’s the general relationship between reaction time and sleep?\nIs this the same for everybody? What differs?\nExercise 4: Pivot wider\nMake the data wide again, with each day becoming its own column.\nPart a\nAdjust the code below. What don’t you like about the column labels?\n\n# sleep_long |&gt;\n#   pivot_wider(names_from = ___, values_from = ___) |&gt; \n#   head()\n\nPart b\nUsing your intuition, adjust your code from part a to name the reaction time columns “day_0”, “day_1”, etc.\n\n# sleep_long |&gt;\n#   pivot_wider(names_from = ___, values_from = ___, names_prefix = \"___\") |&gt; \n#   head()\n\nExercise 5: Practice with Billboard charts\nLoad data on songs that hit the billboard charts around the year 2000. Included for each song is the artist name, track name, the date it hit the charts (date.enter), and wk-related variables that indicate rankings in each subsequent week on the charts:\n\n# Load data\nlibrary(tidyr)\ndata(\"billboard\")\n\n# Check it out\nhead(billboard)\n\n# A tibble: 6 × 79\n  artist      track date.entered   wk1   wk2   wk3   wk4   wk5   wk6   wk7   wk8\n  &lt;chr&gt;       &lt;chr&gt; &lt;date&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 2 Pac       Baby… 2000-02-26      87    82    72    77    87    94    99    NA\n2 2Ge+her     The … 2000-09-02      91    87    92    NA    NA    NA    NA    NA\n3 3 Doors Do… Kryp… 2000-04-08      81    70    68    67    66    57    54    53\n4 3 Doors Do… Loser 2000-10-21      76    76    72    69    67    65    55    59\n5 504 Boyz    Wobb… 2000-04-15      57    34    25    17    17    31    36    49\n6 98^0        Give… 2000-08-19      51    39    34    26    26    19     2     2\n# ℹ 68 more variables: wk9 &lt;dbl&gt;, wk10 &lt;dbl&gt;, wk11 &lt;dbl&gt;, wk12 &lt;dbl&gt;,\n#   wk13 &lt;dbl&gt;, wk14 &lt;dbl&gt;, wk15 &lt;dbl&gt;, wk16 &lt;dbl&gt;, wk17 &lt;dbl&gt;, wk18 &lt;dbl&gt;,\n#   wk19 &lt;dbl&gt;, wk20 &lt;dbl&gt;, wk21 &lt;dbl&gt;, wk22 &lt;dbl&gt;, wk23 &lt;dbl&gt;, wk24 &lt;dbl&gt;,\n#   wk25 &lt;dbl&gt;, wk26 &lt;dbl&gt;, wk27 &lt;dbl&gt;, wk28 &lt;dbl&gt;, wk29 &lt;dbl&gt;, wk30 &lt;dbl&gt;,\n#   wk31 &lt;dbl&gt;, wk32 &lt;dbl&gt;, wk33 &lt;dbl&gt;, wk34 &lt;dbl&gt;, wk35 &lt;dbl&gt;, wk36 &lt;dbl&gt;,\n#   wk37 &lt;dbl&gt;, wk38 &lt;dbl&gt;, wk39 &lt;dbl&gt;, wk40 &lt;dbl&gt;, wk41 &lt;dbl&gt;, wk42 &lt;dbl&gt;,\n#   wk43 &lt;dbl&gt;, wk44 &lt;dbl&gt;, wk45 &lt;dbl&gt;, wk46 &lt;dbl&gt;, wk47 &lt;dbl&gt;, wk48 &lt;dbl&gt;, …\n\n\nIn using this data, you’ll need to determine if and when the data needs to be reshaped for the task at hand.\nPart a\nConstruct and summarize a plot of how a song’s Billboard ranking its 2nd week on the chart (y-axis) is related to its ranking the 1st week on the charts (x-axis). Add a reference line geom_abline(intercept = 0, slope = 1). Songs above this line improved their rankings from the 1st to 2nd week.\nPart b\nUse your wrangling tools to identify which songs are those above the line in Part a, i.e. with rankgings that went up from week 1 to week 2.\nPart c\nDefine a new dataset, nov_1999, which:\n\nonly includes data on songs that entered the Billboard charts on November 6, 1999\nkeeps all variables except track and date.entered. HINT: How can you avoid writing out all the variable names you want to keep?\n\n\n# Define nov_1999\n\n\n# Confirm that nov_1999 has 2 rows (songs) and 77 columns\n\nPart d\nCreate and discuss a visualization of the rankings (y-axis) over time (x-axis) for the 2 songs in nov_1999. There are hints below (if you scroll), but you’re encouraged to play around and use as few hints as possible.\nHints:\n\nShould you first pivot wider or longer?\nOnce you pivot, the week number is turned into a character variable. How can you change it to a number?\nExercise 6: Practice with the Daily Show\nThe data associated with this article is available in the fivethirtyeight package, and is loaded into daily below. It includes a list of every guest to ever appear on Jon Stewart’s The Daily Show, a “late-night talk and satirical news” program (per Wikipedia). Check out the dataset and note that when multiple people appeared together, each person receives their own line:\n\nlibrary(fivethirtyeight)\ndata(\"daily_show_guests\")\ndaily &lt;- daily_show_guests\n\nIn analyzing this data, you’ll need to determine if and when the data needs to be reshaped.\nPart a\nIdentify the 15 guests that appeared the most. (This isn’t a very diverse guest list!)\nPart b\nCHALLENGE: Create the following data set containing 19 columns:\n\nThe first column should have the 15 guests with the highest number of total appearances on the show, listed in descending order of number of appearances.\n17 columns should show the number of appearances of the corresponding guest in each year from 1999 to 2015 (one per column).\nAnother column should show the total number of appearances for the corresponding guest over the entire duration of the show.\n\nThere are hints below (if you scroll), but you’re encouraged to play around and use as few hints as possible.\nHINTS: There are lots of ways to do this. You don’t necessarily need all of these hints.\n\nFirst obtain the number of times a guest appears each year.\nAdd a new column which includes the total number of times a guest appears across all years.\nPivot (longer or wider?). When you do, use values_fill = 0 to replace NA values with 0.\nArrange, then and keep the top 15.\nPart c\nLet’s recreate the first figure from the article. This groups all guests into 3 broader occupational categories. However, our current data has 18 categories:\n\ndaily |&gt; \n  count(group)\n\n# A tibble: 18 × 2\n   group              n\n   &lt;chr&gt;          &lt;int&gt;\n 1 Academic         103\n 2 Acting           930\n 3 Advocacy          24\n 4 Athletics         52\n 5 Business          25\n 6 Clergy             8\n 7 Comedy           150\n 8 Consultant        18\n 9 Government        40\n10 Media            751\n11 Military          16\n12 Misc              45\n13 Musician         123\n14 Political Aide    36\n15 Politician       308\n16 Science           28\n17 media              5\n18 &lt;NA&gt;              31\n\n\nLet’s define a new dataset that includes a new variable, broad_group, that buckets these 18 categories into the 3 bigger ones used in the article. And get rid of any rows missing information on broad_group. You’ll learn the code soon! For now, just run this chunk:\n\nplot_data &lt;- daily |&gt; \n  mutate(broad_group = case_when(\n    group %in% c(\"Acting\", \"Athletics\", \"Comedy\", \"Musician\") ~ \"Acting, Comedy & Music\",\n    group %in% c(\"Media\", \"media\", \"Science\", \"Academic\", \"Consultant\", \"Clergy\") ~ \"Media\",\n    group %in% c(\"Politician\", \"Political Aide\", \"Government\", \"Military\", \"Business\", \"Advocacy\") ~ \"Government and Politics\",\n    .default = NA\n  )) |&gt; \n  filter(!is.na(broad_group))\n\nNow, using the broad_group variable in plot_data, recreate the graphic from the article, with three different lines showing the fraction of guests in each group over time. Note: You’ll have to wrangle the data first.",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Reshaping</span>"
    ]
  },
  {
    "objectID": "ica/ica-dates.html#solutions",
    "href": "ica/ica-dates.html#solutions",
    "title": "\n19  Reshaping\n",
    "section": "\n19.4 Solutions",
    "text": "19.4 Solutions\n\nClick for Solutions\nEXAMPLE 1: warm-up counts and proportions\n\n# Using count()\npenguins |&gt; \n  count(species, sex)\n\n# A tibble: 8 × 3\n  species   sex        n\n  &lt;chr&gt;     &lt;chr&gt;  &lt;int&gt;\n1 Adelie    female    73\n2 Adelie    male      73\n3 Adelie    &lt;NA&gt;       6\n4 Chinstrap female    34\n5 Chinstrap male      34\n6 Gentoo    female    58\n7 Gentoo    male      61\n8 Gentoo    &lt;NA&gt;       5\n\n# Using group_by() and summarize()\npenguins |&gt; \n  group_by(species, sex) |&gt; \n  summarize(n())\n\n# A tibble: 8 × 3\n# Groups:   species [3]\n  species   sex    `n()`\n  &lt;chr&gt;     &lt;chr&gt;  &lt;int&gt;\n1 Adelie    female    73\n2 Adelie    male      73\n3 Adelie    &lt;NA&gt;       6\n4 Chinstrap female    34\n5 Chinstrap male      34\n6 Gentoo    female    58\n7 Gentoo    male      61\n8 Gentoo    &lt;NA&gt;       5\n\n# Relative frequencies\npenguins |&gt; \n  group_by(species, sex) |&gt; \n  summarize(n = n()) |&gt; \n  mutate(proportion = n / sum(n))\n\n# A tibble: 8 × 4\n# Groups:   species [3]\n  species   sex        n proportion\n  &lt;chr&gt;     &lt;chr&gt;  &lt;int&gt;      &lt;dbl&gt;\n1 Adelie    female    73     0.480 \n2 Adelie    male      73     0.480 \n3 Adelie    &lt;NA&gt;       6     0.0395\n4 Chinstrap female    34     0.5   \n5 Chinstrap male      34     0.5   \n6 Gentoo    female    58     0.468 \n7 Gentoo    male      61     0.492 \n8 Gentoo    &lt;NA&gt;       5     0.0403\n\n# Changing the order calculates the proportion of species within each sex\npenguins |&gt; \n  group_by(sex, species) |&gt; \n  summarize(n = n()) |&gt; \n  mutate(proportion = n / sum(n))\n\n# A tibble: 8 × 4\n# Groups:   sex [3]\n  sex    species       n proportion\n  &lt;chr&gt;  &lt;chr&gt;     &lt;int&gt;      &lt;dbl&gt;\n1 female Adelie       73      0.442\n2 female Chinstrap    34      0.206\n3 female Gentoo       58      0.352\n4 male   Adelie       73      0.435\n5 male   Chinstrap    34      0.202\n6 male   Gentoo       61      0.363\n7 &lt;NA&gt;   Adelie        6      0.545\n8 &lt;NA&gt;   Gentoo        5      0.455\n\n\nEXAMPLE 3: units of observation\n\n# Units of observation = penguins\nhead(penguins)\n\n# A tibble: 6 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;chr&gt;   &lt;chr&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;dbl&gt;       &lt;dbl&gt;\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           40.3          18                 195        3250\n4 Adelie  Torgersen           NA            NA                  NA          NA\n5 Adelie  Torgersen           36.7          19.3               193        3450\n6 Adelie  Torgersen           39.3          20.6               190        3650\n# ℹ 2 more variables: sex &lt;chr&gt;, year &lt;dbl&gt;\n\n# Units of observation = species/sex combos\nhead(penguin_avg)\n\n# A tibble: 6 × 3\n# Groups:   species [3]\n  species   sex    avg_body_mass\n  &lt;chr&gt;     &lt;chr&gt;          &lt;dbl&gt;\n1 Adelie    female         3369.\n2 Adelie    male           4043.\n3 Chinstrap female         3527.\n4 Chinstrap male           3939.\n5 Gentoo    female         4680.\n6 Gentoo    male           5485.\n\n\nEXAMPLE 5: pivot wider\n\npenguin_avg |&gt; \n  pivot_wider(names_from = sex, values_from = avg_body_mass)\n\n# A tibble: 3 × 3\n# Groups:   species [3]\n  species   female  male\n  &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt;\n1 Adelie     3369. 4043.\n2 Chinstrap  3527. 3939.\n3 Gentoo     4680. 5485.\n\n\nFOLLOW-UP:\n\nWhat are the units of observation? species\nDid we lose any information when we widened the data? no\nUse the wide data to calculate the difference in average body mass, male vs female, for each species.\n\n\npenguin_avg |&gt; \n  pivot_wider(names_from = sex, values_from = avg_body_mass) |&gt; \n  mutate(diff = male - female)\n\n# A tibble: 3 × 4\n# Groups:   species [3]\n  species   female  male  diff\n  &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Adelie     3369. 4043.  675.\n2 Chinstrap  3527. 3939.  412.\n3 Gentoo     4680. 5485.  805.\n\n\nEXAMPLE 6: Pivot longer\n\n# We can either communicate which variables we WANT to collect into a single column (female, male)\npenguin_avg_wide |&gt; \n  pivot_longer(cols = c(female, male), names_to = \"sex\", values_to = \"avg_body_mass\")\n\n# A tibble: 6 × 3\n# Groups:   species [3]\n  species   sex    avg_body_mass\n  &lt;chr&gt;     &lt;chr&gt;          &lt;dbl&gt;\n1 Adelie    female         3369.\n2 Adelie    male           4043.\n3 Chinstrap female         3527.\n4 Chinstrap male           3939.\n5 Gentoo    female         4680.\n6 Gentoo    male           5485.\n\n# Or which variable(s) we do NOT want to collect into a single column (sex)\npenguin_avg_wide |&gt; \n  pivot_longer(cols = -species, names_to = \"sex\", values_to = \"avg_body_mass\")\n\n# A tibble: 6 × 3\n# Groups:   species [3]\n  species   sex    avg_body_mass\n  &lt;chr&gt;     &lt;chr&gt;          &lt;dbl&gt;\n1 Adelie    female         3369.\n2 Adelie    male           4043.\n3 Chinstrap female         3527.\n4 Chinstrap male           3939.\n5 Gentoo    female         4680.\n6 Gentoo    male           5485.\n\n\nFOLLOW-UP:\n\nWhat are the units of observation? species/sex combos\nDid we lose any information when we lengthened the data? no\n\n19.4.1 EXAMPLE 7: Practice [-]\n\nfood &lt;- data.frame(\n  customer = rep(c(\"A\", \"B\"), each = 3),\n  restaurant = rep(c(\"Shish\", \"FrenchMeadow\", \"DunnBros\"), 2),\n  order = c(\"falafel\", \"salad\", \"coffee\", \"baklava\", \"pastry\", \"tea\")\n)\n\nfood\n\n  customer   restaurant   order\n1        A        Shish falafel\n2        A FrenchMeadow   salad\n3        A     DunnBros  coffee\n4        B        Shish baklava\n5        B FrenchMeadow  pastry\n6        B     DunnBros     tea\n\nfood |&gt; \n  pivot_wider(names_from = restaurant, values_from = order)\n\n# A tibble: 2 × 4\n  customer Shish   FrenchMeadow DunnBros\n  &lt;chr&gt;    &lt;chr&gt;   &lt;chr&gt;        &lt;chr&gt;   \n1 A        falafel salad        coffee  \n2 B        baklava pastry       tea     \n\n\n\nmore_food &lt;- data.frame(\n  customer = c(\"C\", \"D\"),\n  Shish = c(\"coffee\", \"maza\"),\n  FrenchMeadow = c(\"soup\", \"sandwich\"),\n  DunnBros = c(\"cookie\", \"coffee\")\n)\n\nmore_food\n\n  customer  Shish FrenchMeadow DunnBros\n1        C coffee         soup   cookie\n2        D   maza     sandwich   coffee\n\nmore_food |&gt; \n  pivot_longer(cols = -customer, names_to = \"restaurant\", values_to = \"order\")\n\n# A tibble: 6 × 3\n  customer restaurant   order   \n  &lt;chr&gt;    &lt;chr&gt;        &lt;chr&gt;   \n1 C        Shish        coffee  \n2 C        FrenchMeadow soup    \n3 C        DunnBros     cookie  \n4 D        Shish        maza    \n5 D        FrenchMeadow sandwich\n6 D        DunnBros     coffee  \n\n\nExercise 1: What’s the problem?\nPart a\nsubjects/people\nPart c\npivot_longer()\nExercise 2: Pivot longer\nPart a\n\n# For cols, try 2 appproaches: using - and starts_with\nsleep_wide |&gt;\n  pivot_longer(cols = -Subject, names_to = \"day\", values_to = \"reaction_time\")\n\n# A tibble: 180 × 3\n   Subject day   reaction_time\n     &lt;int&gt; &lt;chr&gt;         &lt;dbl&gt;\n 1     308 day_0          250.\n 2     308 day_1          259.\n 3     308 day_2          251.\n 4     308 day_3          321.\n 5     308 day_4          357.\n 6     308 day_5          415.\n 7     308 day_6          382.\n 8     308 day_7          290.\n 9     308 day_8          431.\n10     308 day_9          466.\n# ℹ 170 more rows\n\nsleep_wide |&gt;\n  pivot_longer(cols = starts_with(\"day\"), names_to = \"day\", values_to = \"reaction_time\")\n\n# A tibble: 180 × 3\n   Subject day   reaction_time\n     &lt;int&gt; &lt;chr&gt;         &lt;dbl&gt;\n 1     308 day_0          250.\n 2     308 day_1          259.\n 3     308 day_2          251.\n 4     308 day_3          321.\n 5     308 day_4          357.\n 6     308 day_5          415.\n 7     308 day_6          382.\n 8     308 day_7          290.\n 9     308 day_8          431.\n10     308 day_9          466.\n# ℹ 170 more rows\n\n\nPart b\nAdding names_prefix = \"day_\" removed “day_” from the start of the day entries. did this impact how the values are recorded in the day column?\n\nsleep_long &lt;- sleep_wide |&gt;\n  pivot_longer(cols = -Subject,\n               names_to = \"day\",\n               names_prefix = \"day_\",\n               values_to = \"reaction_time\") \n\nPart c\nSubject is an integer and day is a character. We want them to be categorical (factor) and numeric, respectively.\n\nggplot(sleep_long, aes(y = reaction_time, x = day, color = Subject)) + \n  geom_line()\n\n\n\n\n\n\n\nExercise 3: Changing variable classes & plotting\n\nsleep_long &lt;- sleep_wide |&gt;\n  pivot_longer(cols = -Subject,\n               names_to = \"day\",\n               names_prefix = \"day_\",\n               values_to = \"reaction_time\") |&gt; \n  mutate(Subject = as.factor(Subject), day = as.numeric(day))\n\nPart a\nNow make some plots.\n\n# Make a line plot of reaction time by day for each subject\n# Put these all on the same frame\nggplot(sleep_long, aes(y = reaction_time, x = day, color = Subject)) + \n  geom_line()\n\n\n\n\n\n\n\n\n# Make a line plot of reaction time by day for each subject\n# Put these all on separate frames (one per subject)\nggplot(sleep_long, aes(y = reaction_time, x = day, color = Subject)) + \n  geom_line() + \n  facet_wrap(~ Subject)\n\n\n\n\n\n\n\nPart b\nReaction time increases (worsens) with a lack of sleep. Some subjects seem to be more impacted than others by lack of sleep, and some tend to have faster/slower reaction times in general.\nExercise 4: Pivot wider\nPart a\n\nsleep_long |&gt;\n  pivot_wider(names_from = day, values_from = reaction_time) |&gt;\n  head()\n\n# A tibble: 6 × 11\n  Subject   `0`   `1`   `2`   `3`   `4`   `5`   `6`   `7`   `8`   `9`\n  &lt;fct&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 308      250.  259.  251.  321.  357.  415.  382.  290.  431.  466.\n2 309      223.  205.  203.  205.  208.  216.  214.  218.  224.  237.\n3 310      199.  194.  234.  233.  229.  220.  235.  256.  261.  248.\n4 330      322.  300.  284.  285.  286.  298.  280.  318.  305.  354.\n5 331      288.  285   302.  320.  316.  293.  290.  335.  294.  372.\n6 332      235.  243.  273.  310.  317.  310   454.  347.  330.  254.\n\n\nPart b\n\nsleep_long |&gt;\n  pivot_wider(names_from = day, values_from = reaction_time, names_prefix = \"day_\") |&gt;\n  head()\n\n# A tibble: 6 × 11\n  Subject day_0 day_1 day_2 day_3 day_4 day_5 day_6 day_7 day_8 day_9\n  &lt;fct&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 308      250.  259.  251.  321.  357.  415.  382.  290.  431.  466.\n2 309      223.  205.  203.  205.  208.  216.  214.  218.  224.  237.\n3 310      199.  194.  234.  233.  229.  220.  235.  256.  261.  248.\n4 330      322.  300.  284.  285.  286.  298.  280.  318.  305.  354.\n5 331      288.  285   302.  320.  316.  293.  290.  335.  294.  372.\n6 332      235.  243.  273.  310.  317.  310   454.  347.  330.  254.\n\n\nExercise 5: Practice with Billboard charts\nPart a\nThe higher a song’s week 1 rating, the higher its week 2 rating tends to be. But almost all song’s rankings drop from week 1 to week 2.\n\nggplot(billboard, aes(y = wk2, x = wk1)) + \n  geom_point() +\n  geom_abline(intercept = 0, slope = 1)\n\n\n\n\n\n\n\nPart b\n\nbillboard |&gt; \n  filter(wk2 &gt; wk1)\n\n# A tibble: 7 × 79\n  artist      track date.entered   wk1   wk2   wk3   wk4   wk5   wk6   wk7   wk8\n  &lt;chr&gt;       &lt;chr&gt; &lt;date&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Carey, Mar… Cryb… 2000-06-24      28    34    48    62    77    90    95    NA\n2 Clark, Ter… A Li… 2000-12-16      75    82    88    96    99    99    NA    NA\n3 Diffie, Joe The … 2000-01-01      98   100   100    90    93    94    NA    NA\n4 Hart, Beth  L.A.… 1999-11-27      99   100    98    99    99    99    98    90\n5 Jay-Z       Hey … 2000-08-12      98   100    98    94    83    83    80    78\n6 Lil' Zane   Call… 2000-07-29      83    89    57    40    34    21    33    46\n7 Pearl Jam   Noth… 2000-05-13      49    70    84    89    93    91    NA    NA\n# ℹ 68 more variables: wk9 &lt;dbl&gt;, wk10 &lt;dbl&gt;, wk11 &lt;dbl&gt;, wk12 &lt;dbl&gt;,\n#   wk13 &lt;dbl&gt;, wk14 &lt;dbl&gt;, wk15 &lt;dbl&gt;, wk16 &lt;dbl&gt;, wk17 &lt;dbl&gt;, wk18 &lt;dbl&gt;,\n#   wk19 &lt;dbl&gt;, wk20 &lt;dbl&gt;, wk21 &lt;dbl&gt;, wk22 &lt;dbl&gt;, wk23 &lt;dbl&gt;, wk24 &lt;dbl&gt;,\n#   wk25 &lt;dbl&gt;, wk26 &lt;dbl&gt;, wk27 &lt;dbl&gt;, wk28 &lt;dbl&gt;, wk29 &lt;dbl&gt;, wk30 &lt;dbl&gt;,\n#   wk31 &lt;dbl&gt;, wk32 &lt;dbl&gt;, wk33 &lt;dbl&gt;, wk34 &lt;dbl&gt;, wk35 &lt;dbl&gt;, wk36 &lt;dbl&gt;,\n#   wk37 &lt;dbl&gt;, wk38 &lt;dbl&gt;, wk39 &lt;dbl&gt;, wk40 &lt;dbl&gt;, wk41 &lt;dbl&gt;, wk42 &lt;dbl&gt;,\n#   wk43 &lt;dbl&gt;, wk44 &lt;dbl&gt;, wk45 &lt;dbl&gt;, wk46 &lt;dbl&gt;, wk47 &lt;dbl&gt;, wk48 &lt;dbl&gt;, …\n\n\nPart c\n\n# Define nov_1999\nnov_1999 &lt;- billboard |&gt; \n  filter(date.entered == \"1999-11-06\") |&gt; \n  select(-track, -date.entered)\n\n# Or\nnov_1999 &lt;- billboard |&gt; \n  filter(date.entered == \"1999-11-06\") |&gt; \n  select(artist, starts_with(\"wk\"))\n\n\n# Confirm that nov_1999 has 2 rows (songs) and 77 columns\ndim(nov_1999)\n\n[1]  2 77\n\n\nPart c\n\nnov_1999 |&gt; \n  pivot_longer(cols = -artist, names_to = \"week\", names_prefix = \"wk\", values_to = \"ranking\") |&gt; \n  mutate(week = as.numeric(week)) |&gt; \n  ggplot(aes(y = ranking, x = week, color = artist)) + \n    geom_line()\n\n\n\n\n\n\n\nExercise 6: Practice with the Daily Show\nPart a\n\ndaily |&gt; \n  count(raw_guest_list) |&gt; \n  arrange(desc(n)) |&gt; \n  head(15)\n\n# A tibble: 15 × 2\n   raw_guest_list        n\n   &lt;chr&gt;             &lt;int&gt;\n 1 Fareed Zakaria       19\n 2 Denis Leary          17\n 3 Brian Williams       16\n 4 Paul Rudd            13\n 5 Ricky Gervais        13\n 6 Tom Brokaw           12\n 7 Bill O'Reilly        10\n 8 Reza Aslan           10\n 9 Richard Lewis        10\n10 Will Ferrell         10\n11 Sarah Vowell          9\n12 Adam Sandler          8\n13 Ben Affleck           8\n14 Louis C.K.            8\n15 Maggie Gyllenhaal     8\n\n\nPart b\n\ndaily |&gt; \n  count(year, raw_guest_list) |&gt; \n  group_by(raw_guest_list) |&gt; \n  mutate(total = sum(n)) |&gt;\n  pivot_wider(names_from = year, \n              values_from = n,\n              values_fill = 0) |&gt; \n  arrange(desc(total)) |&gt; \n  head(15)\n\n# A tibble: 15 × 19\n# Groups:   raw_guest_list [15]\n   raw_guest_list  total `1999` `2000` `2001` `2002` `2003` `2004` `2005` `2006`\n   &lt;chr&gt;           &lt;int&gt;  &lt;int&gt;  &lt;int&gt;  &lt;int&gt;  &lt;int&gt;  &lt;int&gt;  &lt;int&gt;  &lt;int&gt;  &lt;int&gt;\n 1 Fareed Zakaria     19      0      0      1      0      1      2      2      2\n 2 Denis Leary        17      1      0      1      2      1      0      0      1\n 3 Brian Williams     16      0      0      0      0      1      1      2      1\n 4 Paul Rudd          13      1      0      1      1      1      1      1      0\n 5 Ricky Gervais      13      0      0      0      0      0      0      1      2\n 6 Tom Brokaw         12      0      0      0      1      0      2      1      0\n 7 Richard Lewis      10      1      0      2      2      1      1      0      0\n 8 Will Ferrell       10      0      1      1      0      1      1      1      1\n 9 Bill O'Reilly      10      0      0      1      1      0      1      1      0\n10 Reza Aslan         10      0      0      0      0      0      0      1      2\n11 Sarah Vowell        9      0      0      0      1      0      1      1      1\n12 Adam Sandler        8      1      2      0      1      0      0      0      1\n13 Ben Affleck         8      0      0      0      0      2      0      0      1\n14 Maggie Gyllenh…     8      0      0      0      0      1      0      1      1\n15 Louis C.K.          8      0      0      0      0      0      0      0      1\n# ℹ 9 more variables: `2007` &lt;int&gt;, `2008` &lt;int&gt;, `2009` &lt;int&gt;, `2010` &lt;int&gt;,\n#   `2011` &lt;int&gt;, `2012` &lt;int&gt;, `2013` &lt;int&gt;, `2014` &lt;int&gt;, `2015` &lt;int&gt;\n\n\nPart c\n\nplot_data |&gt;\n  group_by(year, broad_group) |&gt;\n  summarise(n = n()) |&gt;\n  mutate(freq = n / sum(n)) |&gt; \n  ggplot(aes(y = freq, x = year, color = broad_group)) + \n    geom_line()",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Reshaping</span>"
    ]
  },
  {
    "objectID": "ica/ica-dates.html#footnotes",
    "href": "ica/ica-dates.html#footnotes",
    "title": "\n19  Reshaping\n",
    "section": "",
    "text": "Gregory Belenky, Nancy J. Wesensten, David R. Thorne, Maria L. Thomas, Helen C. Sing, Daniel P. Redmond, Michael B. Russo and Thomas J. Balkin (2003) Patterns of performance degradation and restoration during sleep restriction and subsequent recovery: a sleep dose-response study. Journal of Sleep Research 12, 1–12.↩︎",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Reshaping</span>"
    ]
  },
  {
    "objectID": "ica/ica-reshaping.html",
    "href": "ica/ica-reshaping.html",
    "title": "\n20  Reshaping\n",
    "section": "",
    "text": "20.1 Review",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Reshaping</span>"
    ]
  },
  {
    "objectID": "ica/ica-reshaping.html#review",
    "href": "ica/ica-reshaping.html#review",
    "title": "\n20  Reshaping\n",
    "section": "",
    "text": "EXAMPLE 1: warm-up counts and proportions\nRecall the penguins we worked with last class:\n\nlibrary(tidyverse)\npenguins &lt;- read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-07-28/penguins.csv')\n\nTally up the number of male/female penguins by species in 2 ways:\n\n# Using count()\npenguins |&gt;\n  count(species, sex)\n\n# A tibble: 8 × 3\n  species   sex        n\n  &lt;chr&gt;     &lt;chr&gt;  &lt;int&gt;\n1 Adelie    female    73\n2 Adelie    male      73\n3 Adelie    &lt;NA&gt;       6\n4 Chinstrap female    34\n5 Chinstrap male      34\n6 Gentoo    female    58\n7 Gentoo    male      61\n8 Gentoo    &lt;NA&gt;       5\n\n# Using group_by() and summarize()\npenguins |&gt; \n  group_by(species, sex) |&gt; \n  summarize(n())\n\n# A tibble: 8 × 3\n# Groups:   species [3]\n  species   sex    `n()`\n  &lt;chr&gt;     &lt;chr&gt;  &lt;int&gt;\n1 Adelie    female    73\n2 Adelie    male      73\n3 Adelie    &lt;NA&gt;       6\n4 Chinstrap female    34\n5 Chinstrap male      34\n6 Gentoo    female    58\n7 Gentoo    male      61\n8 Gentoo    &lt;NA&gt;       5\n\n\nDefine a new column that includes the proportion or relative frequencies of male/female penguins in each species.\n\nWe can’t do this by adjusting our count() code, but can adjust the group_by() and summarize() code since it’s still tracking the group categories in the background.\nDoes the order of species and sex in group_by() matter?\n\n\npenguins |&gt;\n  #changes proportion to the species within each sex\n  group_by(sex, species) |&gt; \n  summarize(n = n()) |&gt; \n  mutate(proportion = n / sum(n))\n\n# A tibble: 8 × 4\n# Groups:   sex [3]\n  sex    species       n proportion\n  &lt;chr&gt;  &lt;chr&gt;     &lt;int&gt;      &lt;dbl&gt;\n1 female Adelie       73      0.442\n2 female Chinstrap    34      0.206\n3 female Gentoo       58      0.352\n4 male   Adelie       73      0.435\n5 male   Chinstrap    34      0.202\n6 male   Gentoo       61      0.363\n7 &lt;NA&gt;   Adelie        6      0.545\n8 &lt;NA&gt;   Gentoo        5      0.455\n\n\nEXAMPLE 2: New data\nWhat will the following code do? Think about it before running.\n\n#creates an average body mass for each sex within species\npenguin_avg &lt;- penguins |&gt; \n  group_by(species, sex) |&gt; \n  summarize(avg_body_mass = mean(body_mass_g, na.rm = TRUE)) |&gt; \n  na.omit()\n\nEXAMPLE 3: units of observation\nTo get the information on average body masses, we reshaped our original data.\n\nDid the reshaping process change the units of observation?\n\n\n# Units of observation = penguins\nhead(penguins)\n\n# A tibble: 6 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;chr&gt;   &lt;chr&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;dbl&gt;       &lt;dbl&gt;\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           40.3          18                 195        3250\n4 Adelie  Torgersen           NA            NA                  NA          NA\n5 Adelie  Torgersen           36.7          19.3               193        3450\n6 Adelie  Torgersen           39.3          20.6               190        3650\n# ℹ 2 more variables: sex &lt;chr&gt;, year &lt;dbl&gt;\n\n# Units of observation = species and sexes within species\nhead(penguin_avg)\n\n# A tibble: 6 × 3\n# Groups:   species [3]\n  species   sex    avg_body_mass\n  &lt;chr&gt;     &lt;chr&gt;          &lt;dbl&gt;\n1 Adelie    female         3369.\n2 Adelie    male           4043.\n3 Chinstrap female         3527.\n4 Chinstrap male           3939.\n5 Gentoo    female         4680.\n6 Gentoo    male           5485.\n\n\n\nDid the reshaping process result in any information loss from the original data? yes",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Reshaping</span>"
    ]
  },
  {
    "objectID": "ica/ica-reshaping.html#reshaping-data",
    "href": "ica/ica-reshaping.html#reshaping-data",
    "title": "\n20  Reshaping\n",
    "section": "\n20.2 Reshaping Data",
    "text": "20.2 Reshaping Data\nThere are two general types of reshaped data:\n\naggregate data\nFor example, using group_by() with summarize() gains aggregate information about our observations but loses data on individual observations.\nraw data, reshaped\nWe often want to retain all information on individual observations, but need to reshape it in order to perform the task at hand.\n\nEXAMPLE 4: reshape it with your mind\nLet’s calculate the difference in average body mass, male vs female, for each species. Since penguin_avg is small, we could do these calculations by hand. But this doesn’t scale up to bigger datasets.\n\nSketch out (on paper, in your head, anything) how this data would need to be reshaped, without losing any information, in order to calculate the differences in average body mass using our wrangling verbs. Make it as specific as possible, with column labels, entries, correct numbers, etc.\nIdentify the units of observation.\n\n\npenguin_avg\n\n# A tibble: 6 × 3\n# Groups:   species [3]\n  species   sex    avg_body_mass\n  &lt;chr&gt;     &lt;chr&gt;          &lt;dbl&gt;\n1 Adelie    female         3369.\n2 Adelie    male           4043.\n3 Chinstrap female         3527.\n4 Chinstrap male           3939.\n5 Gentoo    female         4680.\n6 Gentoo    male           5485.\n\n\nWider vs Longer formats\nMaking our data longer or wider reshapes the data, changing the units of observation while retaining all raw information:\n\nMake the data longer, i.e. combine values from multiple variables into 1 variable. EXAMPLE: 1999 and 2000 represent two years. We want to combine their results into 1 variable without losing any information.\n\n\n\nMake the data wider, i.e. spread out the values across new variables. EXAMPLE: cases and pop represent two categories within type. To compare or combine their count outcomes side-by-side, we can separate them into their own variables.\n\n\nEXAMPLE 5: pivot wider\nBecause it’s a small enough dataset to examine all at once, let’s start with our penguin_avg data:\n\npenguin_avg\n\n# A tibble: 6 × 3\n# Groups:   species [3]\n  species   sex    avg_body_mass\n  &lt;chr&gt;     &lt;chr&gt;          &lt;dbl&gt;\n1 Adelie    female         3369.\n2 Adelie    male           4043.\n3 Chinstrap female         3527.\n4 Chinstrap male           3939.\n5 Gentoo    female         4680.\n6 Gentoo    male           5485.\n\n\nWith the goal of being able to calculate the difference in average body mass, male vs female, for each species, let’s make the dataset wider. That is, let’s get one row per species with separate columns for the average body mass by sex. Put this code into a chunk and run it:\n\npenguin_avg |&gt; \npivot_wider(names_from = sex, values_from = avg_body_mass)\n\n# A tibble: 3 × 3\n# Groups:   species [3]\n  species   female  male\n  &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt;\n1 Adelie     3369. 4043.\n2 Chinstrap  3527. 3939.\n3 Gentoo     4680. 5485.\n\n\n\n\n\n\n\n\nPivot Wider\n\n\n\n\n\nnames_from = the variable whose values we want to separate into their own columns, i.e. where we want to get the new column names from\n\n\nvalues_from = which variable to take the new column values from\n\n\n\n\nFOLLOW-UP:\n\nWhat are the units of observation? penguin species and sexes\n\nDid we lose any information when we widened the data? no\n\nUse the wide data to calculate the difference in average body mass, male vs female, for each species.\n\n\npenguin_avg |&gt; \n  pivot_wider(names_from = sex, values_from = avg_body_mass) |&gt; \n  mutate(diff = male - female)\n\n# A tibble: 3 × 4\n# Groups:   species [3]\n  species   female  male  diff\n  &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Adelie     3369. 4043.  675.\n2 Chinstrap  3527. 3939.  412.\n3 Gentoo     4680. 5485.  805.\n\n\nEXAMPLE 6: Pivot longer\nLet’s store our wide data:\n\npenguin_avg_wide &lt;- penguin_avg |&gt; \n  pivot_wider(names_from = sex, values_from = avg_body_mass)\n\npenguin_avg_wide\n\n# A tibble: 3 × 3\n# Groups:   species [3]\n  species   female  male\n  &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt;\n1 Adelie     3369. 4043.\n2 Chinstrap  3527. 3939.\n3 Gentoo     4680. 5485.\n\n\nSuppose we wanted to change this data back to a longer format. In general, this happens when some variables (here female and male) represent two categories or values of some broader variable (here sex), and we want to combine them into that 1 variable without losing any information. Let’s pivot_longer():\n\n# We can either communicate which variables we WANT to collect into a single column (female, male)\npenguin_avg_wide |&gt; \n  pivot_longer(cols = c(female, male), names_to = \"sex\", values_to = \"avg_body_mass\")\n\n# A tibble: 6 × 3\n# Groups:   species [3]\n  species   sex    avg_body_mass\n  &lt;chr&gt;     &lt;chr&gt;          &lt;dbl&gt;\n1 Adelie    female         3369.\n2 Adelie    male           4043.\n3 Chinstrap female         3527.\n4 Chinstrap male           3939.\n5 Gentoo    female         4680.\n6 Gentoo    male           5485.\n\n# Or which variable(s) we do NOT want to collect into a single column (sex)\npenguin_avg_wide |&gt; \n  pivot_longer(cols = -species, names_to = \"sex\", values_to = \"avg_body_mass\")\n\n# A tibble: 6 × 3\n# Groups:   species [3]\n  species   sex    avg_body_mass\n  &lt;chr&gt;     &lt;chr&gt;          &lt;dbl&gt;\n1 Adelie    female         3369.\n2 Adelie    male           4043.\n3 Chinstrap female         3527.\n4 Chinstrap male           3939.\n5 Gentoo    female         4680.\n6 Gentoo    male           5485.\n\n\n\n\n\n\n\n\nPivot Longer\n\n\n\n\n\ncols = the columns (variables) to collect into a single, new variable. We can also specify what variables we don’t want to collect\n\nnames_to = the name of the new variable which will include the names or labels of the collected variables\n\nvalues_to = the name of the new variable which will include the values of the collected variables\n\n\n\nFOLLOW-UP:\n\nWhat are the units of observation? species and sexes\n\nDid we lose any information when we lengthened the data? no\n\nWhy did we put the variables in quotes “” here but not when we used pivot_wider()? because you’re making a new variable\n\nEXAMPLE 7: Practice\nLet’s make up some data on the orders of 2 different customers at 3 different restaurants:\n\nfood &lt;- data.frame(\n  customer = rep(c(\"A\", \"B\"), each = 3),\n  restaurant = rep(c(\"Shish\", \"FrenchMeadow\", \"DunnBros\"), 2),\n  order = c(\"falafel\", \"salad\", \"coffee\", \"baklava\", \"pastry\", \"tea\")\n)\nfood\n\n  customer   restaurant   order\n1        A        Shish falafel\n2        A FrenchMeadow   salad\n3        A     DunnBros  coffee\n4        B        Shish baklava\n5        B FrenchMeadow  pastry\n6        B     DunnBros     tea\n\n\nThe units of observation in food are customer / restaurant combinations. Wrangle this data so that the units of observation are customers, spreading the restaurants into separate columns.\n\nfood |&gt;\n  pivot_wider(names_from = restaurant, values_from = order)\n\n# A tibble: 2 × 4\n  customer Shish   FrenchMeadow DunnBros\n  &lt;chr&gt;    &lt;chr&gt;   &lt;chr&gt;        &lt;chr&gt;   \n1 A        falafel salad        coffee  \n2 B        baklava pastry       tea     \n\n\nConsider 2 more customers:\n\nmore_food &lt;- data.frame(\n  customer = c(\"C\", \"D\"),\n  Shish = c(\"coffee\", \"maza\"),\n  FrenchMeadow = c(\"soup\", \"sandwich\"),\n  DunnBros = c(\"cookie\", \"coffee\")\n)\nmore_food\n\n  customer  Shish FrenchMeadow DunnBros\n1        C coffee         soup   cookie\n2        D   maza     sandwich   coffee\n\n\nWrangle this data so that the 3 restaurant columns are combined into 1, hence the units of observation are customer / restaurant combinations.\n\nmore_food |&gt; \n  pivot_longer(cols = -customer, names_to = \"restaurant\", values_to = \"order\")\n\n# A tibble: 6 × 3\n  customer restaurant   order   \n  &lt;chr&gt;    &lt;chr&gt;        &lt;chr&gt;   \n1 C        Shish        coffee  \n2 C        FrenchMeadow soup    \n3 C        DunnBros     cookie  \n4 D        Shish        maza    \n5 D        FrenchMeadow sandwich\n6 D        DunnBros     coffee",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Reshaping</span>"
    ]
  },
  {
    "objectID": "ica/ica-reshaping.html#exercises",
    "href": "ica/ica-reshaping.html#exercises",
    "title": "\n20  Reshaping\n",
    "section": "\n20.3 Exercises",
    "text": "20.3 Exercises\nExercise 1: What’s the problem?\nConsider data on a sleep study in which subjects received only 3 hours of sleep per night. Each day, their reaction time to a stimulus (in ms) was recorded.1\n\nsleep_wide &lt;- read.csv(\"https://mac-stat.github.io/data/sleep_wide.csv\")\n\nhead(sleep_wide)\n\n  Subject  day_0  day_1  day_2  day_3  day_4  day_5  day_6  day_7  day_8  day_9\n1     308 249.56 258.70 250.80 321.44 356.85 414.69 382.20 290.15 430.59 466.35\n2     309 222.73 205.27 202.98 204.71 207.72 215.96 213.63 217.73 224.30 237.31\n3     310 199.05 194.33 234.32 232.84 229.31 220.46 235.42 255.75 261.01 247.52\n4     330 321.54 300.40 283.86 285.13 285.80 297.59 280.24 318.26 305.35 354.05\n5     331 287.61 285.00 301.82 320.12 316.28 293.32 290.08 334.82 293.75 371.58\n6     332 234.86 242.81 272.96 309.77 317.46 310.00 454.16 346.83 330.30 253.86\n\n\nPart a\nWhat are the units of observation in sleep_wide? subjects\nPart b\nSuppose I ask you to plot each subject’s reaction time (y-axis) vs the number of days of sleep restriction (x-axis). “Sketch” out in words what the first few rows of the data need to look like in order to do this. It might help to think about what you’d need to complete the plotting frame:\nggplot(sleep_wide, aes(y = reaction, x = day, color = subject))\nPart c\nHow can you obtain the dataset you sketched in part b?\n\npivot_longer()\nExercise 2: Pivot longer\nTo plot reaction time by day for each subject, we need to reshape the data into a long format where each row represents a subject/day combination. Specifically, we want a dataset with 3 columns and a first few rows that look something like this:\n\n\nSubject\nday\nreaction_time\n\n\n\n308\n0\n249.56\n\n\n308\n1\n258.70\n\n\n308\n2\n250.80\n\n\n\nPart a\nUse pivot_longer() to create the long-format dataset above. Show the first 3 lines (head(3)), which should be similar to those above. Follow-up: Thinking forward to plotting reaction time vs day for each subject, what would you like to fix / change about this dataset?\n\n# For cols, try 2 appproaches: using - and starts_with\nsleep_wide|&gt; \n  pivot_longer(cols = 2:11, names_to = \"fakeday\", values_to = \"reaction_time\") |&gt;\n  mutate(day = gsub(\"day_\", \"\", fakeday)) |&gt;\n  select(Subject, day, reaction_time)\n\n# A tibble: 180 × 3\n   Subject day   reaction_time\n     &lt;int&gt; &lt;chr&gt;         &lt;dbl&gt;\n 1     308 0              250.\n 2     308 1              259.\n 3     308 2              251.\n 4     308 3              321.\n 5     308 4              357.\n 6     308 5              415.\n 7     308 6              382.\n 8     308 7              290.\n 9     308 8              431.\n10     308 9              466.\n# ℹ 170 more rows\n\n\nPart b\nRun this chunk:\n\nsleep_long &lt;- sleep_wide |&gt;\n  pivot_longer(cols = -Subject,\n               names_to = \"day\",\n               names_prefix = \"day_\",\n               values_to = \"reaction_time\")\n\nhead(sleep_long)\n\n# A tibble: 6 × 3\n  Subject day   reaction_time\n    &lt;int&gt; &lt;chr&gt;         &lt;dbl&gt;\n1     308 0              250.\n2     308 1              259.\n3     308 2              251.\n4     308 3              321.\n5     308 4              357.\n6     308 5              415.\n\n\nFollow-up:\n\nBesides putting each argument on a different line for readability and storing the results, what changed in the code? it got rid of the “day_” part\n\nHow did this impact how the values are recorded in the day column? yead it got rid of the day_part\n\nPart c\nUsing sleep_long, construct a line plot of reaction time vs day for each subject. This will look goofy no matter what you do. Why? HINT: look back at head(sleep_long). What class or type of variables are Subject and day? What do we want them to be?\n\nggplot(sleep_long, aes(y = reaction_time, x = day, color = Subject)) +\n  geom_line()\n\n\n\n\n\n\n\nExercise 3: Changing variable classes & plotting\nLet’s finalize sleep_long by mutating the Subject variable to be a factor (categorical) and the day variable to be numeric (quantitative). Take note of the mutate() code! You’ll use this type of code a lot.\n\nsleep_long &lt;- sleep_wide |&gt;\n  pivot_longer(cols = -Subject,\n               names_to = \"day\",\n               names_prefix = \"day_\",\n               values_to = \"reaction_time\") |&gt; \n  mutate(Subject = as.factor(Subject), day = as.numeric(day))\n\n# Check it out\n# Same data, different class\nhead(sleep_long)\n\n# A tibble: 6 × 3\n  Subject   day reaction_time\n  &lt;fct&gt;   &lt;dbl&gt;         &lt;dbl&gt;\n1 308         0          250.\n2 308         1          259.\n3 308         2          251.\n4 308         3          321.\n5 308         4          357.\n6 308         5          415.\n\n\nPart a\nNow make some plots.\n\n# Make a line plot of reaction time by day for each subject\n# Put these all on the same frame\nggplot(sleep_long, aes(y = reaction_time, x = day, color = Subject)) +\n  geom_line()\n\n\n\n\n\n\n\n\n# Make a line plot of reaction time by day for each subject\n# Put these all on separate frames (one per subject)\nggplot(sleep_long, aes(y = reaction_time, x = day, color = Subject)) +\n  geom_line() +\n  facet_wrap(~Subject)\n\n\n\n\n\n\n\nPart b\nSummarize what you learned from the plots. For example:\n\nWhat’s the general relationship between reaction time and sleep? reaction time kind of increases, but not as much for everybody\n\nIs this the same for everybody? What differs? some increases are much higher than others, while some have a rather linear increase\n\nExercise 4: Pivot wider\nMake the data wide again, with each day becoming its own column.\nPart a\nAdjust the code below. What don’t you like about the column labels? they no longer have names\n\nsleep_long |&gt;\n  pivot_wider(names_from = day, values_from = reaction_time) |&gt;\n  head()\n\n# A tibble: 6 × 11\n  Subject   `0`   `1`   `2`   `3`   `4`   `5`   `6`   `7`   `8`   `9`\n  &lt;fct&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 308      250.  259.  251.  321.  357.  415.  382.  290.  431.  466.\n2 309      223.  205.  203.  205.  208.  216.  214.  218.  224.  237.\n3 310      199.  194.  234.  233.  229.  220.  235.  256.  261.  248.\n4 330      322.  300.  284.  285.  286.  298.  280.  318.  305.  354.\n5 331      288.  285   302.  320.  316.  293.  290.  335.  294.  372.\n6 332      235.  243.  273.  310.  317.  310   454.  347.  330.  254.\n\n\nPart b\nUsing your intuition, adjust your code from part a to name the reaction time columns “day_0”, “day_1”, etc.\n\nsleep_long |&gt;\n  pivot_wider(names_from = day, values_from = reaction_time, names_prefix = \"day_\") |&gt;\n  head()\n\n# A tibble: 6 × 11\n  Subject day_0 day_1 day_2 day_3 day_4 day_5 day_6 day_7 day_8 day_9\n  &lt;fct&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 308      250.  259.  251.  321.  357.  415.  382.  290.  431.  466.\n2 309      223.  205.  203.  205.  208.  216.  214.  218.  224.  237.\n3 310      199.  194.  234.  233.  229.  220.  235.  256.  261.  248.\n4 330      322.  300.  284.  285.  286.  298.  280.  318.  305.  354.\n5 331      288.  285   302.  320.  316.  293.  290.  335.  294.  372.\n6 332      235.  243.  273.  310.  317.  310   454.  347.  330.  254.\n\n\nExercise 5: Practice with Billboard charts\nLoad data on songs that hit the billboard charts around the year 2000. Included for each song is the artist name, track name, the date it hit the charts (date.enter), and wk-related variables that indicate rankings in each subsequent week on the charts:\n\n# Load data\nlibrary(tidyr)\ndata(\"billboard\")\n\n# Check it out\nhead(billboard)\n\n# A tibble: 6 × 79\n  artist      track date.entered   wk1   wk2   wk3   wk4   wk5   wk6   wk7   wk8\n  &lt;chr&gt;       &lt;chr&gt; &lt;date&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 2 Pac       Baby… 2000-02-26      87    82    72    77    87    94    99    NA\n2 2Ge+her     The … 2000-09-02      91    87    92    NA    NA    NA    NA    NA\n3 3 Doors Do… Kryp… 2000-04-08      81    70    68    67    66    57    54    53\n4 3 Doors Do… Loser 2000-10-21      76    76    72    69    67    65    55    59\n5 504 Boyz    Wobb… 2000-04-15      57    34    25    17    17    31    36    49\n6 98^0        Give… 2000-08-19      51    39    34    26    26    19     2     2\n# ℹ 68 more variables: wk9 &lt;dbl&gt;, wk10 &lt;dbl&gt;, wk11 &lt;dbl&gt;, wk12 &lt;dbl&gt;,\n#   wk13 &lt;dbl&gt;, wk14 &lt;dbl&gt;, wk15 &lt;dbl&gt;, wk16 &lt;dbl&gt;, wk17 &lt;dbl&gt;, wk18 &lt;dbl&gt;,\n#   wk19 &lt;dbl&gt;, wk20 &lt;dbl&gt;, wk21 &lt;dbl&gt;, wk22 &lt;dbl&gt;, wk23 &lt;dbl&gt;, wk24 &lt;dbl&gt;,\n#   wk25 &lt;dbl&gt;, wk26 &lt;dbl&gt;, wk27 &lt;dbl&gt;, wk28 &lt;dbl&gt;, wk29 &lt;dbl&gt;, wk30 &lt;dbl&gt;,\n#   wk31 &lt;dbl&gt;, wk32 &lt;dbl&gt;, wk33 &lt;dbl&gt;, wk34 &lt;dbl&gt;, wk35 &lt;dbl&gt;, wk36 &lt;dbl&gt;,\n#   wk37 &lt;dbl&gt;, wk38 &lt;dbl&gt;, wk39 &lt;dbl&gt;, wk40 &lt;dbl&gt;, wk41 &lt;dbl&gt;, wk42 &lt;dbl&gt;,\n#   wk43 &lt;dbl&gt;, wk44 &lt;dbl&gt;, wk45 &lt;dbl&gt;, wk46 &lt;dbl&gt;, wk47 &lt;dbl&gt;, wk48 &lt;dbl&gt;, …\n\n\nIn using this data, you’ll need to determine if and when the data needs to be reshaped for the task at hand.\nPart a\nConstruct and summarize a plot of how a song’s Billboard ranking its 2nd week on the chart (y-axis) is related to its ranking the 1st week on the charts (x-axis). Add a reference line geom_abline(intercept = 0, slope = 1). Songs above this line improved their rankings from the 1st to 2nd week. The higher the week one performance, the higher the week two performance will be, but most don’t go above the week one performance\n\nggplot(billboard, aes(x = wk1, y = wk2)) +\n  geom_point() +\n  geom_abline(intercept = 0, slope = 1)\n\n\n\n\n\n\n\nPart b\nUse your wrangling tools to identify which songs are those above the line in Part a, i.e. with rankgings that went up from week 1 to week 2.\n\nbillboard |&gt;\n  filter(wk1 &lt; wk2) |&gt;\n  select(artist, track, date.entered)\n\n# A tibble: 7 × 3\n  artist        track               date.entered\n  &lt;chr&gt;         &lt;chr&gt;               &lt;date&gt;      \n1 Carey, Mariah Crybaby             2000-06-24  \n2 Clark, Terri  A Little Gasoline   2000-12-16  \n3 Diffie, Joe   The Quittin' Kind   2000-01-01  \n4 Hart, Beth    L.A. Song           1999-11-27  \n5 Jay-Z         Hey Papi            2000-08-12  \n6 Lil' Zane     Callin' Me          2000-07-29  \n7 Pearl Jam     Nothing As It Seems 2000-05-13  \n\n\nPart c\nDefine a new dataset, nov_1999, which:\n\nonly includes data on songs that entered the Billboard charts on November 6, 1999\nkeeps all variables except track and date.entered. HINT: How can you avoid writing out all the variable names you want to keep?\n\n\n# Define nov_1999\nnov_1999 &lt;- billboard |&gt;\n  filter(date.entered == \"1999-11-6\") |&gt;\n  select(-track, -date.entered)\n\n# Confirm that nov_1999 has 2 rows (songs) and 77 columns\nncol(nov_1999)\n\n[1] 77\n\nnrow(nov_1999)\n\n[1] 2\n\n\nPart d\nCreate and discuss a visualization of the rankings (y-axis) over time (x-axis) for the 2 songs in nov_1999. There are hints below (if you scroll), but you’re encouraged to play around and use as few hints as possible.\n\nnov_1999 |&gt;\n  pivot_longer(cols = -artist, names_to = \"week\", names_prefix = \"wk\", values_to = \"ranking\") |&gt;\n  mutate(week = as.numeric(week)) |&gt;\n  ggplot(aes(x = week, y = ranking, color = artist)) +\n  geom_line()\n\n\n\n\n\n\n\nHints:\n\nShould you first pivot wider or longer?\nOnce you pivot, the week number is turned into a character variable. How can you change it to a number?\nExercise 6: Practice with the Daily Show\nThe data associated with this article is available in the fivethirtyeight package, and is loaded into daily below. It includes a list of every guest to ever appear on Jon Stewart’s The Daily Show, a “late-night talk and satirical news” program (per Wikipedia). Check out the dataset and note that when multiple people appeared together, each person receives their own line:\n\nlibrary(fivethirtyeight)\ndata(\"daily_show_guests\")\ndaily &lt;- daily_show_guests\n\nIn analyzing this data, you’ll need to determine if and when the data needs to be reshaped.\nPart a\nIdentify the 15 guests that appeared the most. (This isn’t a very diverse guest list!)\n\ndaily |&gt; \n  count(raw_guest_list) |&gt; \n  arrange(desc(n)) |&gt; \n  head(15)\n\n# A tibble: 15 × 2\n   raw_guest_list        n\n   &lt;chr&gt;             &lt;int&gt;\n 1 Fareed Zakaria       19\n 2 Denis Leary          17\n 3 Brian Williams       16\n 4 Paul Rudd            13\n 5 Ricky Gervais        13\n 6 Tom Brokaw           12\n 7 Bill O'Reilly        10\n 8 Reza Aslan           10\n 9 Richard Lewis        10\n10 Will Ferrell         10\n11 Sarah Vowell          9\n12 Adam Sandler          8\n13 Ben Affleck           8\n14 Louis C.K.            8\n15 Maggie Gyllenhaal     8\n\n\nPart b\nCHALLENGE: Create the following data set containing 19 columns:\n\nThe first column should have the 15 guests with the highest number of total appearances on the show, listed in descending order of number of appearances.\n17 columns should show the number of appearances of the corresponding guest in each year from 1999 to 2015 (one per column).\nAnother column should show the total number of appearances for the corresponding guest over the entire duration of the show.\n\nThere are hints below (if you scroll), but you’re encouraged to play around and use as few hints as possible.\nHINTS: There are lots of ways to do this. You don’t necessarily need all of these hints.\n\nFirst obtain the number of times a guest appears each year.\nAdd a new column which includes the total number of times a guest appears across all years.\nPivot (longer or wider?). When you do, use values_fill = 0 to replace NA values with 0.\nArrange, then and keep the top 15.\nPart c\nLet’s recreate the first figure from the article. This groups all guests into 3 broader occupational categories. However, our current data has 18 categories:\n\ndaily |&gt; \n  count(group)\n\n# A tibble: 18 × 2\n   group              n\n   &lt;chr&gt;          &lt;int&gt;\n 1 Academic         103\n 2 Acting           930\n 3 Advocacy          24\n 4 Athletics         52\n 5 Business          25\n 6 Clergy             8\n 7 Comedy           150\n 8 Consultant        18\n 9 Government        40\n10 Media            751\n11 Military          16\n12 Misc              45\n13 Musician         123\n14 Political Aide    36\n15 Politician       308\n16 Science           28\n17 media              5\n18 &lt;NA&gt;              31\n\n\nLet’s define a new dataset that includes a new variable, broad_group, that buckets these 18 categories into the 3 bigger ones used in the article. And get rid of any rows missing information on broad_group. You’ll learn the code soon! For now, just run this chunk:\n\nplot_data &lt;- daily |&gt; \n  mutate(broad_group = case_when(\n    group %in% c(\"Acting\", \"Athletics\", \"Comedy\", \"Musician\") ~ \"Acting, Comedy & Music\",\n    group %in% c(\"Media\", \"media\", \"Science\", \"Academic\", \"Consultant\", \"Clergy\") ~ \"Media\",\n    group %in% c(\"Politician\", \"Political Aide\", \"Government\", \"Military\", \"Business\", \"Advocacy\") ~ \"Government and Politics\",\n    .default = NA\n  )) |&gt; \n  filter(!is.na(broad_group))\n\nNow, using the broad_group variable in plot_data, recreate the graphic from the article, with three different lines showing the fraction of guests in each group over time. Note: You’ll have to wrangle the data first.\n\nplot_data |&gt;\n  group_by(year, broad_group) |&gt;\n  summarise(n = n()) |&gt;\n  mutate(freq = n / sum(n)) |&gt; \n  ggplot(aes(y = freq, x = year, color = broad_group)) + \n    geom_line()",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Reshaping</span>"
    ]
  },
  {
    "objectID": "ica/ica-reshaping.html#solutions",
    "href": "ica/ica-reshaping.html#solutions",
    "title": "\n20  Reshaping\n",
    "section": "\n20.4 Solutions",
    "text": "20.4 Solutions\n\nClick for Solutions\nEXAMPLE 1: warm-up counts and proportions\n\n# Using count()\npenguins |&gt; \n  count(species, sex)\n\n# A tibble: 8 × 3\n  species   sex        n\n  &lt;chr&gt;     &lt;chr&gt;  &lt;int&gt;\n1 Adelie    female    73\n2 Adelie    male      73\n3 Adelie    &lt;NA&gt;       6\n4 Chinstrap female    34\n5 Chinstrap male      34\n6 Gentoo    female    58\n7 Gentoo    male      61\n8 Gentoo    &lt;NA&gt;       5\n\n# Using group_by() and summarize()\npenguins |&gt; \n  group_by(species, sex) |&gt; \n  summarize(n())\n\n# A tibble: 8 × 3\n# Groups:   species [3]\n  species   sex    `n()`\n  &lt;chr&gt;     &lt;chr&gt;  &lt;int&gt;\n1 Adelie    female    73\n2 Adelie    male      73\n3 Adelie    &lt;NA&gt;       6\n4 Chinstrap female    34\n5 Chinstrap male      34\n6 Gentoo    female    58\n7 Gentoo    male      61\n8 Gentoo    &lt;NA&gt;       5\n\n# Relative frequencies\npenguins |&gt; \n  group_by(species, sex) |&gt; \n  summarize(n = n()) |&gt; \n  mutate(proportion = n / sum(n))\n\n# A tibble: 8 × 4\n# Groups:   species [3]\n  species   sex        n proportion\n  &lt;chr&gt;     &lt;chr&gt;  &lt;int&gt;      &lt;dbl&gt;\n1 Adelie    female    73     0.480 \n2 Adelie    male      73     0.480 \n3 Adelie    &lt;NA&gt;       6     0.0395\n4 Chinstrap female    34     0.5   \n5 Chinstrap male      34     0.5   \n6 Gentoo    female    58     0.468 \n7 Gentoo    male      61     0.492 \n8 Gentoo    &lt;NA&gt;       5     0.0403\n\n# Changing the order calculates the proportion of species within each sex\npenguins |&gt; \n  group_by(sex, species) |&gt; \n  summarize(n = n()) |&gt; \n  mutate(proportion = n / sum(n))\n\n# A tibble: 8 × 4\n# Groups:   sex [3]\n  sex    species       n proportion\n  &lt;chr&gt;  &lt;chr&gt;     &lt;int&gt;      &lt;dbl&gt;\n1 female Adelie       73      0.442\n2 female Chinstrap    34      0.206\n3 female Gentoo       58      0.352\n4 male   Adelie       73      0.435\n5 male   Chinstrap    34      0.202\n6 male   Gentoo       61      0.363\n7 &lt;NA&gt;   Adelie        6      0.545\n8 &lt;NA&gt;   Gentoo        5      0.455\n\n\nEXAMPLE 3: units of observation\n\n# Units of observation = penguins\nhead(penguins)\n\n# A tibble: 6 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;chr&gt;   &lt;chr&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;dbl&gt;       &lt;dbl&gt;\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           40.3          18                 195        3250\n4 Adelie  Torgersen           NA            NA                  NA          NA\n5 Adelie  Torgersen           36.7          19.3               193        3450\n6 Adelie  Torgersen           39.3          20.6               190        3650\n# ℹ 2 more variables: sex &lt;chr&gt;, year &lt;dbl&gt;\n\n# Units of observation = species/sex combos\nhead(penguin_avg)\n\n# A tibble: 6 × 3\n# Groups:   species [3]\n  species   sex    avg_body_mass\n  &lt;chr&gt;     &lt;chr&gt;          &lt;dbl&gt;\n1 Adelie    female         3369.\n2 Adelie    male           4043.\n3 Chinstrap female         3527.\n4 Chinstrap male           3939.\n5 Gentoo    female         4680.\n6 Gentoo    male           5485.\n\n\nEXAMPLE 5: pivot wider\n\npenguin_avg |&gt; \n  pivot_wider(names_from = sex, values_from = avg_body_mass)\n\n# A tibble: 3 × 3\n# Groups:   species [3]\n  species   female  male\n  &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt;\n1 Adelie     3369. 4043.\n2 Chinstrap  3527. 3939.\n3 Gentoo     4680. 5485.\n\n\nFOLLOW-UP:\n\nWhat are the units of observation? species\nDid we lose any information when we widened the data? no\nUse the wide data to calculate the difference in average body mass, male vs female, for each species.\n\n\npenguin_avg |&gt; \n  pivot_wider(names_from = sex, values_from = avg_body_mass) |&gt; \n  mutate(diff = male - female)\n\n# A tibble: 3 × 4\n# Groups:   species [3]\n  species   female  male  diff\n  &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Adelie     3369. 4043.  675.\n2 Chinstrap  3527. 3939.  412.\n3 Gentoo     4680. 5485.  805.\n\n\nEXAMPLE 6: Pivot longer\n\n# We can either communicate which variables we WANT to collect into a single column (female, male)\npenguin_avg_wide |&gt; \n  pivot_longer(cols = c(female, male), names_to = \"sex\", values_to = \"avg_body_mass\")\n\n# A tibble: 6 × 3\n# Groups:   species [3]\n  species   sex    avg_body_mass\n  &lt;chr&gt;     &lt;chr&gt;          &lt;dbl&gt;\n1 Adelie    female         3369.\n2 Adelie    male           4043.\n3 Chinstrap female         3527.\n4 Chinstrap male           3939.\n5 Gentoo    female         4680.\n6 Gentoo    male           5485.\n\n# Or which variable(s) we do NOT want to collect into a single column (sex)\npenguin_avg_wide |&gt; \n  pivot_longer(cols = -species, names_to = \"sex\", values_to = \"avg_body_mass\")\n\n# A tibble: 6 × 3\n# Groups:   species [3]\n  species   sex    avg_body_mass\n  &lt;chr&gt;     &lt;chr&gt;          &lt;dbl&gt;\n1 Adelie    female         3369.\n2 Adelie    male           4043.\n3 Chinstrap female         3527.\n4 Chinstrap male           3939.\n5 Gentoo    female         4680.\n6 Gentoo    male           5485.\n\n\nFOLLOW-UP:\n\nWhat are the units of observation? species/sex combos\nDid we lose any information when we lengthened the data? no\n\n20.4.1 EXAMPLE 7: Practice [-]\n\nfood &lt;- data.frame(\n  customer = rep(c(\"A\", \"B\"), each = 3),\n  restaurant = rep(c(\"Shish\", \"FrenchMeadow\", \"DunnBros\"), 2),\n  order = c(\"falafel\", \"salad\", \"coffee\", \"baklava\", \"pastry\", \"tea\")\n)\n\nfood\n\n  customer   restaurant   order\n1        A        Shish falafel\n2        A FrenchMeadow   salad\n3        A     DunnBros  coffee\n4        B        Shish baklava\n5        B FrenchMeadow  pastry\n6        B     DunnBros     tea\n\nfood |&gt; \n  pivot_wider(names_from = restaurant, values_from = order)\n\n# A tibble: 2 × 4\n  customer Shish   FrenchMeadow DunnBros\n  &lt;chr&gt;    &lt;chr&gt;   &lt;chr&gt;        &lt;chr&gt;   \n1 A        falafel salad        coffee  \n2 B        baklava pastry       tea     \n\n\n\nmore_food &lt;- data.frame(\n  customer = c(\"C\", \"D\"),\n  Shish = c(\"coffee\", \"maza\"),\n  FrenchMeadow = c(\"soup\", \"sandwich\"),\n  DunnBros = c(\"cookie\", \"coffee\")\n)\n\nmore_food\n\n  customer  Shish FrenchMeadow DunnBros\n1        C coffee         soup   cookie\n2        D   maza     sandwich   coffee\n\nmore_food |&gt; \n  pivot_longer(cols = -customer, names_to = \"restaurant\", values_to = \"order\")\n\n# A tibble: 6 × 3\n  customer restaurant   order   \n  &lt;chr&gt;    &lt;chr&gt;        &lt;chr&gt;   \n1 C        Shish        coffee  \n2 C        FrenchMeadow soup    \n3 C        DunnBros     cookie  \n4 D        Shish        maza    \n5 D        FrenchMeadow sandwich\n6 D        DunnBros     coffee  \n\n\nExercise 1: What’s the problem?\nPart a\nsubjects/people\nPart c\npivot_longer()\nExercise 2: Pivot longer\nPart a\n\n# For cols, try 2 appproaches: using - and starts_with\nsleep_wide |&gt;\n  pivot_longer(cols = -Subject, names_to = \"day\", values_to = \"reaction_time\")\n\n# A tibble: 180 × 3\n   Subject day   reaction_time\n     &lt;int&gt; &lt;chr&gt;         &lt;dbl&gt;\n 1     308 day_0          250.\n 2     308 day_1          259.\n 3     308 day_2          251.\n 4     308 day_3          321.\n 5     308 day_4          357.\n 6     308 day_5          415.\n 7     308 day_6          382.\n 8     308 day_7          290.\n 9     308 day_8          431.\n10     308 day_9          466.\n# ℹ 170 more rows\n\nsleep_wide |&gt;\n  pivot_longer(cols = starts_with(\"day\"), names_to = \"day\", values_to = \"reaction_time\")\n\n# A tibble: 180 × 3\n   Subject day   reaction_time\n     &lt;int&gt; &lt;chr&gt;         &lt;dbl&gt;\n 1     308 day_0          250.\n 2     308 day_1          259.\n 3     308 day_2          251.\n 4     308 day_3          321.\n 5     308 day_4          357.\n 6     308 day_5          415.\n 7     308 day_6          382.\n 8     308 day_7          290.\n 9     308 day_8          431.\n10     308 day_9          466.\n# ℹ 170 more rows\n\n\nPart b\nAdding names_prefix = \"day_\" removed “day_” from the start of the day entries. did this impact how the values are recorded in the day column?\n\nsleep_long &lt;- sleep_wide |&gt;\n  pivot_longer(cols = -Subject,\n               names_to = \"day\",\n               names_prefix = \"day_\",\n               values_to = \"reaction_time\") \n\nPart c\nSubject is an integer and day is a character. We want them to be categorical (factor) and numeric, respectively.\n\nggplot(sleep_long, aes(y = reaction_time, x = day, color = Subject)) + \n  geom_line()\n\n\n\n\n\n\n\nExercise 3: Changing variable classes & plotting\n\nsleep_long &lt;- sleep_wide |&gt;\n  pivot_longer(cols = -Subject,\n               names_to = \"day\",\n               names_prefix = \"day_\",\n               values_to = \"reaction_time\") |&gt; \n  mutate(Subject = as.factor(Subject), day = as.numeric(day))\n\nPart a\nNow make some plots.\n\n# Make a line plot of reaction time by day for each subject\n# Put these all on the same frame\nggplot(sleep_long, aes(y = reaction_time, x = day, color = Subject)) + \n  geom_line()\n\n\n\n\n\n\n\n\n# Make a line plot of reaction time by day for each subject\n# Put these all on separate frames (one per subject)\nggplot(sleep_long, aes(y = reaction_time, x = day, color = Subject)) + \n  geom_line() + \n  facet_wrap(~ Subject)\n\n\n\n\n\n\n\nPart b\nReaction time increases (worsens) with a lack of sleep. Some subjects seem to be more impacted than others by lack of sleep, and some tend to have faster/slower reaction times in general.\nExercise 4: Pivot wider\nPart a\n\nsleep_long |&gt;\n  pivot_wider(names_from = day, values_from = reaction_time) |&gt;\n  head()\n\n# A tibble: 6 × 11\n  Subject   `0`   `1`   `2`   `3`   `4`   `5`   `6`   `7`   `8`   `9`\n  &lt;fct&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 308      250.  259.  251.  321.  357.  415.  382.  290.  431.  466.\n2 309      223.  205.  203.  205.  208.  216.  214.  218.  224.  237.\n3 310      199.  194.  234.  233.  229.  220.  235.  256.  261.  248.\n4 330      322.  300.  284.  285.  286.  298.  280.  318.  305.  354.\n5 331      288.  285   302.  320.  316.  293.  290.  335.  294.  372.\n6 332      235.  243.  273.  310.  317.  310   454.  347.  330.  254.\n\n\nPart b\n\nsleep_long |&gt;\n  pivot_wider(names_from = day, values_from = reaction_time, names_prefix = \"day_\") |&gt;\n  head()\n\n# A tibble: 6 × 11\n  Subject day_0 day_1 day_2 day_3 day_4 day_5 day_6 day_7 day_8 day_9\n  &lt;fct&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 308      250.  259.  251.  321.  357.  415.  382.  290.  431.  466.\n2 309      223.  205.  203.  205.  208.  216.  214.  218.  224.  237.\n3 310      199.  194.  234.  233.  229.  220.  235.  256.  261.  248.\n4 330      322.  300.  284.  285.  286.  298.  280.  318.  305.  354.\n5 331      288.  285   302.  320.  316.  293.  290.  335.  294.  372.\n6 332      235.  243.  273.  310.  317.  310   454.  347.  330.  254.\n\n\nExercise 5: Practice with Billboard charts\nPart a\nThe higher a song’s week 1 rating, the higher its week 2 rating tends to be. But almost all song’s rankings drop from week 1 to week 2.\n\nggplot(billboard, aes(y = wk2, x = wk1)) + \n  geom_point() +\n  geom_abline(intercept = 0, slope = 1)\n\n\n\n\n\n\n\nPart b\n\nbillboard |&gt; \n  filter(wk2 &gt; wk1)\n\n# A tibble: 7 × 79\n  artist      track date.entered   wk1   wk2   wk3   wk4   wk5   wk6   wk7   wk8\n  &lt;chr&gt;       &lt;chr&gt; &lt;date&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Carey, Mar… Cryb… 2000-06-24      28    34    48    62    77    90    95    NA\n2 Clark, Ter… A Li… 2000-12-16      75    82    88    96    99    99    NA    NA\n3 Diffie, Joe The … 2000-01-01      98   100   100    90    93    94    NA    NA\n4 Hart, Beth  L.A.… 1999-11-27      99   100    98    99    99    99    98    90\n5 Jay-Z       Hey … 2000-08-12      98   100    98    94    83    83    80    78\n6 Lil' Zane   Call… 2000-07-29      83    89    57    40    34    21    33    46\n7 Pearl Jam   Noth… 2000-05-13      49    70    84    89    93    91    NA    NA\n# ℹ 68 more variables: wk9 &lt;dbl&gt;, wk10 &lt;dbl&gt;, wk11 &lt;dbl&gt;, wk12 &lt;dbl&gt;,\n#   wk13 &lt;dbl&gt;, wk14 &lt;dbl&gt;, wk15 &lt;dbl&gt;, wk16 &lt;dbl&gt;, wk17 &lt;dbl&gt;, wk18 &lt;dbl&gt;,\n#   wk19 &lt;dbl&gt;, wk20 &lt;dbl&gt;, wk21 &lt;dbl&gt;, wk22 &lt;dbl&gt;, wk23 &lt;dbl&gt;, wk24 &lt;dbl&gt;,\n#   wk25 &lt;dbl&gt;, wk26 &lt;dbl&gt;, wk27 &lt;dbl&gt;, wk28 &lt;dbl&gt;, wk29 &lt;dbl&gt;, wk30 &lt;dbl&gt;,\n#   wk31 &lt;dbl&gt;, wk32 &lt;dbl&gt;, wk33 &lt;dbl&gt;, wk34 &lt;dbl&gt;, wk35 &lt;dbl&gt;, wk36 &lt;dbl&gt;,\n#   wk37 &lt;dbl&gt;, wk38 &lt;dbl&gt;, wk39 &lt;dbl&gt;, wk40 &lt;dbl&gt;, wk41 &lt;dbl&gt;, wk42 &lt;dbl&gt;,\n#   wk43 &lt;dbl&gt;, wk44 &lt;dbl&gt;, wk45 &lt;dbl&gt;, wk46 &lt;dbl&gt;, wk47 &lt;dbl&gt;, wk48 &lt;dbl&gt;, …\n\n\nPart c\n\n# Define nov_1999\nnov_1999 &lt;- billboard |&gt; \n  filter(date.entered == \"1999-11-06\") |&gt; \n  select(-track, -date.entered)\n\n# Or\nnov_1999 &lt;- billboard |&gt; \n  filter(date.entered == \"1999-11-06\") |&gt; \n  select(artist, starts_with(\"wk\"))\n\n\n# Confirm that nov_1999 has 2 rows (songs) and 77 columns\ndim(nov_1999)\n\n[1]  2 77\n\n\nPart c\n\nnov_1999 |&gt; \n  pivot_longer(cols = -artist, names_to = \"week\", names_prefix = \"wk\", values_to = \"ranking\") |&gt; \n  mutate(week = as.numeric(week)) |&gt; \n  ggplot(aes(y = ranking, x = week, color = artist)) + \n    geom_line()\n\n\n\n\n\n\n\nExercise 6: Practice with the Daily Show\nPart a\n\ndaily |&gt; \n  count(raw_guest_list) |&gt; \n  arrange(desc(n)) |&gt; \n  head(15)\n\n# A tibble: 15 × 2\n   raw_guest_list        n\n   &lt;chr&gt;             &lt;int&gt;\n 1 Fareed Zakaria       19\n 2 Denis Leary          17\n 3 Brian Williams       16\n 4 Paul Rudd            13\n 5 Ricky Gervais        13\n 6 Tom Brokaw           12\n 7 Bill O'Reilly        10\n 8 Reza Aslan           10\n 9 Richard Lewis        10\n10 Will Ferrell         10\n11 Sarah Vowell          9\n12 Adam Sandler          8\n13 Ben Affleck           8\n14 Louis C.K.            8\n15 Maggie Gyllenhaal     8\n\n\nPart b\n\ndaily |&gt; \n  count(year, raw_guest_list) |&gt; \n  group_by(raw_guest_list) |&gt; \n  mutate(total = sum(n)) |&gt;\n  pivot_wider(names_from = year, \n              values_from = n,\n              values_fill = 0) |&gt; \n  arrange(desc(total)) |&gt; \n  head(15)\n\n# A tibble: 15 × 19\n# Groups:   raw_guest_list [15]\n   raw_guest_list  total `1999` `2000` `2001` `2002` `2003` `2004` `2005` `2006`\n   &lt;chr&gt;           &lt;int&gt;  &lt;int&gt;  &lt;int&gt;  &lt;int&gt;  &lt;int&gt;  &lt;int&gt;  &lt;int&gt;  &lt;int&gt;  &lt;int&gt;\n 1 Fareed Zakaria     19      0      0      1      0      1      2      2      2\n 2 Denis Leary        17      1      0      1      2      1      0      0      1\n 3 Brian Williams     16      0      0      0      0      1      1      2      1\n 4 Paul Rudd          13      1      0      1      1      1      1      1      0\n 5 Ricky Gervais      13      0      0      0      0      0      0      1      2\n 6 Tom Brokaw         12      0      0      0      1      0      2      1      0\n 7 Richard Lewis      10      1      0      2      2      1      1      0      0\n 8 Will Ferrell       10      0      1      1      0      1      1      1      1\n 9 Bill O'Reilly      10      0      0      1      1      0      1      1      0\n10 Reza Aslan         10      0      0      0      0      0      0      1      2\n11 Sarah Vowell        9      0      0      0      1      0      1      1      1\n12 Adam Sandler        8      1      2      0      1      0      0      0      1\n13 Ben Affleck         8      0      0      0      0      2      0      0      1\n14 Maggie Gyllenh…     8      0      0      0      0      1      0      1      1\n15 Louis C.K.          8      0      0      0      0      0      0      0      1\n# ℹ 9 more variables: `2007` &lt;int&gt;, `2008` &lt;int&gt;, `2009` &lt;int&gt;, `2010` &lt;int&gt;,\n#   `2011` &lt;int&gt;, `2012` &lt;int&gt;, `2013` &lt;int&gt;, `2014` &lt;int&gt;, `2015` &lt;int&gt;\n\n\nPart c\n\nplot_data |&gt;\n  group_by(year, broad_group) |&gt;\n  summarise(n = n()) |&gt;\n  mutate(freq = n / sum(n)) |&gt; \n  ggplot(aes(y = freq, x = year, color = broad_group)) + \n    geom_line()",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Reshaping</span>"
    ]
  },
  {
    "objectID": "ica/ica-reshaping.html#footnotes",
    "href": "ica/ica-reshaping.html#footnotes",
    "title": "\n20  Reshaping\n",
    "section": "",
    "text": "Gregory Belenky, Nancy J. Wesensten, David R. Thorne, Maria L. Thomas, Helen C. Sing, Daniel P. Redmond, Michael B. Russo and Thomas J. Balkin (2003) Patterns of performance degradation and restoration during sleep restriction and subsequent recovery: a sleep dose-response study. Journal of Sleep Research 12, 1–12.↩︎",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Reshaping</span>"
    ]
  },
  {
    "objectID": "ica/ica-joining.html",
    "href": "ica/ica-joining.html",
    "title": "\n21  Joining\n",
    "section": "",
    "text": "21.1 Review\nWhere are we? Data preparation\nThus far, we’ve learned how to:",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Joining</span>"
    ]
  },
  {
    "objectID": "ica/ica-joining.html#review",
    "href": "ica/ica-joining.html#review",
    "title": "\n21  Joining\n",
    "section": "",
    "text": "arrange() our data in a meaningful order\nsubset the data to only filter() the rows and select() the columns of interest\n\nmutate() existing variables and define new variables\n\nsummarize() various aspects of a variable, both overall and by group (group_by())\nreshape our data to fit the task at hand (pivot_longer(), pivot_wider())",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Joining</span>"
    ]
  },
  {
    "objectID": "ica/ica-joining.html#motivation",
    "href": "ica/ica-joining.html#motivation",
    "title": "\n21  Joining\n",
    "section": "\n21.2 Motivation",
    "text": "21.2 Motivation\nIn practice, we often have to collect and combine data from various sources in order to address our research questions. Example:\n\nWhat are the best predictors of album sales?\nCombine:\n\nSpotify data on individual songs (eg: popularity, genre, characteristics)\nsales data on individual songs\n\n\nWhat are the best predictors of flight delays?\nCombine:\n\ndata on individual flights including airline, starting airport, and destination airport\ndata on different airlines (eg: ticket prices, reliability, etc)\ndata on different airports (eg: location, reliability, etc)\n\n\n\nExample 1\nConsider the following (made up) data on students and course enrollments:\n\nstudents_1 &lt;- data.frame(\n  student = c(\"A\", \"B\", \"C\"),\n  class = c(\"STAT 101\", \"GEOL 101\", \"ANTH 101\")\n)\n\n# Check it out\nstudents_1\n\n  student    class\n1       A STAT 101\n2       B GEOL 101\n3       C ANTH 101\n\n\n\nenrollments_1 &lt;- data.frame(\n  class = c(\"STAT 101\", \"ART 101\", \"GEOL 101\"),\n  enrollment = c(18, 17, 24)\n)\n\n# Check it out\nenrollments_1\n\n     class enrollment\n1 STAT 101         18\n2  ART 101         17\n3 GEOL 101         24\n\n\nOur goal is to combine or join these datasets into one. For reference, here they are side by side:\n\nFirst, consider the following:\n\nWhat variable or key do these datasets have in common? Thus by what information can we match the observations in these datasets?\nRelative to this key, what info does students_1 have that enrollments_1 doesn’t?\nRelative to this key, what info does enrollments_1 have that students_1 doesn’t?",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Joining</span>"
    ]
  },
  {
    "objectID": "ica/ica-joining.html#mutating-joins-left-inner-full",
    "href": "ica/ica-joining.html#mutating-joins-left-inner-full",
    "title": "\n21  Joining\n",
    "section": "\n21.3 Mutating Joins: left, inner, full\n",
    "text": "21.3 Mutating Joins: left, inner, full\n\nExample 2\nThere are various ways to join these datasets:\n\nLet’s learn by doing. First, try the left_join() function:\n\nlibrary(tidyverse)\nstudents_1 |&gt; \n  left_join(enrollments_1)\n\n  student    class enrollment\n1       A STAT 101         18\n2       B GEOL 101         24\n3       C ANTH 101         NA\n\n\n\nWhat did this do? What are the roles of students_1 (the left table) and enrollments_1 (the right table)? the class, and when they enrolled\n\nWhat, if anything, would change if we reversed the order of the data tables? Think about it, then try. the students would be on the left, enrollment would be at the right\n\n\n\nenrollments_1 |&gt;\n  left_join(students_1)\n\n     class enrollment student\n1 STAT 101         18       A\n2  ART 101         17    &lt;NA&gt;\n3 GEOL 101         24       B\n\n\nExample 3\nNext, explore how our datasets are joined using inner_join():\n\n\nstudents_1 |&gt; \n  inner_join(enrollments_1)\n\n  student    class enrollment\n1       A STAT 101         18\n2       B GEOL 101         24\n\n\n\nWhat did this do? What are the roles of students_1 (the left table) and enrollments_1 (the right table)? students are the subjects, enrollment is the year they enrolled\nWhat, if anything, would change if we reversed the order of the data tables? Think about it, then try. same thing would happen, students would be on the left now\n\n\nenrollments_1 |&gt;\n  inner_join(students_1)\n\n     class enrollment student\n1 STAT 101         18       A\n2 GEOL 101         24       B\n\n\nExample 4\nNext, explore how our datasets are joined using full_join():\n\n\nstudents_1 |&gt; \n  full_join(enrollments_1)\n\n  student    class enrollment\n1       A STAT 101         18\n2       B GEOL 101         24\n3       C ANTH 101         NA\n4    &lt;NA&gt;  ART 101         17\n\n\n\nWhat did this do? What are the roles of students_1 (the left table) and enrollments_1 (the right table)? *students are still the subjects and enrollment is still the variable of when they enrolled but it adds all categories, not just ones where there are values for all\nWhat, if anything, would change if we reversed the order of the data tables? Think about it, then try. the same thing would happen for all of these enrollment would be on the left and students on the right\n\n\nenrollments_1 |&gt;\n  full_join(students_1)\n\n     class enrollment student\n1 STAT 101         18       A\n2  ART 101         17    &lt;NA&gt;\n3 GEOL 101         24       B\n4 ANTH 101         NA       C\n\n\n\n21.3.1 Summary\nMutating joins add new variables (columns) to the left data table from matching observations in the right table:\nleft_data |&gt; mutating_join(right_data)\nThe most common mutating joins are:\n\nleft_join()\nKeeps all observations from the left, but discards any observations in the right that do not have a match in the left.1\ninner_join()\nKeeps only the observations from the left with a match in the right.\nfull_join()\nKeeps all observations from the left and the right. (This is less common than left_join() and inner_join()).\n\nNOTE: When an observation in the left table has multiple matches in the right table, these mutating joins produce a separate observation in the new table for each match.",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Joining</span>"
    ]
  },
  {
    "objectID": "ica/ica-joining.html#filtering-joins-semi-anti",
    "href": "ica/ica-joining.html#filtering-joins-semi-anti",
    "title": "\n21  Joining\n",
    "section": "\n21.4 Filtering Joins: semi, anti\n",
    "text": "21.4 Filtering Joins: semi, anti\n\nMutating joins combine information, thus increase the number of columns in a dataset (like mutate()). Filtering joins keep only certain observations in one dataset (like filter()), not based on rules related to any variables in the dataset, but on the observations that exist in another dataset. This is useful when we merely care about the membership or non-membership of an observation in the other dataset, not the raw data itself.\nExample 5\nIn our example data, suppose enrollments_1 only included courses being taught in the Theater building:\n\n\nstudents_1 |&gt; \n  semi_join(enrollments_1)\n\n  student    class\n1       A STAT 101\n2       B GEOL 101\n\n\n\nWhat did this do? What info would it give us? it only gives values on the left that match the right\nHow does semi_join() differ from inner_join()? inner join gives matches for both, this is specifically aimed at matches on the right side\nWhat, if anything, would change if we reversed the order of the data tables? Think about it, then try.\n\n\nenrollments_1 |&gt;\n  semi_join(students_1)\n\n     class enrollment\n1 STAT 101         18\n2 GEOL 101         24\n\n\nExample 6\nLet’s try another filtering join for our example data:\n\n\nstudents_1 |&gt; \n  anti_join(enrollments_1)\n\n  student    class\n1       C ANTH 101\n\n\n\nWhat did this do? What info would it give us? it retains the one without enrollment info\n\nWhat, if anything, would change if we reversed the order of the data tables? Think about it, then try.\n\n\nenrollments_1 |&gt;\n  anti_join(students_1)\n\n    class enrollment\n1 ART 101         17\n\n\n\n21.4.1 Summary\nFiltering joins keep specific observations from the left table based on whether they match an observation in the right table.\n\nsemi_join()\nDiscards any observations in the left table that do not have a match in the right table. If there are multiple matches of right cases to a left case, it keeps just one copy of the left case.\nanti_join()\nDiscards any observations in the left table that do have a match in the right table.",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Joining</span>"
    ]
  },
  {
    "objectID": "ica/ica-joining.html#summary-of-all-joins",
    "href": "ica/ica-joining.html#summary-of-all-joins",
    "title": "\n21  Joining\n",
    "section": "\n21.5 Summary of All Joins",
    "text": "21.5 Summary of All Joins",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Joining</span>"
    ]
  },
  {
    "objectID": "ica/ica-joining.html#exercises",
    "href": "ica/ica-joining.html#exercises",
    "title": "\n21  Joining\n",
    "section": "\n21.6 Exercises",
    "text": "21.6 Exercises\nExercise 1: Where are my keys?\nPart a\nDefine two new datasets, with different students and courses:\n\nstudents_2 &lt;- data.frame(\n  student = c(\"D\", \"E\", \"F\"),\n  class = c(\"COMP 101\", \"BIOL 101\", \"POLI 101\")\n)\n\n# Check it out\nstudents_2\n\n  student    class\n1       D COMP 101\n2       E BIOL 101\n3       F POLI 101\n\nenrollments_2 &lt;- data.frame(\n  course = c(\"ART 101\", \"BIOL 101\", \"COMP 101\"),\n  enrollment = c(18, 20, 19)\n)\n\n# Check it out\nenrollments_2\n\n    course enrollment\n1  ART 101         18\n2 BIOL 101         20\n3 COMP 101         19\n\n\nTo connect the course enrollments to the students’ courses, try do a left_join(). You get an error! Identify the problem by reviewing the error message and the datasets we’re trying to join.\n\n# eval = FALSE: don't evaluate this chunk when knitting. it produces an error.\nstudents_2 |&gt; \n  left_join(enrollments_2)\n\nPart b\nThe problem is that course name, the key or variable that links these two datasets, is labeled differently: class in the students_2 data and course in the enrollments_2 data. Thus we have to specify these keys in our code:\n\nstudents_2 |&gt; \n  left_join(enrollments_2, join_by(class == course))\n\n  student    class enrollment\n1       D COMP 101         19\n2       E BIOL 101         20\n3       F POLI 101         NA\n\n\n\n# The order of the keys is important:\n# by = c(\"left data key\" = \"right data key\")\n# The order is mixed up here, thus we get an error:\nstudents_2 |&gt; \n  left_join(enrollments_2, join_by(course == class))\n\nPart c\nDefine another set of fake data which adds grade information:\n\n# Add student grades in each course\nstudents_3 &lt;- data.frame(\n  student = c(\"Y\", \"Y\", \"Z\", \"Z\"),\n  class = c(\"COMP 101\", \"BIOL 101\", \"POLI 101\", \"COMP 101\"),\n  grade = c(\"B\", \"S\", \"C\", \"A\")\n)\n\n# Check it out\nstudents_3\n\n  student    class grade\n1       Y COMP 101     B\n2       Y BIOL 101     S\n3       Z POLI 101     C\n4       Z COMP 101     A\n\n# Add average grades in each course\nenrollments_3 &lt;- data.frame(\n  class = c(\"ART 101\", \"BIOL 101\",\"COMP 101\"),\n  grade = c(\"B\", \"A\", \"A-\"),\n  enrollment = c(20, 18, 19)\n)\n\n# Check it out\nenrollments_3\n\n     class grade enrollment\n1  ART 101     B         20\n2 BIOL 101     A         18\n3 COMP 101    A-         19\n\n\nTry doing a left_join() to link the students’ classes to their enrollment info. Did this work? Try and figure out the culprit by examining the output.\n\nstudents_3 |&gt; \n  left_join(enrollments_3)\n\n  student    class grade enrollment\n1       Y COMP 101     B         NA\n2       Y BIOL 101     S         NA\n3       Z POLI 101     C         NA\n4       Z COMP 101     A         NA\n\n\nPart d\nThe issue here is that our datasets have 2 column names in common: class and grade. BUT grade is measuring 2 different things here: individual student grades in students_3 and average student grades in enrollments_3. Thus it doesn’t make sense to try to join the datasets with respect to this variable. We can again solve this by specifying that we want to join the datasets using the class variable or key. What are grade.x and grade.y?\n\nstudents_3 |&gt; \n  left_join(enrollments_3, by = c(\"class\" = \"class\"))\n\n  student    class grade.x grade.y enrollment\n1       Y COMP 101       B      A-         19\n2       Y BIOL 101       S       A         18\n3       Z POLI 101       C    &lt;NA&gt;         NA\n4       Z COMP 101       A      A-         19\n\n\nExercise 2: More small practice\nBefore applying these ideas to bigger datasets, let’s practice identifying which join is appropriate in different scenarios. Define the following fake data on voters (people who have voted) and contact info for voting age adults (people who could vote):\n\n# People who have voted\nvoters &lt;- data.frame(\n  id = c(\"A\", \"D\", \"E\", \"F\", \"G\"),\n  times_voted = c(2, 4, 17, 6, 20)\n)\n\nvoters\n\n  id times_voted\n1  A           2\n2  D           4\n3  E          17\n4  F           6\n5  G          20\n\n# Contact info for voting age adults\ncontact &lt;- data.frame(\n  name = c(\"A\", \"B\", \"C\", \"D\"),\n  address = c(\"summit\", \"grand\", \"snelling\", \"fairview\"),\n  age = c(24, 89, 43, 38)\n)\n\ncontact\n\n  name  address age\n1    A   summit  24\n2    B    grand  89\n3    C snelling  43\n4    D fairview  38\n\n\nUse the appropriate join for each prompt below. In each case, think before you type:\n\nWhat dataset goes on the left?\nWhat do you want the resulting dataset to look like? How many rows and columns will it have?\n\n\n# 1. We want contact info for people who HAVEN'T voted\ncontact |&gt;\n  anti_join(voters, join_by(name == id))\n\n  name  address age\n1    B    grand  89\n2    C snelling  43\n\n# 2. We want contact info for people who HAVE voted\ncontact |&gt;\n  semi_join(voters, join_by(name == id))\n\n  name  address age\n1    A   summit  24\n2    D fairview  38\n\n# 3. We want any data available on each person\ncontact |&gt;\n  full_join(voters, join_by(name == id))\n\n  name  address age times_voted\n1    A   summit  24           2\n2    B    grand  89          NA\n3    C snelling  43          NA\n4    D fairview  38           4\n5    E     &lt;NA&gt;  NA          17\n6    F     &lt;NA&gt;  NA           6\n7    G     &lt;NA&gt;  NA          20\n\n# 4. When possible, we want to add contact info to the voting roster\nvoters |&gt;\n  full_join(contact, join_by(id == name))\n\n  id times_voted  address age\n1  A           2   summit  24\n2  D           4 fairview  38\n3  E          17     &lt;NA&gt;  NA\n4  F           6     &lt;NA&gt;  NA\n5  G          20     &lt;NA&gt;  NA\n6  B          NA    grand  89\n7  C          NA snelling  43\n\n\nExercise 3: Bigger datasets\nLet’s apply these ideas to some bigger datasets. In grades, each row is a student-class pair with information on:\n\n\nsid = student ID\n\ngrade = student’s grade\n\nsessionID = an identifier of the class section\n\n\n\n     sid grade   sessionID\n1 S31185    D+ session1784\n2 S31185    B+ session1785\n3 S31185    A- session1791\n4 S31185    B+ session1792\n5 S31185    B- session1794\n6 S31185    C+ session1795\n\n\nIn courses, each row corresponds to a class section with information on:\n\n\nsessionID = an identifier of the class section\n\ndept = department\n\nlevel = course level (eg: 100)\n\nsem = semester\n\nenroll = enrollment (number of students)\n\niid = instructor ID\n\n\n\n    sessionID dept level    sem enroll     iid\n1 session1784    M   100 FA1991     22 inst265\n2 session1785    k   100 FA1991     52 inst458\n3 session1791    J   100 FA1993     22 inst223\n4 session1792    J   300 FA1993     20 inst235\n5 session1794    J   200 FA1993     22 inst234\n6 session1795    J   200 SP1994     26 inst230\n\n\nUse R code to take a quick glance at the data.\n\n# How many observations (rows) and variables (columns) are there in the grades data?\nncol(grades)\n\n[1] 3\n\nnrow(grades)\n\n[1] 5844\n\n# How many observations (rows) and variables (columns) are there in the courses data?\nncol(courses)\n\n[1] 6\n\nnrow(courses)\n\n[1] 1718\n\n\nExercise 4: Class size\nHow big are the classes?\nPart a\nBefore digging in, note that some courses are listed twice in the courses data:\n\ncourses |&gt; \n  count(sessionID) |&gt; \n  filter(n &gt; 1)\n\n     sessionID n\n1  session2047 2\n2  session2067 2\n3  session2448 2\n4  session2509 2\n5  session2541 2\n6  session2824 2\n7  session2826 2\n8  session2862 2\n9  session2897 2\n10 session3046 2\n11 session3057 2\n12 session3123 2\n13 session3243 2\n14 session3257 2\n15 session3387 2\n16 session3400 2\n17 session3414 2\n18 session3430 2\n19 session3489 2\n20 session3524 2\n21 session3629 2\n22 session3643 2\n23 session3821 2\n\n\nIf we pick out just 1 of these, we learn that some courses are cross-listed in multiple departments:\n\ncourses |&gt; \n  filter(sessionID == \"session2047\")\n\nFor our class size exploration, obtain the total enrollments in each sessionID, combining any cross-listed sections. Save this as courses_combined. NOTE: There’s no joining to do here!\n\ncourses_combined &lt;- courses |&gt;\n  group_by(sessionID) |&gt;\n  summarise(enroll = sum(enroll))\n\n# Check that this has 1695 rows and 2 columns\ndim(courses_combined)\n\n[1] 1695    2\n\n\nPart b\nLet’s first examine the question of class size from the administration’s viewpoint. To this end, calculate the median class size across all class sections. (The median is the middle or 50th percentile. Unlike the mean, it’s not skewed by outliers.) THINK FIRST:\n\nWhich of the 2 datasets do you need to answer this question? One? Both?\nIf you need course information, use courses_combined not courses.\nDo you have to do any joining? If so, which dataset will go on the left, i.e. which dataset includes your primary observations of interest? Which join function will you need?\n\n\ncourses_combined |&gt;\n  summarize(median(enroll))\n\n# A tibble: 1 × 1\n  `median(enroll)`\n             &lt;int&gt;\n1               18\n\n\nPart c\nBut how big are classes from the student perspective? To this end, calculate the median class size for each individual student. Once you have the correct output, store it as student_class_size. THINK FIRST:\n\nWhich of the 2 datasets do you need to answer this question? One? Both?\nIf you need course information, use courses_combined not courses.\nDo you have to do any joining? If so, which dataset will go on the left, i.e. which dataset includes your primary observations of interest? Which join function will you need?\n\n\nstudentsize &lt;- grades |&gt;\n  left_join(courses_combined) |&gt;\n  group_by(sid) |&gt;\n  summarize(classmed = median(enroll)) \nhead(studentsize)\n\n# A tibble: 6 × 2\n  sid    classmed\n  &lt;chr&gt;     &lt;dbl&gt;\n1 S31185     23.5\n2 S31188     21  \n3 S31191     25  \n4 S31194     15  \n5 S31197     24  \n6 S31200     21  \n\n\nPart d\nThe median class size varies from student to student. To get a sense for the typical student experience and range in student experiences, construct and discuss a histogram of the median class sizes experienced by the students.\n\nggplot(studentsize, aes(x = classmed)) +\n  geom_histogram()\n\n\n\n\n\n\n\nExercise 5: Narrowing in on classes\nPart a\nShow data on the students that enrolled in session1986. THINK FIRST: Which of the 2 datasets do you need to answer this question? One? Both?\n\ngrades |&gt;\n  filter(sessionID == \"session1986\")\n\n     sid grade   sessionID\n1 S31401    B+ session1986\n2 S32247     B session1986\n\n\nPart b\nBelow is a dataset with all courses in department E:\n\ndept_E &lt;- courses |&gt; \n  filter(dept == \"E\")\n\nWhat students enrolled in classes in department E? (We just want info on the students, not the classes.)\n\ngrades |&gt; \n  semi_join(dept_E)\n\n      sid grade   sessionID\n1  S31245     A session2326\n2  S31470     B session3658\n3  S31470     B session3798\n4  S31470     A session3799\n5  S31938     A session2326\n6  S31968     A session3104\n7  S32022     A session3798\n8  S32046    A- session2326\n9  S32226     A session2326\n10 S32415     B session2835\n11 S32415    B+ session3799\n12 S32484    A- session3658\n\n\nExercise 6: All the wrangling\nUse all of your wrangling skills to answer the following prompts! THINK FIRST:\n\nThink about what tables you might need to join (if any). Identify the corresponding variables to match.\nYou’ll need an extra table to convert grades to grade point averages:\n\n\ngpa_conversion &lt;- tibble(\n  grade = c(\"A+\", \"A\", \"A-\", \"B+\", \"B\", \"B-\", \"C+\", \"C\", \"C-\", \"D+\", \"D\", \"D-\", \"NC\", \"AU\", \"S\"), \n  gp = c(4.3, 4, 3.7, 3.3, 3, 2.7, 2.3, 2, 1.7, 1.3, 1, 0.7, 0, NA, NA)\n)\n\ngpa_conversion\n\n# A tibble: 15 × 2\n   grade    gp\n   &lt;chr&gt; &lt;dbl&gt;\n 1 A+      4.3\n 2 A       4  \n 3 A-      3.7\n 4 B+      3.3\n 5 B       3  \n 6 B-      2.7\n 7 C+      2.3\n 8 C       2  \n 9 C-      1.7\n10 D+      1.3\n11 D       1  \n12 D-      0.7\n13 NC      0  \n14 AU     NA  \n15 S      NA  \n\n\nPart a\nHow many total student enrollments are there in each department? Order from high to low.\n\ncourses |&gt;\n  group_by(dept) |&gt;\n  summarize(total = sum(enroll)) |&gt;\n  arrange(desc(total))\n\n# A tibble: 40 × 2\n   dept  total\n   &lt;chr&gt; &lt;int&gt;\n 1 d      3046\n 2 j      2312\n 3 O      2178\n 4 M      2129\n 5 m      2105\n 6 D      2003\n 7 W      1960\n 8 q      1859\n 9 k      1824\n10 F      1587\n# ℹ 30 more rows\n\n\nPart b\nWhat’s the grade-point average (GPA) for each student?\n\ngrades |&gt;\n  left_join(gpa_conversion) |&gt;\n  group_by(sid) |&gt;\n  summarise(gpa = mean(gp, na.rm = TRUE)) |&gt;\n  summarize(median(gpa))\n\n# A tibble: 1 × 1\n  `median(gpa)`\n          &lt;dbl&gt;\n1          3.47\n\n\nPart c\nWhat’s the median GPA across all students?\n\ngrades |&gt; \n  left_join(gpa_conversion) |&gt; \n  group_by(sid) |&gt; \n  summarize(gpa = mean(gp, na.rm = TRUE)) |&gt; \n  summarize(median(gpa))\n\n# A tibble: 1 × 1\n  `median(gpa)`\n          &lt;dbl&gt;\n1          3.47\n\n\nPart d\nWhat fraction of grades are below B+?\n\ngrades |&gt; \n  left_join(gpa_conversion) |&gt; \n  mutate(below_b_plus = (gp &lt; 3.3)) |&gt; \n  summarize(mean(below_b_plus, na.rm = TRUE))\n\n  mean(below_b_plus, na.rm = TRUE)\n1                        0.2834776\n\n\nPart e\nWhat’s the grade-point average for each instructor? Order from low to high.\n\ngrades |&gt; \n  left_join(gpa_conversion) |&gt; \n  left_join(courses) |&gt; \n  group_by(iid) |&gt; \n  summarize(gpa = mean(gp, na.rm = TRUE)) |&gt; \n  arrange(gpa)\n\n# A tibble: 364 × 2\n   iid       gpa\n   &lt;chr&gt;   &lt;dbl&gt;\n 1 inst265  1.3 \n 2 inst444  1.7 \n 3 inst513  1.85\n 4 inst200  2   \n 5 inst507  2.2 \n 6 inst445  2.3 \n 7 inst420  2.6 \n 8 inst262  2.65\n 9 inst176  2.66\n10 inst234  2.7 \n# ℹ 354 more rows\n\n\nPart f\nCHALLENGE: Estimate the grade-point average for each department, and sort from low to high. NOTE: Don’t include cross-listed courses. Students in cross-listed courses could be enrolled under either department, and we do not know which department to assign the grade to. HINT: You’ll need to do multiple joins.\nExercise 7: HOMEWORK PRACTICE\nThis exercise is on Homework 4, thus no solutions are provided. In Homework 4, you’ll be working with the Birthdays data:\n\nlibrary(mosaic)\ndata(\"Birthdays\")\nhead(Birthdays)\n\n  state year month day       date wday births\n1    AK 1969     1   1 1969-01-01  Wed     14\n2    AL 1969     1   1 1969-01-01  Wed    174\n3    AR 1969     1   1 1969-01-01  Wed     78\n4    AZ 1969     1   1 1969-01-01  Wed     84\n5    CA 1969     1   1 1969-01-01  Wed    824\n6    CO 1969     1   1 1969-01-01  Wed    100\n\n\nYou’ll also be exploring how the number of daily births is (or isn’t!) related to holidays. To this end, import data on U.S. federal holidays here. NOTE: lubridate::dmy() converts the character-string date stored in the CSV to a “POSIX” date-number.\n\nholidays &lt;- read.csv(\"https://mac-stat.github.io/data/US-Holidays.csv\") |&gt;\n  mutate(date = as.POSIXct(lubridate::dmy(date)))\n\nPart a\nCreate a new dataset, daily_births_1980, which:\n\nkeeps only daily_births related to 1980\n\nadds a variable called is_holiday which is TRUE when the day is a holiday, and FALSE otherwise. NOTE: !is.na(x) is TRUE if column x is not NA, and FALSE if it is NA.\n\nPrint out the first 6 rows and confirm that your dataset has 366 rows (1 per day in 1980) and 7 columns. HINT: You’ll need to combine 2 different datasets.\n\n# Define daily_births_1980\n\n\n# Check out the first 6 rows\n\n\n# Confirm that daily_births_1980 has 366 rows and 7 columns\n\nPart b\nPlot the total number of babies born (y-axis) per day (x-axis) in 1980. Color each date according to its day of the week, and shape each date according to whether or not it’s a holiday. (This is a modified version of 3c!)\nPart c\nDiscuss your observations. For example: To what degree does the theory that there tend to be fewer births on holidays hold up? What holidays stand out the most?\nPart d (OPTIONAL)\nSome holidays stand out more than others. It would be helpful to label them. Use geom_text to add labels to each of the holidays. NOTE: You can set the orientation of a label with the angle argument; e.g., geom_text(angle = 40, ...).",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Joining</span>"
    ]
  },
  {
    "objectID": "ica/ica-joining.html#solutions",
    "href": "ica/ica-joining.html#solutions",
    "title": "\n21  Joining\n",
    "section": "\n21.7 Solutions",
    "text": "21.7 Solutions\n\nClick for Solutions\nExample 1\n\nclass\na student that took ANTH 101\ndata on ART 101\nExample 2\n\nWhat did this do? Linked course info to all students in students_1\n\nWhich observations from students_1 (the left table) were retained? All of them.\nWhich observations from enrollments_1 (the right table) were retained? Only STAT and GEOL, those that matched the students.\nWhat, if anything, would change if we reversed the order of the data tables? Think about it, then try. We retain the courses, not students.\n\n\nenrollments_1 |&gt; \n  left_join(students_1)\n\n     class enrollment student\n1 STAT 101         18       A\n2  ART 101         17    &lt;NA&gt;\n3 GEOL 101         24       B\n\n\nExample 3\n\nWhich observations from students_1 (the left table) were retained? A and B, only those with enrollment info.\nWhich observations from enrollments_1 (the right table) were retained? STAT and GEOL, only those with studen info.\nWhat, if anything, would change if we reversed the order of the data tables? Think about it, then try. Same info, different column order.\n\n\nenrollments_1 |&gt; \n    inner_join(students_1)\n\n     class enrollment student\n1 STAT 101         18       A\n2 GEOL 101         24       B\n\n\nExample 4\n\nWhich observations from students_1 (the left table) were retained? All\nWhich observations from enrollments_1 (the right table) were retained? All\nWhat, if anything, would change if we reversed the order of the data tables? Think about it, then try. Same data, different order.\n\n\nenrollments_1 |&gt; \n    full_join(students_1)\n\n     class enrollment student\n1 STAT 101         18       A\n2  ART 101         17    &lt;NA&gt;\n3 GEOL 101         24       B\n4 ANTH 101         NA       C\n\n\nExample 5\n\nWhich observations from students_1 (the left table) were retained? Only those with enrollment info.\nWhich observations from enrollments_1 (the right table) were retained? None.\nWhat, if anything, would change if we reversed the order of the data tables? Think about it, then try. Same data, different order.\n\n\nenrollments_1 |&gt; \n  semi_join(students_1)\n\n     class enrollment\n1 STAT 101         18\n2 GEOL 101         24\n\n\nExample 6\n\nWhich observations from students_1 (the left table) were retained? Only C, the one without enrollment info.\nWhich observations from enrollments_1 (the right table) were retained? None.\nWhat, if anything, would change if we reversed the order of the data tables? Think about it, then try. Retain only ART 101, the course with no student info.\n\n\nenrollments_1 |&gt; \n  anti_join(students_1)\n\n    class enrollment\n1 ART 101         17\n\n\nExercise 2: More small practice\n\n# 1. We want contact info for people who HAVEN'T voted\ncontact |&gt; \n  anti_join(voters, by = c(\"name\" = \"id\"))\n\n  name  address age\n1    B    grand  89\n2    C snelling  43\n\n# 2. We want contact info for people who HAVE voted\ncontact |&gt; \n  semi_join(voters, by = c(\"name\" = \"id\"))\n\n  name  address age\n1    A   summit  24\n2    D fairview  38\n\n# 3. We want any data available on each person\ncontact |&gt; \n  full_join(voters, by = c(\"name\" = \"id\"))\n\n  name  address age times_voted\n1    A   summit  24           2\n2    B    grand  89          NA\n3    C snelling  43          NA\n4    D fairview  38           4\n5    E     &lt;NA&gt;  NA          17\n6    F     &lt;NA&gt;  NA           6\n7    G     &lt;NA&gt;  NA          20\n\nvoters |&gt; \n  full_join(contact, by = c(\"id\" = \"name\"))\n\n  id times_voted  address age\n1  A           2   summit  24\n2  D           4 fairview  38\n3  E          17     &lt;NA&gt;  NA\n4  F           6     &lt;NA&gt;  NA\n5  G          20     &lt;NA&gt;  NA\n6  B          NA    grand  89\n7  C          NA snelling  43\n\n# 4. We want to add contact info, when possible, to the voting roster\nvoters |&gt; \n  left_join(contact, by = c(\"id\" = \"name\"))\n\n  id times_voted  address age\n1  A           2   summit  24\n2  D           4 fairview  38\n3  E          17     &lt;NA&gt;  NA\n4  F           6     &lt;NA&gt;  NA\n5  G          20     &lt;NA&gt;  NA\n\n\nExercise 3: Bigger datasets\n\n# How many observations (rows) and variables (columns) are there in the grades data?\ndim(grades)\n\n[1] 5844    3\n\n# How many observations (rows) and variables (columns) are there in the courses data?\ndim(courses)\n\n[1] 1718    6\n\n\nExercise 4: Class size\nPart a\n\ncourses_combined &lt;- courses |&gt;\n  group_by(sessionID) |&gt;\n  summarize(enroll = sum(enroll))\n\n# Check that this has 1695 rows and 2 columns\ndim(courses_combined)\n\n[1] 1695    2\n\n\nPart b\n\ncourses_combined |&gt; \n  summarize(median(enroll))\n\nPart c\n\nstudent_class_size &lt;- grades |&gt; \n  left_join(courses_combined) |&gt; \n  group_by(sid) |&gt; \n  summarize(med_class = median(enroll))\n\nhead(student_class_size)\n\nPart d\n\nggplot(student_class_size, aes(x = med_class)) +\n  geom_histogram(color = \"white\")\n\nExercise 5: Narrowing in on classes\nPart a\n\ngrades |&gt; \n  filter(sessionID == \"session1986\")\n\nPart b\n\ngrades |&gt; \n  semi_join(dept_E)\n\nExercise 6: All the wrangling\nPart a\n\ncourses |&gt; \n  group_by(dept) |&gt; \n  summarize(total = sum(enroll)) |&gt; \n  arrange(desc(total))\n\nPart b\n\ngrades |&gt; \n  left_join(gpa_conversion) |&gt; \n  group_by(sid) |&gt; \n  summarize(mean(gp, na.rm = TRUE))\n\nPart c\n\ngrades |&gt; \n  left_join(gpa_conversion) |&gt; \n  group_by(sid) |&gt; \n  summarize(gpa = mean(gp, na.rm = TRUE)) |&gt; \n  summarize(median(gpa))\n\nPart d\n\n# There are lots of approaches here!\ngrades |&gt; \n  left_join(gpa_conversion) |&gt; \n  mutate(below_b_plus = (gp &lt; 3.3)) |&gt; \n  summarize(mean(below_b_plus, na.rm = TRUE))\n\nPart e\n\ngrades |&gt; \n  left_join(gpa_conversion) |&gt; \n  left_join(courses) |&gt; \n  group_by(iid) |&gt; \n  summarize(gpa = mean(gp, na.rm = TRUE)) |&gt; \n  arrange(gpa)\n\nPart f\n\ncross_listed &lt;- courses |&gt; \n  count(sessionID) |&gt; \n  filter(n &gt; 1)\n\ngrades |&gt; \n  anti_join(cross_listed) |&gt; \n  inner_join(courses) |&gt; \n  left_join(gpa_conversion) |&gt; \n  group_by(dept) |&gt; \n  summarize(gpa = mean(gp, na.rm = TRUE)) |&gt; \n  arrange(gpa)",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Joining</span>"
    ]
  },
  {
    "objectID": "ica/ica-joining.html#footnotes",
    "href": "ica/ica-joining.html#footnotes",
    "title": "\n21  Joining\n",
    "section": "",
    "text": "There is also a right_join() that adds variables in the reverse direction from the left table to the right table, but we do not really need it as we can always switch the roles of the two tables.︎↩︎",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Joining</span>"
    ]
  }
]